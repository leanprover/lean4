// Lean compiler output
// Module: Lean.Meta.Tactic.Simp.BuiltinSimprocs.BitVec
// Imports: Lean.Meta.LitValues Lean.Meta.Tactic.Simp.BuiltinSimprocs.Nat Lean.Meta.Tactic.Simp.BuiltinSimprocs.Int Init.Data.BitVec.Basic
#include <lean/lean.h>
#if defined(__clang__)
#pragma clang diagnostic ignored "-Wunused-parameter"
#pragma clang diagnostic ignored "-Wunused-label"
#elif defined(__GNUC__) && !defined(__CLANG__)
#pragma GCC diagnostic ignored "-Wunused-parameter"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif
#ifdef __cplusplus
extern "C" {
#endif
static lean_object* l_BitVec_reduceGetElem___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l_BitVec_reduceLT___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
lean_object* l_BitVec_abs(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMod___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
lean_object* l_Lean_Expr_const___override(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l_BitVec_reduceReplicate___redArg___closed__1;
lean_object* l_Lean_Meta_Simp_evalPropStep___redArg(lean_object*, uint8_t, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
static lean_object* l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
LEAN_EXPORT uint8_t l_BitVec_instDecidableEqLiteral(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__5;
static lean_object* l_BitVec_reduceGT___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceClz___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_mkNatLit(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_;
static lean_object* l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l_BitVec_reduceSLE___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
LEAN_EXPORT lean_object* l_BitVec_reduceClz___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
lean_object* lean_mk_empty_array_with_capacity(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_setWidth(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAnd___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceULE___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3264_(lean_object*);
lean_object* l_Lean_Meta_getNatValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1840_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l_BitVec_reduceAnd___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
LEAN_EXPORT lean_object* l_BitVec_reduceLE___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceXOr___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_replicate(lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_extractLsb_x27___redArg(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_(lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__10;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceNeg___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__8;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1974_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
lean_object* l_Lean_Meta_mkEqSymm(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_(lean_object*);
lean_object* l_Lean_mkAppB(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
static lean_object* l_BitVec_reduceZeroExtend___redArg___closed__1;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
static lean_object* l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6571_(lean_object*);
static lean_object* l_BitVec_reduceHShiftRight___redArg___closed__0;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_(lean_object*);
static lean_object* l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
uint8_t l_Lean_Expr_isAppOfArity(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l_BitVec_reduceExtracLsb_x27___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
static lean_object* l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
LEAN_EXPORT lean_object* l_BitVec_reduceULE___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShift___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
uint8_t l_Lean_Expr_isApp(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSRem___redArg___closed__1;
static lean_object* l_BitVec_reduceAdd___redArg___closed__1;
lean_object* lean_array_push(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetElem___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2821_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_(lean_object*);
static lean_object* l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_(lean_object*);
static lean_object* l_BitVec_reduceUnary___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2665_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
static lean_object* l_BitVec_reduceNot___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSub___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
static lean_object* l_BitVec_reduceNot___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNot___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_(lean_object*);
static lean_object* l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_;
static lean_object* l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
static lean_object* l_BitVec_reduceLE___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_(lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1600_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
lean_object* l_BitVec_append___redArg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4885_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__3;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2897_(lean_object*);
static lean_object* l_BitVec_reduceGetLsb___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
static lean_object* l_BitVec_reduceNeg___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l_BitVec_reduceBinPred___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4176_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_(lean_object*);
lean_object* l_Lean_Expr_cleanupAnnotations(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_;
static lean_object* l_BitVec_reduceNe___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Meta_evalNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6769_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l_BitVec_reduceOr___redArg___closed__0;
static lean_object* l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5211_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSLE___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__7;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_shiftLeft(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
LEAN_EXPORT lean_object* l_BitVec_reduceNe___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
uint8_t lean_int_dec_le(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_shiftr(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_;
static lean_object* l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2751_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_(lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l_BitVec_reduceAnd___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
LEAN_EXPORT lean_object* l_BitVec_reduceBin___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSub___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
lean_object* l_Lean_Level_ofNat(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
lean_object* l_Lean_Expr_appArg_x21(lean_object*);
static lean_object* l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__10;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l_BitVec_reduceAppend___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceMul___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___redArg___closed__5;
lean_object* l_BitVec_smtUDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
static lean_object* l_BitVec_reduceGE___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l_BitVec_reduceGetBit___redArg___closed__4;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_allOnes(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2131_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l_BitVec_reduceExtracLsb_x27___redArg___closed__0;
lean_object* l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT uint8_t l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32_(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_(lean_object*);
lean_object* l_Nat_reprFast(lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___redArg___closed__0;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l_BitVec_reduceSub___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBEq___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSMod___redArg___closed__1;
static lean_object* l_BitVec_reduceEq___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2642_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_object*);
static lean_object* l_BitVec_reduceNeg___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceShift___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4508_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l_BitVec_reduceUnary___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6095_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUDiv___redArg___closed__0;
static lean_object* l_BitVec_reduceXOr___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceRotateLeft___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
LEAN_EXPORT lean_object* l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1800_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_(lean_object*);
static lean_object* l_BitVec_reduceSShiftRight___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_(lean_object*);
lean_object* l_BitVec_neg(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__13;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__11;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l_BitVec_reduceShiftRightShiftRight___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l_BitVec_reduceMod___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
lean_object* l_Lean_Meta_getIntValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_;
static lean_object* l_BitVec_reduceSShiftRight___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l_BitVec_reduceHShiftRight___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_;
static lean_object* l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
lean_object* l_BitVec_ofInt(lean_object*, lean_object*);
lean_object* l_BitVec_not(lean_object*, lean_object*);
lean_object* lean_nat_to_int(lean_object*);
static lean_object* l_BitVec_reduceRotateLeft___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l_BitVec_reduceBNe___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2055_(lean_object*);
static lean_object* l_BitVec_reduceULT___redArg___closed__0;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_div(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l_BitVec_reduceGT___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l_BitVec_reduceEq___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5827_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_(lean_object*);
static lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4467_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l_BitVec_reduceSMTUDiv___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceClz(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__14;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
static lean_object* l_BitVec_reduceSetWidth___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4670_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l_BitVec_reduceSignExtend___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
lean_object* l_BitVec_smtSDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_(lean_object*);
static lean_object* l_BitVec_reduceXOr___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3937_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_;
static lean_object* l_BitVec_reduceULT___redArg___closed__1;
lean_object* l_Lean_Meta_getBitVecValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_ofNat(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
LEAN_EXPORT lean_object* l_BitVec_reduceBin___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4862_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
lean_object* l_Lean_Meta_mkAppM(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l_BitVec_reduceLE___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceLE___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2082_(lean_object*);
static lean_object* l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_(lean_object*);
static lean_object* l_BitVec_reduceCast___redArg___closed__1;
static lean_object* l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
lean_object* l_BitVec_srem(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2001_(lean_object*);
static lean_object* l_BitVec_reduceMul___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l_BitVec_reduceGetBit___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
lean_object* l_BitVec_sdiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
LEAN_EXPORT lean_object* l_BitVec_reduceBEq(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6161_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOfInt___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
LEAN_EXPORT lean_object* l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3563_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
static lean_object* l_BitVec_reduceSLT___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
static lean_object* l_BitVec_reduceToInt___redArg___closed__0;
static lean_object* l_BitVec_reduceLT___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
LEAN_EXPORT lean_object* l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2175_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
static lean_object* l_BitVec_reduceShiftShift___redArg___closed__0;
static lean_object* l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2781_(lean_object*);
static lean_object* l_BitVec_reduceHShiftLeft___redArg___closed__2;
lean_object* l_BitVec_add(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l_BitVec_reduceUDiv___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
LEAN_EXPORT lean_object* l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4711_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
lean_object* lean_nat_land(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2711_(lean_object*);
static lean_object* l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l_BitVec_reduceSetWidth_x27___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMod___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_(lean_object*);
static lean_object* l_BitVec_reduceClz___redArg___closed__0;
static lean_object* l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_;
LEAN_EXPORT lean_object* l_BitVec_reduceULE___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l_BitVec_reduceGetBit___redArg___closed__3;
static lean_object* l_BitVec_reduceGetMsb___redArg___closed__1;
static lean_object* l_BitVec_reduceSignExtend___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_;
static lean_object* l_BitVec_reduceUMod___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4793_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
static lean_object* l_BitVec_reduceHShiftLeft___redArg___closed__0;
static lean_object* l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
lean_object* l_Lean_Expr_appFn_x21(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
static lean_object* l_BitVec_reduceSMTUDiv___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4629_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
static lean_object* l_BitVec_reduceShiftLeft___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
lean_object* l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(lean_object*, uint8_t, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
lean_object* l_BitVec_sshiftRight(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__11;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1680_(lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceULT___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_(lean_object*);
static lean_object* l_BitVec_reduceSMTSDiv___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
lean_object* l_Lean_Meta_getFinValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t l_BitVec_slt(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4752_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__4;
static lean_object* l_BitVec_reduceNot___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
static lean_object* l_BitVec_reduceMul___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
static lean_object* l_BitVec_reduceAbs___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l_BitVec_reduceSMod___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
lean_object* l_BitVec_rotateRight(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceReplicate___redArg___closed__0;
static lean_object* l_BitVec_instReprLiteral___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l_BitVec_reduceShiftRightShiftRight___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetMsb___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNe(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSetWidth___redArg___closed__0;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_;
static lean_object* l_BitVec_reduceSMTSDiv___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_(lean_object*);
static lean_object* l_BitVec_reduceUMod___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object*);
static lean_object* l_BitVec_reduceGetElem___redArg___closed__0;
static lean_object* l_BitVec_reduceToNat___redArg___closed__1;
lean_object* lean_nat_lxor(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_object*);
uint8_t l_Nat_testBit(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_;
static lean_object* l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_;
static lean_object* l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_(lean_object*);
static lean_object* l_BitVec_reduceLT___redArg___closed__1;
static lean_object* l_BitVec_reduceAdd___redArg___closed__0;
static lean_object* l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l_BitVec_reduceZeroExtend___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
lean_object* l_Lean_Expr_appFnCleanup___redArg(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4839_(lean_object*);
static lean_object* l_BitVec_reduceGetLsb___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_;
lean_object* l_Lean_Expr_app___override(lean_object*, lean_object*);
lean_object* lean_nat_pow(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULT___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_signExtend(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
lean_object* l_Lean_Meta_Simp_registerBuiltinSimproc(lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__6;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_(lean_object*);
uint8_t lean_nat_dec_eq(lean_object*, lean_object*);
lean_object* l_Lean_mkApp3(lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2851_(lean_object*);
static lean_object* l_BitVec_reduceAllOnes___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
static lean_object* l_BitVec_reduceDiv___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l_BitVec_reduceLE___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2028_(lean_object*);
static lean_object* l_BitVec_reduceAbs___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceShift___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t lean_nat_dec_lt(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
static lean_object* l_BitVec_reduceCast___redArg___closed__0;
static lean_object* l_BitVec_reduceMod___redArg___closed__0;
static lean_object* l_BitVec_reduceSLT___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6117_(lean_object*);
lean_object* lean_nat_mod(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2688_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
lean_object* l_Lean_mkRawNatLit(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_instReprLiteral;
static lean_object* l_BitVec_reduceMod___redArg___closed__2;
static lean_object* l_BitVec_reduceDiv___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMod___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Meta_Simp_registerBuiltinDSimproc(lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
lean_object* l_Lean_Name_mkStr2(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2109_(lean_object*);
static lean_object* l_BitVec_reduceSRem___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
static lean_object* l_BitVec_reduceUnary___redArg___closed__3;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_rotateLeft(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceEq___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
static lean_object* l_BitVec_reduceHShiftRight___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAppend___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_;
uint8_t l_Lean_Expr_isConstOf(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceNe___redArg___closed__0;
static lean_object* l_BitVec_reduceBEq___redArg___closed__2;
lean_object* l_BitVec_toInt(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___redArg___closed__6;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
static lean_object* l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
static lean_object* l_BitVec_reduceToInt___redArg___closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Int_toNat(lean_object*);
static lean_object* l_BitVec_reduceDiv___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeft___redArg___closed__0;
static lean_object* l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
LEAN_EXPORT lean_object* l_BitVec_reduceCast___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_shiftl(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_;
LEAN_EXPORT lean_object* l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4548_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_sub(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___redArg___closed__1;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_(lean_object*);
uint8_t l_instDecidableNot___redArg(uint8_t);
lean_object* lean_nat_mul(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_(lean_object*);
static lean_object* l_BitVec_reduceToNat___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNe___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6139_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_(lean_object*);
static lean_object* l_BitVec_reduceGE___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
static lean_object* l_BitVec_reduceUnary___redArg___closed__4;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__2;
static lean_object* l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
LEAN_EXPORT lean_object* l_BitVec_reduceULE___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceMul___redArg___closed__2;
static lean_object* l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_(lean_object*);
lean_object* l_Lean_Meta_Simp_addSimprocBuiltinAttr(lean_object*, uint8_t, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_(lean_object*);
static lean_object* l_BitVec_reduceSDiv___redArg___closed__0;
lean_object* l_BitVec_smod(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_(lean_object*);
static lean_object* l_BitVec_reduceAdd___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAllOnes___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceEq(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___redArg___closed__4;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_(lean_object*);
lean_object* l_BitVec_mul(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___redArg___closed__1;
static lean_object* l_BitVec_reduceBitVecOfFin___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_(lean_object*);
static lean_object* l_BitVec_reduceHShiftLeft___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1760_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
LEAN_EXPORT lean_object* l_BitVec_reduceCast___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
static lean_object* l_BitVec_reduceOr___redArg___closed__2;
static lean_object* l_BitVec_reduceAppend___redArg___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_instToExprInt_mkNat(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
lean_object* l_BitVec_clz(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
static lean_object* l_BitVec_reduceULE___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6321_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__12;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
lean_object* l_Lean_Name_mkStr1(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
LEAN_EXPORT lean_object* l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4816_(lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_(lean_object*);
static lean_object* l_BitVec_reduceOr___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2153_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
LEAN_EXPORT lean_object* l_BitVec_reprLiteral___redArg____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1947_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceEq___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecOfFin___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
static lean_object* l_BitVec_reduceToInt___redArg___closed__3;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
LEAN_EXPORT lean_object* l_BitVec_reduceULT___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5479_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
lean_object* lean_int_neg(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
static lean_object* l_BitVec_reduceGT___redArg___closed__2;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
static lean_object* l_BitVec_reduceBEq___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
uint8_t lean_nat_dec_le(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l_BitVec_reduceBNe___redArg___closed__0;
LEAN_EXPORT lean_object* l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBNe(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32____boxed(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_;
static lean_object* l_BitVec_reduceSetWidth_x27___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l_BitVec_reduceRotateRight___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1541_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
lean_object* lean_nat_add(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSub___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUnary___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
static lean_object* l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_;
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l_BitVec_reduceGE___redArg___closed__0;
static lean_object* l_BitVec_reduceSDiv___redArg___closed__1;
static lean_object* l_BitVec_reduceGetBit___redArg___closed__0;
static lean_object* l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_;
LEAN_EXPORT lean_object* l_BitVec_instDecidableEqLiteral___boxed(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__5;
static lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
static lean_object* l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_object*);
lean_object* l_BitVec_BitVec_repr(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0;
static lean_object* l_BitVec_reduceRotateRight___redArg___closed__0;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
LEAN_EXPORT lean_object* l_BitVec_reduceClz___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_lor(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
static lean_object* l_BitVec_reduceBitVecToFin___redArg___closed__7;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
lean_object* l_BitVec_sub(lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
LEAN_EXPORT lean_object* l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177____boxed(lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1578_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4589_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t l_BitVec_sle(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___redArg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_(lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___redArg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
static lean_object* l_BitVec_reduceClz___redArg___closed__1;
static lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
static lean_object* l_BitVec_reduceOfInt___redArg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_(lean_object*);
LEAN_EXPORT uint8_t l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32_(lean_object* x_1, lean_object* x_2) {
_start:
{
lean_object* x_3; lean_object* x_4; lean_object* x_5; lean_object* x_6; uint8_t x_7; 
x_3 = lean_ctor_get(x_1, 0);
x_4 = lean_ctor_get(x_1, 1);
x_5 = lean_ctor_get(x_2, 0);
x_6 = lean_ctor_get(x_2, 1);
x_7 = lean_nat_dec_eq(x_3, x_5);
if (x_7 == 0)
{
return x_7;
}
else
{
uint8_t x_8; 
x_8 = lean_nat_dec_eq(x_4, x_6);
return x_8;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32____boxed(lean_object* x_1, lean_object* x_2) {
_start:
{
uint8_t x_3; lean_object* x_4; 
x_3 = l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32_(x_1, x_2);
lean_dec(x_2);
lean_dec(x_1);
x_4 = lean_box(x_3);
return x_4;
}
}
LEAN_EXPORT uint8_t l_BitVec_instDecidableEqLiteral(lean_object* x_1, lean_object* x_2) {
_start:
{
uint8_t x_3; 
x_3 = l_BitVec_decEqLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_32_(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_instDecidableEqLiteral___boxed(lean_object* x_1, lean_object* x_2) {
_start:
{
uint8_t x_3; lean_object* x_4; 
x_3 = l_BitVec_instDecidableEqLiteral(x_1, x_2);
lean_dec(x_2);
lean_dec(x_1);
x_4 = lean_box(x_3);
return x_4;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("{ ", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("n", 1, 1);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_box(0);
x_3 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked(" := ", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_3 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(5u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked(",", 1, 1);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("value", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(9u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked(" }", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reprLiteral___redArg____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(lean_object* x_1) {
_start:
{
uint8_t x_2; 
x_2 = !lean_is_exclusive(x_1);
if (x_2 == 0)
{
lean_object* x_3; lean_object* x_4; lean_object* x_5; lean_object* x_6; lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_11; uint8_t x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; uint8_t x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; uint8_t x_34; 
x_3 = lean_ctor_get(x_1, 0);
x_4 = lean_ctor_get(x_1, 1);
x_5 = l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_6 = l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_7 = l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
lean_inc(x_3);
x_8 = l_Nat_reprFast(x_3);
x_9 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_9, 0, x_8);
lean_ctor_set_tag(x_1, 4);
lean_ctor_set(x_1, 1, x_9);
lean_ctor_set(x_1, 0, x_7);
x_10 = lean_box(0);
x_11 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_11, 0, x_1);
x_12 = lean_unbox(x_10);
lean_ctor_set_uint8(x_11, sizeof(void*)*1, x_12);
x_13 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_13, 0, x_6);
lean_ctor_set(x_13, 1, x_11);
x_14 = l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_15 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_15, 0, x_13);
lean_ctor_set(x_15, 1, x_14);
x_16 = lean_box(1);
x_17 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_17, 0, x_15);
lean_ctor_set(x_17, 1, x_16);
x_18 = l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_19 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_19, 0, x_17);
lean_ctor_set(x_19, 1, x_18);
x_20 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_5);
x_21 = l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_22 = l_BitVec_BitVec_repr(x_3, x_4);
x_23 = lean_alloc_ctor(4, 2, 0);
lean_ctor_set(x_23, 0, x_21);
lean_ctor_set(x_23, 1, x_22);
x_24 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_unbox(x_10);
lean_ctor_set_uint8(x_24, sizeof(void*)*1, x_25);
x_26 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_26, 0, x_20);
lean_ctor_set(x_26, 1, x_24);
x_27 = l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_28 = l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_29 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_29, 1, x_26);
x_30 = l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_31 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_31, 0, x_29);
lean_ctor_set(x_31, 1, x_30);
x_32 = lean_alloc_ctor(4, 2, 0);
lean_ctor_set(x_32, 0, x_27);
lean_ctor_set(x_32, 1, x_31);
x_33 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_33, 0, x_32);
x_34 = lean_unbox(x_10);
lean_ctor_set_uint8(x_33, sizeof(void*)*1, x_34);
return x_33;
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; uint8_t x_67; 
x_35 = lean_ctor_get(x_1, 0);
x_36 = lean_ctor_get(x_1, 1);
lean_inc(x_36);
lean_inc(x_35);
lean_dec(x_1);
x_37 = l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_38 = l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_39 = l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
lean_inc(x_35);
x_40 = l_Nat_reprFast(x_35);
x_41 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_41, 0, x_40);
x_42 = lean_alloc_ctor(4, 2, 0);
lean_ctor_set(x_42, 0, x_39);
lean_ctor_set(x_42, 1, x_41);
x_43 = lean_box(0);
x_44 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_44, 0, x_42);
x_45 = lean_unbox(x_43);
lean_ctor_set_uint8(x_44, sizeof(void*)*1, x_45);
x_46 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_46, 0, x_38);
lean_ctor_set(x_46, 1, x_44);
x_47 = l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_48 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_48, 0, x_46);
lean_ctor_set(x_48, 1, x_47);
x_49 = lean_box(1);
x_50 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
x_51 = l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_52 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_52, 0, x_50);
lean_ctor_set(x_52, 1, x_51);
x_53 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_37);
x_54 = l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_55 = l_BitVec_BitVec_repr(x_35, x_36);
x_56 = lean_alloc_ctor(4, 2, 0);
lean_ctor_set(x_56, 0, x_54);
lean_ctor_set(x_56, 1, x_55);
x_57 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_57, 0, x_56);
x_58 = lean_unbox(x_43);
lean_ctor_set_uint8(x_57, sizeof(void*)*1, x_58);
x_59 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_59, 0, x_53);
lean_ctor_set(x_59, 1, x_57);
x_60 = l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_61 = l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_62 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_59);
x_63 = l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_;
x_64 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
x_65 = lean_alloc_ctor(4, 2, 0);
lean_ctor_set(x_65, 0, x_60);
lean_ctor_set(x_65, 1, x_64);
x_66 = lean_alloc_ctor(6, 1, 1);
lean_ctor_set(x_66, 0, x_65);
x_67 = lean_unbox(x_43);
lean_ctor_set_uint8(x_66, sizeof(void*)*1, x_67);
return x_66;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(lean_object* x_1, lean_object* x_2) {
_start:
{
lean_object* x_3; 
x_3 = l_BitVec_reprLiteral___redArg____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177____boxed(lean_object* x_1, lean_object* x_2) {
_start:
{
lean_object* x_3; 
x_3 = l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_(x_1, x_2);
lean_dec(x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_instReprLiteral___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reprLiteral____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177____boxed), 2, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_instReprLiteral() {
_start:
{
lean_object* x_1; 
x_1 = l_BitVec_instReprLiteral___closed__0;
return x_1;
}
}
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_Lean_Meta_getBitVecValue_x3f(x_1, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_7) == 0)
{
lean_object* x_8; 
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
if (lean_obj_tag(x_8) == 0)
{
uint8_t x_9; 
x_9 = !lean_is_exclusive(x_7);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
x_10 = lean_ctor_get(x_7, 0);
lean_dec(x_10);
x_11 = lean_box(0);
lean_ctor_set(x_7, 0, x_11);
return x_7;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = lean_ctor_get(x_7, 1);
lean_inc(x_12);
lean_dec(x_7);
x_13 = lean_box(0);
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_12);
return x_14;
}
}
else
{
uint8_t x_15; 
x_15 = !lean_is_exclusive(x_8);
if (x_15 == 0)
{
uint8_t x_16; 
x_16 = !lean_is_exclusive(x_7);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; uint8_t x_19; 
x_17 = lean_ctor_get(x_8, 0);
x_18 = lean_ctor_get(x_7, 0);
lean_dec(x_18);
x_19 = !lean_is_exclusive(x_17);
if (x_19 == 0)
{
return x_7;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_17, 0);
x_21 = lean_ctor_get(x_17, 1);
lean_inc(x_21);
lean_inc(x_20);
lean_dec(x_17);
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_20);
lean_ctor_set(x_22, 1, x_21);
lean_ctor_set(x_8, 0, x_22);
return x_7;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_23 = lean_ctor_get(x_8, 0);
x_24 = lean_ctor_get(x_7, 1);
lean_inc(x_24);
lean_dec(x_7);
x_25 = lean_ctor_get(x_23, 0);
lean_inc(x_25);
x_26 = lean_ctor_get(x_23, 1);
lean_inc(x_26);
if (lean_is_exclusive(x_23)) {
 lean_ctor_release(x_23, 0);
 lean_ctor_release(x_23, 1);
 x_27 = x_23;
} else {
 lean_dec_ref(x_23);
 x_27 = lean_box(0);
}
if (lean_is_scalar(x_27)) {
 x_28 = lean_alloc_ctor(0, 2, 0);
} else {
 x_28 = x_27;
}
lean_ctor_set(x_28, 0, x_25);
lean_ctor_set(x_28, 1, x_26);
lean_ctor_set(x_8, 0, x_28);
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_8);
lean_ctor_set(x_29, 1, x_24);
return x_29;
}
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_30 = lean_ctor_get(x_8, 0);
lean_inc(x_30);
lean_dec(x_8);
x_31 = lean_ctor_get(x_7, 1);
lean_inc(x_31);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_32 = x_7;
} else {
 lean_dec_ref(x_7);
 x_32 = lean_box(0);
}
x_33 = lean_ctor_get(x_30, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_30, 1);
lean_inc(x_34);
if (lean_is_exclusive(x_30)) {
 lean_ctor_release(x_30, 0);
 lean_ctor_release(x_30, 1);
 x_35 = x_30;
} else {
 lean_dec_ref(x_30);
 x_35 = lean_box(0);
}
if (lean_is_scalar(x_35)) {
 x_36 = lean_alloc_ctor(0, 2, 0);
} else {
 x_36 = x_35;
}
lean_ctor_set(x_36, 0, x_33);
lean_ctor_set(x_36, 1, x_34);
x_37 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_37, 0, x_36);
if (lean_is_scalar(x_32)) {
 x_38 = lean_alloc_ctor(0, 2, 0);
} else {
 x_38 = x_32;
}
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_31);
return x_38;
}
}
}
else
{
uint8_t x_39; 
x_39 = !lean_is_exclusive(x_7);
if (x_39 == 0)
{
return x_7;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_7, 0);
x_41 = lean_ctor_get(x_7, 1);
lean_inc(x_41);
lean_inc(x_40);
lean_dec(x_7);
x_42 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_42, 0, x_40);
lean_ctor_set(x_42, 1, x_41);
return x_42;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l_BitVec_reduceUnary___redArg___closed__0() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_box(0);
x_2 = lean_alloc_ctor(2, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceUnary___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("BitVec", 6, 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___redArg___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ofNat", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___redArg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___redArg___closed__2;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceUnary___redArg___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceUnary___redArg___closed__3;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
uint8_t x_10; 
x_10 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; 
x_13 = l_Lean_Expr_appArg_x21(x_4);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_3);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_15);
if (x_22 == 0)
{
uint8_t x_23; 
x_23 = !lean_is_exclusive(x_14);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_24 = lean_ctor_get(x_15, 0);
x_25 = lean_ctor_get(x_14, 0);
lean_dec(x_25);
x_26 = lean_ctor_get(x_24, 0);
lean_inc(x_26);
x_27 = lean_ctor_get(x_24, 1);
lean_inc(x_27);
lean_dec(x_24);
lean_inc(x_26);
x_28 = lean_apply_2(x_3, x_26, x_27);
x_29 = l_BitVec_reduceUnary___redArg___closed__4;
x_30 = l_Lean_mkNatLit(x_26);
x_31 = l_Lean_mkNatLit(x_28);
x_32 = l_Lean_mkAppB(x_29, x_30, x_31);
lean_ctor_set_tag(x_15, 0);
lean_ctor_set(x_15, 0, x_32);
return x_14;
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_15, 0);
x_34 = lean_ctor_get(x_14, 1);
lean_inc(x_34);
lean_dec(x_14);
x_35 = lean_ctor_get(x_33, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_33, 1);
lean_inc(x_36);
lean_dec(x_33);
lean_inc(x_35);
x_37 = lean_apply_2(x_3, x_35, x_36);
x_38 = l_BitVec_reduceUnary___redArg___closed__4;
x_39 = l_Lean_mkNatLit(x_35);
x_40 = l_Lean_mkNatLit(x_37);
x_41 = l_Lean_mkAppB(x_38, x_39, x_40);
lean_ctor_set_tag(x_15, 0);
lean_ctor_set(x_15, 0, x_41);
x_42 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_42, 0, x_15);
lean_ctor_set(x_42, 1, x_34);
return x_42;
}
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_43 = lean_ctor_get(x_15, 0);
lean_inc(x_43);
lean_dec(x_15);
x_44 = lean_ctor_get(x_14, 1);
lean_inc(x_44);
if (lean_is_exclusive(x_14)) {
 lean_ctor_release(x_14, 0);
 lean_ctor_release(x_14, 1);
 x_45 = x_14;
} else {
 lean_dec_ref(x_14);
 x_45 = lean_box(0);
}
x_46 = lean_ctor_get(x_43, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_43, 1);
lean_inc(x_47);
lean_dec(x_43);
lean_inc(x_46);
x_48 = lean_apply_2(x_3, x_46, x_47);
x_49 = l_BitVec_reduceUnary___redArg___closed__4;
x_50 = l_Lean_mkNatLit(x_46);
x_51 = l_Lean_mkNatLit(x_48);
x_52 = l_Lean_mkAppB(x_49, x_50, x_51);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
if (lean_is_scalar(x_45)) {
 x_54 = lean_alloc_ctor(0, 2, 0);
} else {
 x_54 = x_45;
}
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_44);
return x_54;
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_3);
x_55 = !lean_is_exclusive(x_14);
if (x_55 == 0)
{
return x_14;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_14, 0);
x_57 = lean_ctor_get(x_14, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_14);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = l_Lean_Expr_appArg_x21(x_4);
x_17 = l_BitVec_fromExpr_x3f___redArg(x_16, x_8, x_9, x_10, x_11, x_12);
if (lean_obj_tag(x_17) == 0)
{
lean_object* x_18; 
x_18 = lean_ctor_get(x_17, 0);
lean_inc(x_18);
if (lean_obj_tag(x_18) == 0)
{
uint8_t x_19; 
lean_dec(x_3);
x_19 = !lean_is_exclusive(x_17);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; 
x_20 = lean_ctor_get(x_17, 0);
lean_dec(x_20);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_17, 0, x_21);
return x_17;
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_22 = lean_ctor_get(x_17, 1);
lean_inc(x_22);
lean_dec(x_17);
x_23 = l_BitVec_reduceUnary___redArg___closed__0;
x_24 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_24, 0, x_23);
lean_ctor_set(x_24, 1, x_22);
return x_24;
}
}
else
{
uint8_t x_25; 
x_25 = !lean_is_exclusive(x_18);
if (x_25 == 0)
{
uint8_t x_26; 
x_26 = !lean_is_exclusive(x_17);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_27 = lean_ctor_get(x_18, 0);
x_28 = lean_ctor_get(x_17, 0);
lean_dec(x_28);
x_29 = lean_ctor_get(x_27, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_27, 1);
lean_inc(x_30);
lean_dec(x_27);
lean_inc(x_29);
x_31 = lean_apply_2(x_3, x_29, x_30);
x_32 = l_BitVec_reduceUnary___redArg___closed__4;
x_33 = l_Lean_mkNatLit(x_29);
x_34 = l_Lean_mkNatLit(x_31);
x_35 = l_Lean_mkAppB(x_32, x_33, x_34);
lean_ctor_set_tag(x_18, 0);
lean_ctor_set(x_18, 0, x_35);
return x_17;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_36 = lean_ctor_get(x_18, 0);
x_37 = lean_ctor_get(x_17, 1);
lean_inc(x_37);
lean_dec(x_17);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_36, 1);
lean_inc(x_39);
lean_dec(x_36);
lean_inc(x_38);
x_40 = lean_apply_2(x_3, x_38, x_39);
x_41 = l_BitVec_reduceUnary___redArg___closed__4;
x_42 = l_Lean_mkNatLit(x_38);
x_43 = l_Lean_mkNatLit(x_40);
x_44 = l_Lean_mkAppB(x_41, x_42, x_43);
lean_ctor_set_tag(x_18, 0);
lean_ctor_set(x_18, 0, x_44);
x_45 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_45, 0, x_18);
lean_ctor_set(x_45, 1, x_37);
return x_45;
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_46 = lean_ctor_get(x_18, 0);
lean_inc(x_46);
lean_dec(x_18);
x_47 = lean_ctor_get(x_17, 1);
lean_inc(x_47);
if (lean_is_exclusive(x_17)) {
 lean_ctor_release(x_17, 0);
 lean_ctor_release(x_17, 1);
 x_48 = x_17;
} else {
 lean_dec_ref(x_17);
 x_48 = lean_box(0);
}
x_49 = lean_ctor_get(x_46, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_46, 1);
lean_inc(x_50);
lean_dec(x_46);
lean_inc(x_49);
x_51 = lean_apply_2(x_3, x_49, x_50);
x_52 = l_BitVec_reduceUnary___redArg___closed__4;
x_53 = l_Lean_mkNatLit(x_49);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkAppB(x_52, x_53, x_54);
x_56 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_56, 0, x_55);
if (lean_is_scalar(x_48)) {
 x_57 = lean_alloc_ctor(0, 2, 0);
} else {
 x_57 = x_48;
}
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_47);
return x_57;
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_3);
x_58 = !lean_is_exclusive(x_17);
if (x_58 == 0)
{
return x_17;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_17, 0);
x_60 = lean_ctor_get(x_17, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_17);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUnary___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_1);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceUnary(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_1);
return x_13;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
uint8_t x_10; 
x_10 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
x_13 = l_Lean_Expr_appFn_x21(x_4);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
x_15 = l_BitVec_fromExpr_x3f___redArg(x_14, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_15, 1);
lean_inc(x_23);
lean_dec(x_15);
x_24 = lean_ctor_get(x_16, 0);
lean_inc(x_24);
lean_dec(x_16);
x_25 = l_Lean_Expr_appArg_x21(x_4);
x_26 = l_BitVec_fromExpr_x3f___redArg(x_25, x_5, x_6, x_7, x_8, x_23);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_24);
lean_dec(x_3);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceUnary___redArg___closed__0;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_27);
if (x_34 == 0)
{
uint8_t x_35; 
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_36 = lean_ctor_get(x_27, 0);
x_37 = lean_ctor_get(x_26, 0);
lean_dec(x_37);
x_38 = lean_ctor_get(x_24, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_24, 1);
lean_inc(x_39);
lean_dec(x_24);
x_40 = lean_ctor_get(x_36, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_36, 1);
lean_inc(x_41);
lean_dec(x_36);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_38);
lean_free_object(x_27);
lean_dec(x_3);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_26, 0, x_43);
return x_26;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; 
lean_inc(x_38);
x_44 = lean_apply_3(x_3, x_38, x_39, x_41);
x_45 = l_BitVec_reduceUnary___redArg___closed__4;
x_46 = l_Lean_mkNatLit(x_38);
x_47 = l_Lean_mkNatLit(x_44);
x_48 = l_Lean_mkAppB(x_45, x_46, x_47);
lean_ctor_set_tag(x_27, 0);
lean_ctor_set(x_27, 0, x_48);
return x_26;
}
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; uint8_t x_55; 
x_49 = lean_ctor_get(x_27, 0);
x_50 = lean_ctor_get(x_26, 1);
lean_inc(x_50);
lean_dec(x_26);
x_51 = lean_ctor_get(x_24, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_24, 1);
lean_inc(x_52);
lean_dec(x_24);
x_53 = lean_ctor_get(x_49, 0);
lean_inc(x_53);
x_54 = lean_ctor_get(x_49, 1);
lean_inc(x_54);
lean_dec(x_49);
x_55 = lean_nat_dec_eq(x_51, x_53);
lean_dec(x_53);
if (x_55 == 0)
{
lean_object* x_56; lean_object* x_57; 
lean_dec(x_54);
lean_dec(x_52);
lean_dec(x_51);
lean_free_object(x_27);
lean_dec(x_3);
x_56 = l_BitVec_reduceUnary___redArg___closed__0;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_50);
return x_57;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; 
lean_inc(x_51);
x_58 = lean_apply_3(x_3, x_51, x_52, x_54);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_51);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
lean_ctor_set_tag(x_27, 0);
lean_ctor_set(x_27, 0, x_62);
x_63 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_63, 0, x_27);
lean_ctor_set(x_63, 1, x_50);
return x_63;
}
}
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; uint8_t x_71; 
x_64 = lean_ctor_get(x_27, 0);
lean_inc(x_64);
lean_dec(x_27);
x_65 = lean_ctor_get(x_26, 1);
lean_inc(x_65);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 lean_ctor_release(x_26, 1);
 x_66 = x_26;
} else {
 lean_dec_ref(x_26);
 x_66 = lean_box(0);
}
x_67 = lean_ctor_get(x_24, 0);
lean_inc(x_67);
x_68 = lean_ctor_get(x_24, 1);
lean_inc(x_68);
lean_dec(x_24);
x_69 = lean_ctor_get(x_64, 0);
lean_inc(x_69);
x_70 = lean_ctor_get(x_64, 1);
lean_inc(x_70);
lean_dec(x_64);
x_71 = lean_nat_dec_eq(x_67, x_69);
lean_dec(x_69);
if (x_71 == 0)
{
lean_object* x_72; lean_object* x_73; 
lean_dec(x_70);
lean_dec(x_68);
lean_dec(x_67);
lean_dec(x_3);
x_72 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_66)) {
 x_73 = lean_alloc_ctor(0, 2, 0);
} else {
 x_73 = x_66;
}
lean_ctor_set(x_73, 0, x_72);
lean_ctor_set(x_73, 1, x_65);
return x_73;
}
else
{
lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; 
lean_inc(x_67);
x_74 = lean_apply_3(x_3, x_67, x_68, x_70);
x_75 = l_BitVec_reduceUnary___redArg___closed__4;
x_76 = l_Lean_mkNatLit(x_67);
x_77 = l_Lean_mkNatLit(x_74);
x_78 = l_Lean_mkAppB(x_75, x_76, x_77);
x_79 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_79, 0, x_78);
if (lean_is_scalar(x_66)) {
 x_80 = lean_alloc_ctor(0, 2, 0);
} else {
 x_80 = x_66;
}
lean_ctor_set(x_80, 0, x_79);
lean_ctor_set(x_80, 1, x_65);
return x_80;
}
}
}
}
else
{
uint8_t x_81; 
lean_dec(x_24);
lean_dec(x_3);
x_81 = !lean_is_exclusive(x_26);
if (x_81 == 0)
{
return x_26;
}
else
{
lean_object* x_82; lean_object* x_83; lean_object* x_84; 
x_82 = lean_ctor_get(x_26, 0);
x_83 = lean_ctor_get(x_26, 1);
lean_inc(x_83);
lean_inc(x_82);
lean_dec(x_26);
x_84 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_84, 0, x_82);
lean_ctor_set(x_84, 1, x_83);
return x_84;
}
}
}
}
else
{
uint8_t x_85; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_85 = !lean_is_exclusive(x_15);
if (x_85 == 0)
{
return x_15;
}
else
{
lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_86 = lean_ctor_get(x_15, 0);
x_87 = lean_ctor_get(x_15, 1);
lean_inc(x_87);
lean_inc(x_86);
lean_dec(x_15);
x_88 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_88, 0, x_86);
lean_ctor_set(x_88, 1, x_87);
return x_88;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = l_Lean_Expr_appFn_x21(x_4);
x_17 = l_Lean_Expr_appArg_x21(x_16);
lean_dec(x_16);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_18 = l_BitVec_fromExpr_x3f___redArg(x_17, x_8, x_9, x_10, x_11, x_12);
if (lean_obj_tag(x_18) == 0)
{
lean_object* x_19; 
x_19 = lean_ctor_get(x_18, 0);
lean_inc(x_19);
if (lean_obj_tag(x_19) == 0)
{
uint8_t x_20; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_20 = !lean_is_exclusive(x_18);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; 
x_21 = lean_ctor_get(x_18, 0);
lean_dec(x_21);
x_22 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 0, x_22);
return x_18;
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_23 = lean_ctor_get(x_18, 1);
lean_inc(x_23);
lean_dec(x_18);
x_24 = l_BitVec_reduceUnary___redArg___closed__0;
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_23);
return x_25;
}
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_26 = lean_ctor_get(x_18, 1);
lean_inc(x_26);
lean_dec(x_18);
x_27 = lean_ctor_get(x_19, 0);
lean_inc(x_27);
lean_dec(x_19);
x_28 = l_Lean_Expr_appArg_x21(x_4);
x_29 = l_BitVec_fromExpr_x3f___redArg(x_28, x_8, x_9, x_10, x_11, x_26);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
if (lean_obj_tag(x_30) == 0)
{
uint8_t x_31; 
lean_dec(x_27);
lean_dec(x_3);
x_31 = !lean_is_exclusive(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
x_32 = lean_ctor_get(x_29, 0);
lean_dec(x_32);
x_33 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_29, 0, x_33);
return x_29;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_29, 1);
lean_inc(x_34);
lean_dec(x_29);
x_35 = l_BitVec_reduceUnary___redArg___closed__0;
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_36, 1, x_34);
return x_36;
}
}
else
{
uint8_t x_37; 
x_37 = !lean_is_exclusive(x_30);
if (x_37 == 0)
{
uint8_t x_38; 
x_38 = !lean_is_exclusive(x_29);
if (x_38 == 0)
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; 
x_39 = lean_ctor_get(x_30, 0);
x_40 = lean_ctor_get(x_29, 0);
lean_dec(x_40);
x_41 = lean_ctor_get(x_27, 0);
lean_inc(x_41);
x_42 = lean_ctor_get(x_27, 1);
lean_inc(x_42);
lean_dec(x_27);
x_43 = lean_ctor_get(x_39, 0);
lean_inc(x_43);
x_44 = lean_ctor_get(x_39, 1);
lean_inc(x_44);
lean_dec(x_39);
x_45 = lean_nat_dec_eq(x_41, x_43);
lean_dec(x_43);
if (x_45 == 0)
{
lean_object* x_46; 
lean_dec(x_44);
lean_dec(x_42);
lean_dec(x_41);
lean_free_object(x_30);
lean_dec(x_3);
x_46 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_29, 0, x_46);
return x_29;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; 
lean_inc(x_41);
x_47 = lean_apply_3(x_3, x_41, x_42, x_44);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_41);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
lean_ctor_set_tag(x_30, 0);
lean_ctor_set(x_30, 0, x_51);
return x_29;
}
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; uint8_t x_58; 
x_52 = lean_ctor_get(x_30, 0);
x_53 = lean_ctor_get(x_29, 1);
lean_inc(x_53);
lean_dec(x_29);
x_54 = lean_ctor_get(x_27, 0);
lean_inc(x_54);
x_55 = lean_ctor_get(x_27, 1);
lean_inc(x_55);
lean_dec(x_27);
x_56 = lean_ctor_get(x_52, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_52, 1);
lean_inc(x_57);
lean_dec(x_52);
x_58 = lean_nat_dec_eq(x_54, x_56);
lean_dec(x_56);
if (x_58 == 0)
{
lean_object* x_59; lean_object* x_60; 
lean_dec(x_57);
lean_dec(x_55);
lean_dec(x_54);
lean_free_object(x_30);
lean_dec(x_3);
x_59 = l_BitVec_reduceUnary___redArg___closed__0;
x_60 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_60, 0, x_59);
lean_ctor_set(x_60, 1, x_53);
return x_60;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; 
lean_inc(x_54);
x_61 = lean_apply_3(x_3, x_54, x_55, x_57);
x_62 = l_BitVec_reduceUnary___redArg___closed__4;
x_63 = l_Lean_mkNatLit(x_54);
x_64 = l_Lean_mkNatLit(x_61);
x_65 = l_Lean_mkAppB(x_62, x_63, x_64);
lean_ctor_set_tag(x_30, 0);
lean_ctor_set(x_30, 0, x_65);
x_66 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_66, 0, x_30);
lean_ctor_set(x_66, 1, x_53);
return x_66;
}
}
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; uint8_t x_74; 
x_67 = lean_ctor_get(x_30, 0);
lean_inc(x_67);
lean_dec(x_30);
x_68 = lean_ctor_get(x_29, 1);
lean_inc(x_68);
if (lean_is_exclusive(x_29)) {
 lean_ctor_release(x_29, 0);
 lean_ctor_release(x_29, 1);
 x_69 = x_29;
} else {
 lean_dec_ref(x_29);
 x_69 = lean_box(0);
}
x_70 = lean_ctor_get(x_27, 0);
lean_inc(x_70);
x_71 = lean_ctor_get(x_27, 1);
lean_inc(x_71);
lean_dec(x_27);
x_72 = lean_ctor_get(x_67, 0);
lean_inc(x_72);
x_73 = lean_ctor_get(x_67, 1);
lean_inc(x_73);
lean_dec(x_67);
x_74 = lean_nat_dec_eq(x_70, x_72);
lean_dec(x_72);
if (x_74 == 0)
{
lean_object* x_75; lean_object* x_76; 
lean_dec(x_73);
lean_dec(x_71);
lean_dec(x_70);
lean_dec(x_3);
x_75 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_69)) {
 x_76 = lean_alloc_ctor(0, 2, 0);
} else {
 x_76 = x_69;
}
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_68);
return x_76;
}
else
{
lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; 
lean_inc(x_70);
x_77 = lean_apply_3(x_3, x_70, x_71, x_73);
x_78 = l_BitVec_reduceUnary___redArg___closed__4;
x_79 = l_Lean_mkNatLit(x_70);
x_80 = l_Lean_mkNatLit(x_77);
x_81 = l_Lean_mkAppB(x_78, x_79, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
if (lean_is_scalar(x_69)) {
 x_83 = lean_alloc_ctor(0, 2, 0);
} else {
 x_83 = x_69;
}
lean_ctor_set(x_83, 0, x_82);
lean_ctor_set(x_83, 1, x_68);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_27);
lean_dec(x_3);
x_84 = !lean_is_exclusive(x_29);
if (x_84 == 0)
{
return x_29;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_29, 0);
x_86 = lean_ctor_get(x_29, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_29);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
else
{
uint8_t x_88; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_88 = !lean_is_exclusive(x_18);
if (x_88 == 0)
{
return x_18;
}
else
{
lean_object* x_89; lean_object* x_90; lean_object* x_91; 
x_89 = lean_ctor_get(x_18, 0);
x_90 = lean_ctor_get(x_18, 1);
lean_inc(x_90);
lean_inc(x_89);
lean_dec(x_18);
x_91 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_91, 0, x_89);
lean_ctor_set(x_91, 1, x_90);
return x_91;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBin___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_1);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceBin(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_1);
return x_13;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; uint8_t x_10; 
x_9 = lean_unsigned_to_nat(3u);
x_10 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_9);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_8);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; 
x_13 = l_Lean_Expr_appArg_x21(x_3);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_4, x_5, x_6, x_7, x_8);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appFn_x21(x_3);
x_25 = l_Lean_Expr_appArg_x21(x_24);
lean_dec(x_24);
x_26 = l_Lean_Meta_getNatValue_x3f(x_25, x_4, x_5, x_6, x_7, x_22);
lean_dec(x_25);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_23);
lean_dec(x_2);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceUnary___redArg___closed__0;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_26);
if (x_34 == 0)
{
lean_object* x_35; uint8_t x_36; 
x_35 = lean_ctor_get(x_26, 0);
lean_dec(x_35);
x_36 = !lean_is_exclusive(x_27);
if (x_36 == 0)
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; 
x_37 = lean_ctor_get(x_27, 0);
x_38 = lean_ctor_get(x_23, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_23, 1);
lean_inc(x_39);
lean_dec(x_23);
lean_inc(x_37);
x_40 = lean_apply_3(x_2, x_38, x_37, x_39);
x_41 = l_BitVec_reduceUnary___redArg___closed__4;
x_42 = l_Lean_mkNatLit(x_37);
x_43 = l_Lean_mkNatLit(x_40);
x_44 = l_Lean_mkAppB(x_41, x_42, x_43);
lean_ctor_set_tag(x_27, 0);
lean_ctor_set(x_27, 0, x_44);
return x_26;
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_45 = lean_ctor_get(x_27, 0);
lean_inc(x_45);
lean_dec(x_27);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
lean_inc(x_45);
x_48 = lean_apply_3(x_2, x_46, x_45, x_47);
x_49 = l_BitVec_reduceUnary___redArg___closed__4;
x_50 = l_Lean_mkNatLit(x_45);
x_51 = l_Lean_mkNatLit(x_48);
x_52 = l_Lean_mkAppB(x_49, x_50, x_51);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_26, 0, x_53);
return x_26;
}
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_54 = lean_ctor_get(x_26, 1);
lean_inc(x_54);
lean_dec(x_26);
x_55 = lean_ctor_get(x_27, 0);
lean_inc(x_55);
if (lean_is_exclusive(x_27)) {
 lean_ctor_release(x_27, 0);
 x_56 = x_27;
} else {
 lean_dec_ref(x_27);
 x_56 = lean_box(0);
}
x_57 = lean_ctor_get(x_23, 0);
lean_inc(x_57);
x_58 = lean_ctor_get(x_23, 1);
lean_inc(x_58);
lean_dec(x_23);
lean_inc(x_55);
x_59 = lean_apply_3(x_2, x_57, x_55, x_58);
x_60 = l_BitVec_reduceUnary___redArg___closed__4;
x_61 = l_Lean_mkNatLit(x_55);
x_62 = l_Lean_mkNatLit(x_59);
x_63 = l_Lean_mkAppB(x_60, x_61, x_62);
if (lean_is_scalar(x_56)) {
 x_64 = lean_alloc_ctor(0, 1, 0);
} else {
 x_64 = x_56;
 lean_ctor_set_tag(x_64, 0);
}
lean_ctor_set(x_64, 0, x_63);
x_65 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_65, 0, x_64);
lean_ctor_set(x_65, 1, x_54);
return x_65;
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_23);
lean_dec(x_2);
x_66 = !lean_is_exclusive(x_26);
if (x_66 == 0)
{
return x_26;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_26, 0);
x_68 = lean_ctor_get(x_26, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_26);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
else
{
uint8_t x_70; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_70 = !lean_is_exclusive(x_14);
if (x_70 == 0)
{
return x_14;
}
else
{
lean_object* x_71; lean_object* x_72; lean_object* x_73; 
x_71 = lean_ctor_get(x_14, 0);
x_72 = lean_ctor_get(x_14, 1);
lean_inc(x_72);
lean_inc(x_71);
lean_dec(x_14);
x_73 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_73, 0, x_71);
lean_ctor_set(x_73, 1, x_72);
return x_73;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = l_Lean_Expr_appArg_x21(x_3);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_17 = l_BitVec_fromExpr_x3f___redArg(x_16, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_17) == 0)
{
lean_object* x_18; 
x_18 = lean_ctor_get(x_17, 0);
lean_inc(x_18);
if (lean_obj_tag(x_18) == 0)
{
uint8_t x_19; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_19 = !lean_is_exclusive(x_17);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; 
x_20 = lean_ctor_get(x_17, 0);
lean_dec(x_20);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_17, 0, x_21);
return x_17;
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_22 = lean_ctor_get(x_17, 1);
lean_inc(x_22);
lean_dec(x_17);
x_23 = l_BitVec_reduceUnary___redArg___closed__0;
x_24 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_24, 0, x_23);
lean_ctor_set(x_24, 1, x_22);
return x_24;
}
}
else
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_25 = lean_ctor_get(x_17, 1);
lean_inc(x_25);
lean_dec(x_17);
x_26 = lean_ctor_get(x_18, 0);
lean_inc(x_26);
lean_dec(x_18);
x_27 = l_Lean_Expr_appFn_x21(x_3);
x_28 = l_Lean_Expr_appArg_x21(x_27);
lean_dec(x_27);
x_29 = l_Lean_Meta_getNatValue_x3f(x_28, x_7, x_8, x_9, x_10, x_25);
lean_dec(x_28);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
if (lean_obj_tag(x_30) == 0)
{
uint8_t x_31; 
lean_dec(x_26);
lean_dec(x_2);
x_31 = !lean_is_exclusive(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
x_32 = lean_ctor_get(x_29, 0);
lean_dec(x_32);
x_33 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_29, 0, x_33);
return x_29;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_29, 1);
lean_inc(x_34);
lean_dec(x_29);
x_35 = l_BitVec_reduceUnary___redArg___closed__0;
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_36, 1, x_34);
return x_36;
}
}
else
{
uint8_t x_37; 
x_37 = !lean_is_exclusive(x_29);
if (x_37 == 0)
{
lean_object* x_38; uint8_t x_39; 
x_38 = lean_ctor_get(x_29, 0);
lean_dec(x_38);
x_39 = !lean_is_exclusive(x_30);
if (x_39 == 0)
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_40 = lean_ctor_get(x_30, 0);
x_41 = lean_ctor_get(x_26, 0);
lean_inc(x_41);
x_42 = lean_ctor_get(x_26, 1);
lean_inc(x_42);
lean_dec(x_26);
lean_inc(x_40);
x_43 = lean_apply_3(x_2, x_41, x_40, x_42);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_40);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_30, 0);
lean_ctor_set(x_30, 0, x_47);
return x_29;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_48 = lean_ctor_get(x_30, 0);
lean_inc(x_48);
lean_dec(x_30);
x_49 = lean_ctor_get(x_26, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_26, 1);
lean_inc(x_50);
lean_dec(x_26);
lean_inc(x_48);
x_51 = lean_apply_3(x_2, x_49, x_48, x_50);
x_52 = l_BitVec_reduceUnary___redArg___closed__4;
x_53 = l_Lean_mkNatLit(x_48);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkAppB(x_52, x_53, x_54);
x_56 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_29, 0, x_56);
return x_29;
}
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_57 = lean_ctor_get(x_29, 1);
lean_inc(x_57);
lean_dec(x_29);
x_58 = lean_ctor_get(x_30, 0);
lean_inc(x_58);
if (lean_is_exclusive(x_30)) {
 lean_ctor_release(x_30, 0);
 x_59 = x_30;
} else {
 lean_dec_ref(x_30);
 x_59 = lean_box(0);
}
x_60 = lean_ctor_get(x_26, 0);
lean_inc(x_60);
x_61 = lean_ctor_get(x_26, 1);
lean_inc(x_61);
lean_dec(x_26);
lean_inc(x_58);
x_62 = lean_apply_3(x_2, x_60, x_58, x_61);
x_63 = l_BitVec_reduceUnary___redArg___closed__4;
x_64 = l_Lean_mkNatLit(x_58);
x_65 = l_Lean_mkNatLit(x_62);
x_66 = l_Lean_mkAppB(x_63, x_64, x_65);
if (lean_is_scalar(x_59)) {
 x_67 = lean_alloc_ctor(0, 1, 0);
} else {
 x_67 = x_59;
 lean_ctor_set_tag(x_67, 0);
}
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_68, 0, x_67);
lean_ctor_set(x_68, 1, x_57);
return x_68;
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_26);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_29);
if (x_69 == 0)
{
return x_29;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_29, 0);
x_71 = lean_ctor_get(x_29, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_29);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
else
{
uint8_t x_73; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_73 = !lean_is_exclusive(x_17);
if (x_73 == 0)
{
return x_17;
}
else
{
lean_object* x_74; lean_object* x_75; lean_object* x_76; 
x_74 = lean_ctor_get(x_17, 0);
x_75 = lean_ctor_get(x_17, 1);
lean_inc(x_75);
lean_inc(x_74);
lean_dec(x_17);
x_76 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_76, 0, x_74);
lean_ctor_set(x_76, 1, x_75);
return x_76;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; 
x_9 = l_BitVec_reduceExtend___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8);
lean_dec(x_3);
lean_dec(x_1);
return x_9;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
return x_12;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Bool", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("false", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___redArg___closed__1;
x_2 = l_BitVec_reduceGetBit___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___redArg___closed__2;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__4() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("true", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___redArg___closed__4;
x_2 = l_BitVec_reduceGetBit___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___redArg___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___redArg___closed__5;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; uint8_t x_10; 
x_9 = lean_unsigned_to_nat(3u);
x_10 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_9);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_8);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
x_13 = l_Lean_Expr_appFn_x21(x_3);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_15 = l_BitVec_fromExpr_x3f___redArg(x_14, x_4, x_5, x_6, x_7, x_8);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
uint8_t x_23; 
x_23 = !lean_is_exclusive(x_15);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_24 = lean_ctor_get(x_15, 1);
x_25 = lean_ctor_get(x_15, 0);
lean_dec(x_25);
x_26 = lean_ctor_get(x_16, 0);
lean_inc(x_26);
if (lean_is_exclusive(x_16)) {
 lean_ctor_release(x_16, 0);
 x_27 = x_16;
} else {
 lean_dec_ref(x_16);
 x_27 = lean_box(0);
}
x_28 = l_Lean_Expr_appArg_x21(x_3);
x_29 = l_Lean_Meta_getNatValue_x3f(x_28, x_4, x_5, x_6, x_7, x_24);
lean_dec(x_28);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
x_31 = lean_ctor_get(x_29, 1);
lean_inc(x_31);
if (lean_is_exclusive(x_29)) {
 lean_ctor_release(x_29, 0);
 lean_ctor_release(x_29, 1);
 x_32 = x_29;
} else {
 lean_dec_ref(x_29);
 x_32 = lean_box(0);
}
if (lean_obj_tag(x_30) == 0)
{
lean_object* x_37; 
lean_dec(x_32);
lean_dec(x_27);
lean_dec(x_26);
lean_dec(x_2);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 1, x_31);
lean_ctor_set(x_15, 0, x_37);
return x_15;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
lean_free_object(x_15);
x_38 = lean_ctor_get(x_30, 0);
lean_inc(x_38);
lean_dec(x_30);
x_39 = lean_ctor_get(x_26, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_26, 1);
lean_inc(x_40);
lean_dec(x_26);
x_41 = lean_apply_3(x_2, x_39, x_40, x_38);
x_42 = lean_unbox(x_41);
lean_dec(x_41);
if (x_42 == 0)
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___redArg___closed__3;
x_33 = x_43;
goto block_36;
}
else
{
lean_object* x_44; 
x_44 = l_BitVec_reduceGetBit___redArg___closed__6;
x_33 = x_44;
goto block_36;
}
}
block_36:
{
lean_object* x_34; lean_object* x_35; 
if (lean_is_scalar(x_27)) {
 x_34 = lean_alloc_ctor(0, 1, 0);
} else {
 x_34 = x_27;
 lean_ctor_set_tag(x_34, 0);
}
lean_ctor_set(x_34, 0, x_33);
if (lean_is_scalar(x_32)) {
 x_35 = lean_alloc_ctor(0, 2, 0);
} else {
 x_35 = x_32;
}
lean_ctor_set(x_35, 0, x_34);
lean_ctor_set(x_35, 1, x_31);
return x_35;
}
}
else
{
uint8_t x_45; 
lean_dec(x_27);
lean_dec(x_26);
lean_free_object(x_15);
lean_dec(x_2);
x_45 = !lean_is_exclusive(x_29);
if (x_45 == 0)
{
return x_29;
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; 
x_46 = lean_ctor_get(x_29, 0);
x_47 = lean_ctor_get(x_29, 1);
lean_inc(x_47);
lean_inc(x_46);
lean_dec(x_29);
x_48 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_48, 0, x_46);
lean_ctor_set(x_48, 1, x_47);
return x_48;
}
}
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_49 = lean_ctor_get(x_15, 1);
lean_inc(x_49);
lean_dec(x_15);
x_50 = lean_ctor_get(x_16, 0);
lean_inc(x_50);
if (lean_is_exclusive(x_16)) {
 lean_ctor_release(x_16, 0);
 x_51 = x_16;
} else {
 lean_dec_ref(x_16);
 x_51 = lean_box(0);
}
x_52 = l_Lean_Expr_appArg_x21(x_3);
x_53 = l_Lean_Meta_getNatValue_x3f(x_52, x_4, x_5, x_6, x_7, x_49);
lean_dec(x_52);
if (lean_obj_tag(x_53) == 0)
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_54 = lean_ctor_get(x_53, 0);
lean_inc(x_54);
x_55 = lean_ctor_get(x_53, 1);
lean_inc(x_55);
if (lean_is_exclusive(x_53)) {
 lean_ctor_release(x_53, 0);
 lean_ctor_release(x_53, 1);
 x_56 = x_53;
} else {
 lean_dec_ref(x_53);
 x_56 = lean_box(0);
}
if (lean_obj_tag(x_54) == 0)
{
lean_object* x_61; lean_object* x_62; 
lean_dec(x_56);
lean_dec(x_51);
lean_dec(x_50);
lean_dec(x_2);
x_61 = l_BitVec_reduceUnary___redArg___closed__0;
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_55);
return x_62;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; uint8_t x_67; 
x_63 = lean_ctor_get(x_54, 0);
lean_inc(x_63);
lean_dec(x_54);
x_64 = lean_ctor_get(x_50, 0);
lean_inc(x_64);
x_65 = lean_ctor_get(x_50, 1);
lean_inc(x_65);
lean_dec(x_50);
x_66 = lean_apply_3(x_2, x_64, x_65, x_63);
x_67 = lean_unbox(x_66);
lean_dec(x_66);
if (x_67 == 0)
{
lean_object* x_68; 
x_68 = l_BitVec_reduceGetBit___redArg___closed__3;
x_57 = x_68;
goto block_60;
}
else
{
lean_object* x_69; 
x_69 = l_BitVec_reduceGetBit___redArg___closed__6;
x_57 = x_69;
goto block_60;
}
}
block_60:
{
lean_object* x_58; lean_object* x_59; 
if (lean_is_scalar(x_51)) {
 x_58 = lean_alloc_ctor(0, 1, 0);
} else {
 x_58 = x_51;
 lean_ctor_set_tag(x_58, 0);
}
lean_ctor_set(x_58, 0, x_57);
if (lean_is_scalar(x_56)) {
 x_59 = lean_alloc_ctor(0, 2, 0);
} else {
 x_59 = x_56;
}
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_55);
return x_59;
}
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; 
lean_dec(x_51);
lean_dec(x_50);
lean_dec(x_2);
x_70 = lean_ctor_get(x_53, 0);
lean_inc(x_70);
x_71 = lean_ctor_get(x_53, 1);
lean_inc(x_71);
if (lean_is_exclusive(x_53)) {
 lean_ctor_release(x_53, 0);
 lean_ctor_release(x_53, 1);
 x_72 = x_53;
} else {
 lean_dec_ref(x_53);
 x_72 = lean_box(0);
}
if (lean_is_scalar(x_72)) {
 x_73 = lean_alloc_ctor(1, 2, 0);
} else {
 x_73 = x_72;
}
lean_ctor_set(x_73, 0, x_70);
lean_ctor_set(x_73, 1, x_71);
return x_73;
}
}
}
}
else
{
uint8_t x_74; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_74 = !lean_is_exclusive(x_15);
if (x_74 == 0)
{
return x_15;
}
else
{
lean_object* x_75; lean_object* x_76; lean_object* x_77; 
x_75 = lean_ctor_get(x_15, 0);
x_76 = lean_ctor_get(x_15, 1);
lean_inc(x_76);
lean_inc(x_75);
lean_dec(x_15);
x_77 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_77, 0, x_75);
lean_ctor_set(x_77, 1, x_76);
return x_77;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = l_Lean_Expr_appFn_x21(x_3);
x_17 = l_Lean_Expr_appArg_x21(x_16);
lean_dec(x_16);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_18 = l_BitVec_fromExpr_x3f___redArg(x_17, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_18) == 0)
{
lean_object* x_19; 
x_19 = lean_ctor_get(x_18, 0);
lean_inc(x_19);
if (lean_obj_tag(x_19) == 0)
{
uint8_t x_20; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_20 = !lean_is_exclusive(x_18);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; 
x_21 = lean_ctor_get(x_18, 0);
lean_dec(x_21);
x_22 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 0, x_22);
return x_18;
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_23 = lean_ctor_get(x_18, 1);
lean_inc(x_23);
lean_dec(x_18);
x_24 = l_BitVec_reduceUnary___redArg___closed__0;
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_23);
return x_25;
}
}
else
{
uint8_t x_26; 
x_26 = !lean_is_exclusive(x_18);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_27 = lean_ctor_get(x_18, 1);
x_28 = lean_ctor_get(x_18, 0);
lean_dec(x_28);
x_29 = lean_ctor_get(x_19, 0);
lean_inc(x_29);
if (lean_is_exclusive(x_19)) {
 lean_ctor_release(x_19, 0);
 x_30 = x_19;
} else {
 lean_dec_ref(x_19);
 x_30 = lean_box(0);
}
x_31 = l_Lean_Expr_appArg_x21(x_3);
x_32 = l_Lean_Meta_getNatValue_x3f(x_31, x_7, x_8, x_9, x_10, x_27);
lean_dec(x_31);
if (lean_obj_tag(x_32) == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
if (lean_is_exclusive(x_32)) {
 lean_ctor_release(x_32, 0);
 lean_ctor_release(x_32, 1);
 x_35 = x_32;
} else {
 lean_dec_ref(x_32);
 x_35 = lean_box(0);
}
if (lean_obj_tag(x_33) == 0)
{
lean_object* x_40; 
lean_dec(x_35);
lean_dec(x_30);
lean_dec(x_29);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 1, x_34);
lean_ctor_set(x_18, 0, x_40);
return x_18;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; 
lean_free_object(x_18);
x_41 = lean_ctor_get(x_33, 0);
lean_inc(x_41);
lean_dec(x_33);
x_42 = lean_ctor_get(x_29, 0);
lean_inc(x_42);
x_43 = lean_ctor_get(x_29, 1);
lean_inc(x_43);
lean_dec(x_29);
x_44 = lean_apply_3(x_2, x_42, x_43, x_41);
x_45 = lean_unbox(x_44);
lean_dec(x_44);
if (x_45 == 0)
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__3;
x_36 = x_46;
goto block_39;
}
else
{
lean_object* x_47; 
x_47 = l_BitVec_reduceGetBit___redArg___closed__6;
x_36 = x_47;
goto block_39;
}
}
block_39:
{
lean_object* x_37; lean_object* x_38; 
if (lean_is_scalar(x_30)) {
 x_37 = lean_alloc_ctor(0, 1, 0);
} else {
 x_37 = x_30;
 lean_ctor_set_tag(x_37, 0);
}
lean_ctor_set(x_37, 0, x_36);
if (lean_is_scalar(x_35)) {
 x_38 = lean_alloc_ctor(0, 2, 0);
} else {
 x_38 = x_35;
}
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_34);
return x_38;
}
}
else
{
uint8_t x_48; 
lean_dec(x_30);
lean_dec(x_29);
lean_free_object(x_18);
lean_dec(x_2);
x_48 = !lean_is_exclusive(x_32);
if (x_48 == 0)
{
return x_32;
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; 
x_49 = lean_ctor_get(x_32, 0);
x_50 = lean_ctor_get(x_32, 1);
lean_inc(x_50);
lean_inc(x_49);
lean_dec(x_32);
x_51 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_51, 0, x_49);
lean_ctor_set(x_51, 1, x_50);
return x_51;
}
}
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_52 = lean_ctor_get(x_18, 1);
lean_inc(x_52);
lean_dec(x_18);
x_53 = lean_ctor_get(x_19, 0);
lean_inc(x_53);
if (lean_is_exclusive(x_19)) {
 lean_ctor_release(x_19, 0);
 x_54 = x_19;
} else {
 lean_dec_ref(x_19);
 x_54 = lean_box(0);
}
x_55 = l_Lean_Expr_appArg_x21(x_3);
x_56 = l_Lean_Meta_getNatValue_x3f(x_55, x_7, x_8, x_9, x_10, x_52);
lean_dec(x_55);
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_57 = lean_ctor_get(x_56, 0);
lean_inc(x_57);
x_58 = lean_ctor_get(x_56, 1);
lean_inc(x_58);
if (lean_is_exclusive(x_56)) {
 lean_ctor_release(x_56, 0);
 lean_ctor_release(x_56, 1);
 x_59 = x_56;
} else {
 lean_dec_ref(x_56);
 x_59 = lean_box(0);
}
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_64; lean_object* x_65; 
lean_dec(x_59);
lean_dec(x_54);
lean_dec(x_53);
lean_dec(x_2);
x_64 = l_BitVec_reduceUnary___redArg___closed__0;
x_65 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_65, 0, x_64);
lean_ctor_set(x_65, 1, x_58);
return x_65;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_66 = lean_ctor_get(x_57, 0);
lean_inc(x_66);
lean_dec(x_57);
x_67 = lean_ctor_get(x_53, 0);
lean_inc(x_67);
x_68 = lean_ctor_get(x_53, 1);
lean_inc(x_68);
lean_dec(x_53);
x_69 = lean_apply_3(x_2, x_67, x_68, x_66);
x_70 = lean_unbox(x_69);
lean_dec(x_69);
if (x_70 == 0)
{
lean_object* x_71; 
x_71 = l_BitVec_reduceGetBit___redArg___closed__3;
x_60 = x_71;
goto block_63;
}
else
{
lean_object* x_72; 
x_72 = l_BitVec_reduceGetBit___redArg___closed__6;
x_60 = x_72;
goto block_63;
}
}
block_63:
{
lean_object* x_61; lean_object* x_62; 
if (lean_is_scalar(x_54)) {
 x_61 = lean_alloc_ctor(0, 1, 0);
} else {
 x_61 = x_54;
 lean_ctor_set_tag(x_61, 0);
}
lean_ctor_set(x_61, 0, x_60);
if (lean_is_scalar(x_59)) {
 x_62 = lean_alloc_ctor(0, 2, 0);
} else {
 x_62 = x_59;
}
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_58);
return x_62;
}
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; 
lean_dec(x_54);
lean_dec(x_53);
lean_dec(x_2);
x_73 = lean_ctor_get(x_56, 0);
lean_inc(x_73);
x_74 = lean_ctor_get(x_56, 1);
lean_inc(x_74);
if (lean_is_exclusive(x_56)) {
 lean_ctor_release(x_56, 0);
 lean_ctor_release(x_56, 1);
 x_75 = x_56;
} else {
 lean_dec_ref(x_56);
 x_75 = lean_box(0);
}
if (lean_is_scalar(x_75)) {
 x_76 = lean_alloc_ctor(1, 2, 0);
} else {
 x_76 = x_75;
}
lean_ctor_set(x_76, 0, x_73);
lean_ctor_set(x_76, 1, x_74);
return x_76;
}
}
}
}
else
{
uint8_t x_77; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_77 = !lean_is_exclusive(x_18);
if (x_77 == 0)
{
return x_18;
}
else
{
lean_object* x_78; lean_object* x_79; lean_object* x_80; 
x_78 = lean_ctor_get(x_18, 0);
x_79 = lean_ctor_get(x_18, 1);
lean_inc(x_79);
lean_inc(x_78);
lean_dec(x_18);
x_80 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_80, 0, x_78);
lean_ctor_set(x_80, 1, x_79);
return x_80;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; 
x_9 = l_BitVec_reduceGetBit___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8);
lean_dec(x_3);
lean_dec(x_1);
return x_9;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceGetBit(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
uint8_t x_10; 
x_10 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
x_13 = l_Lean_Expr_appFn_x21(x_4);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
x_15 = l_BitVec_fromExpr_x3f___redArg(x_14, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_15, 1);
lean_inc(x_23);
lean_dec(x_15);
x_24 = lean_ctor_get(x_16, 0);
lean_inc(x_24);
lean_dec(x_16);
x_25 = l_Lean_Expr_appArg_x21(x_4);
x_26 = l_Lean_Meta_getNatValue_x3f(x_25, x_5, x_6, x_7, x_8, x_23);
lean_dec(x_25);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_24);
lean_dec(x_3);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceUnary___redArg___closed__0;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_26);
if (x_34 == 0)
{
lean_object* x_35; uint8_t x_36; 
x_35 = lean_ctor_get(x_26, 0);
lean_dec(x_35);
x_36 = !lean_is_exclusive(x_27);
if (x_36 == 0)
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; 
x_37 = lean_ctor_get(x_27, 0);
x_38 = lean_ctor_get(x_24, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_24, 1);
lean_inc(x_39);
lean_dec(x_24);
lean_inc(x_38);
x_40 = lean_apply_3(x_3, x_38, x_39, x_37);
x_41 = l_BitVec_reduceUnary___redArg___closed__4;
x_42 = l_Lean_mkNatLit(x_38);
x_43 = l_Lean_mkNatLit(x_40);
x_44 = l_Lean_mkAppB(x_41, x_42, x_43);
lean_ctor_set_tag(x_27, 0);
lean_ctor_set(x_27, 0, x_44);
return x_26;
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_45 = lean_ctor_get(x_27, 0);
lean_inc(x_45);
lean_dec(x_27);
x_46 = lean_ctor_get(x_24, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
lean_inc(x_46);
x_48 = lean_apply_3(x_3, x_46, x_47, x_45);
x_49 = l_BitVec_reduceUnary___redArg___closed__4;
x_50 = l_Lean_mkNatLit(x_46);
x_51 = l_Lean_mkNatLit(x_48);
x_52 = l_Lean_mkAppB(x_49, x_50, x_51);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_26, 0, x_53);
return x_26;
}
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_54 = lean_ctor_get(x_26, 1);
lean_inc(x_54);
lean_dec(x_26);
x_55 = lean_ctor_get(x_27, 0);
lean_inc(x_55);
if (lean_is_exclusive(x_27)) {
 lean_ctor_release(x_27, 0);
 x_56 = x_27;
} else {
 lean_dec_ref(x_27);
 x_56 = lean_box(0);
}
x_57 = lean_ctor_get(x_24, 0);
lean_inc(x_57);
x_58 = lean_ctor_get(x_24, 1);
lean_inc(x_58);
lean_dec(x_24);
lean_inc(x_57);
x_59 = lean_apply_3(x_3, x_57, x_58, x_55);
x_60 = l_BitVec_reduceUnary___redArg___closed__4;
x_61 = l_Lean_mkNatLit(x_57);
x_62 = l_Lean_mkNatLit(x_59);
x_63 = l_Lean_mkAppB(x_60, x_61, x_62);
if (lean_is_scalar(x_56)) {
 x_64 = lean_alloc_ctor(0, 1, 0);
} else {
 x_64 = x_56;
 lean_ctor_set_tag(x_64, 0);
}
lean_ctor_set(x_64, 0, x_63);
x_65 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_65, 0, x_64);
lean_ctor_set(x_65, 1, x_54);
return x_65;
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_24);
lean_dec(x_3);
x_66 = !lean_is_exclusive(x_26);
if (x_66 == 0)
{
return x_26;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_26, 0);
x_68 = lean_ctor_get(x_26, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_26);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
else
{
uint8_t x_70; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_70 = !lean_is_exclusive(x_15);
if (x_70 == 0)
{
return x_15;
}
else
{
lean_object* x_71; lean_object* x_72; lean_object* x_73; 
x_71 = lean_ctor_get(x_15, 0);
x_72 = lean_ctor_get(x_15, 1);
lean_inc(x_72);
lean_inc(x_71);
lean_dec(x_15);
x_73 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_73, 0, x_71);
lean_ctor_set(x_73, 1, x_72);
return x_73;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = l_Lean_Expr_appFn_x21(x_4);
x_17 = l_Lean_Expr_appArg_x21(x_16);
lean_dec(x_16);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_18 = l_BitVec_fromExpr_x3f___redArg(x_17, x_8, x_9, x_10, x_11, x_12);
if (lean_obj_tag(x_18) == 0)
{
lean_object* x_19; 
x_19 = lean_ctor_get(x_18, 0);
lean_inc(x_19);
if (lean_obj_tag(x_19) == 0)
{
uint8_t x_20; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_20 = !lean_is_exclusive(x_18);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; 
x_21 = lean_ctor_get(x_18, 0);
lean_dec(x_21);
x_22 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 0, x_22);
return x_18;
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_23 = lean_ctor_get(x_18, 1);
lean_inc(x_23);
lean_dec(x_18);
x_24 = l_BitVec_reduceUnary___redArg___closed__0;
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_23);
return x_25;
}
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_26 = lean_ctor_get(x_18, 1);
lean_inc(x_26);
lean_dec(x_18);
x_27 = lean_ctor_get(x_19, 0);
lean_inc(x_27);
lean_dec(x_19);
x_28 = l_Lean_Expr_appArg_x21(x_4);
x_29 = l_Lean_Meta_getNatValue_x3f(x_28, x_8, x_9, x_10, x_11, x_26);
lean_dec(x_28);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
if (lean_obj_tag(x_30) == 0)
{
uint8_t x_31; 
lean_dec(x_27);
lean_dec(x_3);
x_31 = !lean_is_exclusive(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
x_32 = lean_ctor_get(x_29, 0);
lean_dec(x_32);
x_33 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_29, 0, x_33);
return x_29;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_29, 1);
lean_inc(x_34);
lean_dec(x_29);
x_35 = l_BitVec_reduceUnary___redArg___closed__0;
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_36, 1, x_34);
return x_36;
}
}
else
{
uint8_t x_37; 
x_37 = !lean_is_exclusive(x_29);
if (x_37 == 0)
{
lean_object* x_38; uint8_t x_39; 
x_38 = lean_ctor_get(x_29, 0);
lean_dec(x_38);
x_39 = !lean_is_exclusive(x_30);
if (x_39 == 0)
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_40 = lean_ctor_get(x_30, 0);
x_41 = lean_ctor_get(x_27, 0);
lean_inc(x_41);
x_42 = lean_ctor_get(x_27, 1);
lean_inc(x_42);
lean_dec(x_27);
lean_inc(x_41);
x_43 = lean_apply_3(x_3, x_41, x_42, x_40);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_41);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_30, 0);
lean_ctor_set(x_30, 0, x_47);
return x_29;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_48 = lean_ctor_get(x_30, 0);
lean_inc(x_48);
lean_dec(x_30);
x_49 = lean_ctor_get(x_27, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_27, 1);
lean_inc(x_50);
lean_dec(x_27);
lean_inc(x_49);
x_51 = lean_apply_3(x_3, x_49, x_50, x_48);
x_52 = l_BitVec_reduceUnary___redArg___closed__4;
x_53 = l_Lean_mkNatLit(x_49);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkAppB(x_52, x_53, x_54);
x_56 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_29, 0, x_56);
return x_29;
}
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_57 = lean_ctor_get(x_29, 1);
lean_inc(x_57);
lean_dec(x_29);
x_58 = lean_ctor_get(x_30, 0);
lean_inc(x_58);
if (lean_is_exclusive(x_30)) {
 lean_ctor_release(x_30, 0);
 x_59 = x_30;
} else {
 lean_dec_ref(x_30);
 x_59 = lean_box(0);
}
x_60 = lean_ctor_get(x_27, 0);
lean_inc(x_60);
x_61 = lean_ctor_get(x_27, 1);
lean_inc(x_61);
lean_dec(x_27);
lean_inc(x_60);
x_62 = lean_apply_3(x_3, x_60, x_61, x_58);
x_63 = l_BitVec_reduceUnary___redArg___closed__4;
x_64 = l_Lean_mkNatLit(x_60);
x_65 = l_Lean_mkNatLit(x_62);
x_66 = l_Lean_mkAppB(x_63, x_64, x_65);
if (lean_is_scalar(x_59)) {
 x_67 = lean_alloc_ctor(0, 1, 0);
} else {
 x_67 = x_59;
 lean_ctor_set_tag(x_67, 0);
}
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_68, 0, x_67);
lean_ctor_set(x_68, 1, x_57);
return x_68;
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_27);
lean_dec(x_3);
x_69 = !lean_is_exclusive(x_29);
if (x_69 == 0)
{
return x_29;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_29, 0);
x_71 = lean_ctor_get(x_29, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_29);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
else
{
uint8_t x_73; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_73 = !lean_is_exclusive(x_18);
if (x_73 == 0)
{
return x_18;
}
else
{
lean_object* x_74; lean_object* x_75; lean_object* x_76; 
x_74 = lean_ctor_get(x_18, 0);
x_75 = lean_ctor_get(x_18, 1);
lean_inc(x_75);
lean_inc(x_74);
lean_dec(x_18);
x_76 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_76, 0, x_74);
lean_ctor_set(x_76, 1, x_75);
return x_76;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShift___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_1);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceShift(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7) {
_start:
{
lean_object* x_8; uint8_t x_9; 
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_2, x_1, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_7);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_2);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_3, x_4, x_5, x_6, x_7);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_22 = lean_ctor_get(x_14, 0);
x_23 = lean_ctor_get(x_13, 1);
lean_inc(x_23);
lean_dec(x_13);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_Lean_Expr_appFn_x21(x_2);
x_26 = l_Lean_Expr_appArg_x21(x_25);
lean_dec(x_25);
x_27 = l_Lean_mkNatLit(x_24);
x_28 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_29 = lean_array_push(x_28, x_26);
x_30 = lean_array_push(x_29, x_27);
x_31 = l_Lean_Meta_mkAppM(x_1, x_30, x_3, x_4, x_5, x_6, x_23);
if (lean_obj_tag(x_31) == 0)
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_31);
if (x_32 == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_31, 0);
lean_ctor_set(x_14, 0, x_33);
lean_ctor_set(x_31, 0, x_14);
return x_31;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_31, 0);
x_35 = lean_ctor_get(x_31, 1);
lean_inc(x_35);
lean_inc(x_34);
lean_dec(x_31);
lean_ctor_set(x_14, 0, x_34);
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_14);
lean_ctor_set(x_36, 1, x_35);
return x_36;
}
}
else
{
uint8_t x_37; 
lean_free_object(x_14);
x_37 = !lean_is_exclusive(x_31);
if (x_37 == 0)
{
return x_31;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_31, 0);
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_inc(x_38);
lean_dec(x_31);
x_40 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_40, 0, x_38);
lean_ctor_set(x_40, 1, x_39);
return x_40;
}
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_41 = lean_ctor_get(x_14, 0);
lean_inc(x_41);
lean_dec(x_14);
x_42 = lean_ctor_get(x_13, 1);
lean_inc(x_42);
lean_dec(x_13);
x_43 = lean_ctor_get(x_41, 1);
lean_inc(x_43);
lean_dec(x_41);
x_44 = l_Lean_Expr_appFn_x21(x_2);
x_45 = l_Lean_Expr_appArg_x21(x_44);
lean_dec(x_44);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_48 = lean_array_push(x_47, x_45);
x_49 = lean_array_push(x_48, x_46);
x_50 = l_Lean_Meta_mkAppM(x_1, x_49, x_3, x_4, x_5, x_6, x_42);
if (lean_obj_tag(x_50) == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_50, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 1);
lean_inc(x_52);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_53 = x_50;
} else {
 lean_dec_ref(x_50);
 x_53 = lean_box(0);
}
x_54 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_54, 0, x_51);
if (lean_is_scalar(x_53)) {
 x_55 = lean_alloc_ctor(0, 2, 0);
} else {
 x_55 = x_53;
}
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_52);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_50, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_50, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_58 = x_50;
} else {
 lean_dec_ref(x_50);
 x_58 = lean_box(0);
}
if (lean_is_scalar(x_58)) {
 x_59 = lean_alloc_ctor(1, 2, 0);
} else {
 x_59 = x_58;
}
lean_ctor_set(x_59, 0, x_56);
lean_ctor_set(x_59, 1, x_57);
return x_59;
}
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_60 = !lean_is_exclusive(x_13);
if (x_60 == 0)
{
return x_13;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_13, 0);
x_62 = lean_ctor_get(x_13, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_13);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; uint8_t x_12; 
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_2, x_1, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___redArg___closed__0;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_10);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = l_Lean_Expr_appArg_x21(x_2);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_16 = l_BitVec_fromExpr_x3f___redArg(x_15, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_16) == 0)
{
lean_object* x_17; 
x_17 = lean_ctor_get(x_16, 0);
lean_inc(x_17);
if (lean_obj_tag(x_17) == 0)
{
uint8_t x_18; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_18 = !lean_is_exclusive(x_16);
if (x_18 == 0)
{
lean_object* x_19; lean_object* x_20; 
x_19 = lean_ctor_get(x_16, 0);
lean_dec(x_19);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_16, 0, x_20);
return x_16;
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; 
x_21 = lean_ctor_get(x_16, 1);
lean_inc(x_21);
lean_dec(x_16);
x_22 = l_BitVec_reduceUnary___redArg___closed__0;
x_23 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_23, 0, x_22);
lean_ctor_set(x_23, 1, x_21);
return x_23;
}
}
else
{
uint8_t x_24; 
x_24 = !lean_is_exclusive(x_17);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; 
x_25 = lean_ctor_get(x_17, 0);
x_26 = lean_ctor_get(x_16, 1);
lean_inc(x_26);
lean_dec(x_16);
x_27 = lean_ctor_get(x_25, 1);
lean_inc(x_27);
lean_dec(x_25);
x_28 = l_Lean_Expr_appFn_x21(x_2);
x_29 = l_Lean_Expr_appArg_x21(x_28);
lean_dec(x_28);
x_30 = l_Lean_mkNatLit(x_27);
x_31 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_32 = lean_array_push(x_31, x_29);
x_33 = lean_array_push(x_32, x_30);
x_34 = l_Lean_Meta_mkAppM(x_1, x_33, x_6, x_7, x_8, x_9, x_26);
if (lean_obj_tag(x_34) == 0)
{
uint8_t x_35; 
x_35 = !lean_is_exclusive(x_34);
if (x_35 == 0)
{
lean_object* x_36; 
x_36 = lean_ctor_get(x_34, 0);
lean_ctor_set(x_17, 0, x_36);
lean_ctor_set(x_34, 0, x_17);
return x_34;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_37 = lean_ctor_get(x_34, 0);
x_38 = lean_ctor_get(x_34, 1);
lean_inc(x_38);
lean_inc(x_37);
lean_dec(x_34);
lean_ctor_set(x_17, 0, x_37);
x_39 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_39, 0, x_17);
lean_ctor_set(x_39, 1, x_38);
return x_39;
}
}
else
{
uint8_t x_40; 
lean_free_object(x_17);
x_40 = !lean_is_exclusive(x_34);
if (x_40 == 0)
{
return x_34;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_41 = lean_ctor_get(x_34, 0);
x_42 = lean_ctor_get(x_34, 1);
lean_inc(x_42);
lean_inc(x_41);
lean_dec(x_34);
x_43 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_43, 0, x_41);
lean_ctor_set(x_43, 1, x_42);
return x_43;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_44 = lean_ctor_get(x_17, 0);
lean_inc(x_44);
lean_dec(x_17);
x_45 = lean_ctor_get(x_16, 1);
lean_inc(x_45);
lean_dec(x_16);
x_46 = lean_ctor_get(x_44, 1);
lean_inc(x_46);
lean_dec(x_44);
x_47 = l_Lean_Expr_appFn_x21(x_2);
x_48 = l_Lean_Expr_appArg_x21(x_47);
lean_dec(x_47);
x_49 = l_Lean_mkNatLit(x_46);
x_50 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_51 = lean_array_push(x_50, x_48);
x_52 = lean_array_push(x_51, x_49);
x_53 = l_Lean_Meta_mkAppM(x_1, x_52, x_6, x_7, x_8, x_9, x_45);
if (lean_obj_tag(x_53) == 0)
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_54 = lean_ctor_get(x_53, 0);
lean_inc(x_54);
x_55 = lean_ctor_get(x_53, 1);
lean_inc(x_55);
if (lean_is_exclusive(x_53)) {
 lean_ctor_release(x_53, 0);
 lean_ctor_release(x_53, 1);
 x_56 = x_53;
} else {
 lean_dec_ref(x_53);
 x_56 = lean_box(0);
}
x_57 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_57, 0, x_54);
if (lean_is_scalar(x_56)) {
 x_58 = lean_alloc_ctor(0, 2, 0);
} else {
 x_58 = x_56;
}
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_55);
return x_58;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_59 = lean_ctor_get(x_53, 0);
lean_inc(x_59);
x_60 = lean_ctor_get(x_53, 1);
lean_inc(x_60);
if (lean_is_exclusive(x_53)) {
 lean_ctor_release(x_53, 0);
 lean_ctor_release(x_53, 1);
 x_61 = x_53;
} else {
 lean_dec_ref(x_53);
 x_61 = lean_box(0);
}
if (lean_is_scalar(x_61)) {
 x_62 = lean_alloc_ctor(1, 2, 0);
} else {
 x_62 = x_61;
}
lean_ctor_set(x_62, 0, x_59);
lean_ctor_set(x_62, 1, x_60);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_63 = !lean_is_exclusive(x_16);
if (x_63 == 0)
{
return x_16;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_16, 0);
x_65 = lean_ctor_get(x_16, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_16);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7) {
_start:
{
lean_object* x_8; 
x_8 = l_BitVec_reduceShiftWithBitVecLit___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7);
lean_dec(x_2);
return x_8;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftWithBitVecLit___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceShiftWithBitVecLit(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l_BitVec_reduceBinPred___redArg___closed__0() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_box(0);
x_2 = lean_alloc_ctor(2, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
uint8_t x_10; 
x_10 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_11 = l_BitVec_reduceBinPred___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
x_13 = l_Lean_Expr_appFn_x21(x_4);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
x_15 = l_BitVec_fromExpr_x3f___redArg(x_14, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceBinPred___redArg___closed__0;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_15, 1);
lean_inc(x_23);
lean_dec(x_15);
x_24 = lean_ctor_get(x_16, 0);
lean_inc(x_24);
lean_dec(x_16);
x_25 = l_Lean_Expr_appArg_x21(x_4);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
x_26 = l_BitVec_fromExpr_x3f___redArg(x_25, x_5, x_6, x_7, x_8, x_23);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_24);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceBinPred___redArg___closed__0;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_27, 0);
lean_inc(x_34);
lean_dec(x_27);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_36 = lean_ctor_get(x_26, 1);
x_37 = lean_ctor_get(x_26, 0);
lean_dec(x_37);
x_38 = lean_ctor_get(x_24, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_24, 1);
lean_inc(x_39);
lean_dec(x_24);
x_40 = lean_ctor_get(x_34, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_34, 1);
lean_inc(x_41);
lean_dec(x_34);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_38);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_43 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_26, 0, x_43);
return x_26;
}
else
{
lean_object* x_44; uint8_t x_45; lean_object* x_46; 
lean_free_object(x_26);
x_44 = lean_apply_3(x_3, x_38, x_39, x_41);
x_45 = lean_unbox(x_44);
lean_dec(x_44);
x_46 = l_Lean_Meta_Simp_evalPropStep___redArg(x_4, x_45, x_5, x_6, x_7, x_8, x_36);
return x_46;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; uint8_t x_52; 
x_47 = lean_ctor_get(x_26, 1);
lean_inc(x_47);
lean_dec(x_26);
x_48 = lean_ctor_get(x_24, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_24, 1);
lean_inc(x_49);
lean_dec(x_24);
x_50 = lean_ctor_get(x_34, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_34, 1);
lean_inc(x_51);
lean_dec(x_34);
x_52 = lean_nat_dec_eq(x_48, x_50);
lean_dec(x_50);
if (x_52 == 0)
{
lean_object* x_53; lean_object* x_54; 
lean_dec(x_51);
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_53 = l_BitVec_reduceBinPred___redArg___closed__0;
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_47);
return x_54;
}
else
{
lean_object* x_55; uint8_t x_56; lean_object* x_57; 
x_55 = lean_apply_3(x_3, x_48, x_49, x_51);
x_56 = lean_unbox(x_55);
lean_dec(x_55);
x_57 = l_Lean_Meta_Simp_evalPropStep___redArg(x_4, x_56, x_5, x_6, x_7, x_8, x_47);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_24);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_58 = !lean_is_exclusive(x_26);
if (x_58 == 0)
{
return x_26;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_26, 0);
x_60 = lean_ctor_get(x_26, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_26);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_62 = !lean_is_exclusive(x_15);
if (x_62 == 0)
{
return x_15;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_15, 0);
x_64 = lean_ctor_get(x_15, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_15);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceBinPred___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = l_Lean_Expr_appFn_x21(x_4);
x_17 = l_Lean_Expr_appArg_x21(x_16);
lean_dec(x_16);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_18 = l_BitVec_fromExpr_x3f___redArg(x_17, x_8, x_9, x_10, x_11, x_12);
if (lean_obj_tag(x_18) == 0)
{
lean_object* x_19; 
x_19 = lean_ctor_get(x_18, 0);
lean_inc(x_19);
if (lean_obj_tag(x_19) == 0)
{
uint8_t x_20; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_20 = !lean_is_exclusive(x_18);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; 
x_21 = lean_ctor_get(x_18, 0);
lean_dec(x_21);
x_22 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_18, 0, x_22);
return x_18;
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_23 = lean_ctor_get(x_18, 1);
lean_inc(x_23);
lean_dec(x_18);
x_24 = l_BitVec_reduceBinPred___redArg___closed__0;
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_23);
return x_25;
}
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_26 = lean_ctor_get(x_18, 1);
lean_inc(x_26);
lean_dec(x_18);
x_27 = lean_ctor_get(x_19, 0);
lean_inc(x_27);
lean_dec(x_19);
x_28 = l_Lean_Expr_appArg_x21(x_4);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_29 = l_BitVec_fromExpr_x3f___redArg(x_28, x_8, x_9, x_10, x_11, x_26);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
if (lean_obj_tag(x_30) == 0)
{
uint8_t x_31; 
lean_dec(x_27);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_31 = !lean_is_exclusive(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
x_32 = lean_ctor_get(x_29, 0);
lean_dec(x_32);
x_33 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_29, 0, x_33);
return x_29;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_29, 1);
lean_inc(x_34);
lean_dec(x_29);
x_35 = l_BitVec_reduceBinPred___redArg___closed__0;
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_36, 1, x_34);
return x_36;
}
}
else
{
lean_object* x_37; uint8_t x_38; 
x_37 = lean_ctor_get(x_30, 0);
lean_inc(x_37);
lean_dec(x_30);
x_38 = !lean_is_exclusive(x_29);
if (x_38 == 0)
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; 
x_39 = lean_ctor_get(x_29, 1);
x_40 = lean_ctor_get(x_29, 0);
lean_dec(x_40);
x_41 = lean_ctor_get(x_27, 0);
lean_inc(x_41);
x_42 = lean_ctor_get(x_27, 1);
lean_inc(x_42);
lean_dec(x_27);
x_43 = lean_ctor_get(x_37, 0);
lean_inc(x_43);
x_44 = lean_ctor_get(x_37, 1);
lean_inc(x_44);
lean_dec(x_37);
x_45 = lean_nat_dec_eq(x_41, x_43);
lean_dec(x_43);
if (x_45 == 0)
{
lean_object* x_46; 
lean_dec(x_44);
lean_dec(x_42);
lean_dec(x_41);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_46 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_29, 0, x_46);
return x_29;
}
else
{
lean_object* x_47; uint8_t x_48; lean_object* x_49; 
lean_free_object(x_29);
x_47 = lean_apply_3(x_3, x_41, x_42, x_44);
x_48 = lean_unbox(x_47);
lean_dec(x_47);
x_49 = l_Lean_Meta_Simp_evalPropStep___redArg(x_4, x_48, x_8, x_9, x_10, x_11, x_39);
return x_49;
}
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; uint8_t x_55; 
x_50 = lean_ctor_get(x_29, 1);
lean_inc(x_50);
lean_dec(x_29);
x_51 = lean_ctor_get(x_27, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_27, 1);
lean_inc(x_52);
lean_dec(x_27);
x_53 = lean_ctor_get(x_37, 0);
lean_inc(x_53);
x_54 = lean_ctor_get(x_37, 1);
lean_inc(x_54);
lean_dec(x_37);
x_55 = lean_nat_dec_eq(x_51, x_53);
lean_dec(x_53);
if (x_55 == 0)
{
lean_object* x_56; lean_object* x_57; 
lean_dec(x_54);
lean_dec(x_52);
lean_dec(x_51);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_56 = l_BitVec_reduceBinPred___redArg___closed__0;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_50);
return x_57;
}
else
{
lean_object* x_58; uint8_t x_59; lean_object* x_60; 
x_58 = lean_apply_3(x_3, x_51, x_52, x_54);
x_59 = lean_unbox(x_58);
lean_dec(x_58);
x_60 = l_Lean_Meta_Simp_evalPropStep___redArg(x_4, x_59, x_8, x_9, x_10, x_11, x_50);
return x_60;
}
}
}
}
else
{
uint8_t x_61; 
lean_dec(x_27);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_61 = !lean_is_exclusive(x_29);
if (x_61 == 0)
{
return x_29;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_62 = lean_ctor_get(x_29, 0);
x_63 = lean_ctor_get(x_29, 1);
lean_inc(x_63);
lean_inc(x_62);
lean_dec(x_29);
x_64 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
return x_64;
}
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_4);
lean_dec(x_3);
x_65 = !lean_is_exclusive(x_18);
if (x_65 == 0)
{
return x_18;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_18, 0);
x_67 = lean_ctor_get(x_18, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_18);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBinPred___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceBinPred(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
return x_13;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
uint8_t x_10; 
x_10 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
x_13 = l_Lean_Expr_appFn_x21(x_4);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
x_15 = l_BitVec_fromExpr_x3f___redArg(x_14, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___redArg___closed__0;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
uint8_t x_23; 
x_23 = !lean_is_exclusive(x_15);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_24 = lean_ctor_get(x_15, 1);
x_25 = lean_ctor_get(x_15, 0);
lean_dec(x_25);
x_26 = lean_ctor_get(x_16, 0);
lean_inc(x_26);
if (lean_is_exclusive(x_16)) {
 lean_ctor_release(x_16, 0);
 x_27 = x_16;
} else {
 lean_dec_ref(x_16);
 x_27 = lean_box(0);
}
x_28 = l_Lean_Expr_appArg_x21(x_4);
x_29 = l_BitVec_fromExpr_x3f___redArg(x_28, x_5, x_6, x_7, x_8, x_24);
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_30 = lean_ctor_get(x_29, 0);
lean_inc(x_30);
x_31 = lean_ctor_get(x_29, 1);
lean_inc(x_31);
if (lean_is_exclusive(x_29)) {
 lean_ctor_release(x_29, 0);
 lean_ctor_release(x_29, 1);
 x_32 = x_29;
} else {
 lean_dec_ref(x_29);
 x_32 = lean_box(0);
}
if (lean_obj_tag(x_30) == 0)
{
lean_object* x_37; 
lean_dec(x_32);
lean_dec(x_27);
lean_dec(x_26);
lean_dec(x_3);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 1, x_31);
lean_ctor_set(x_15, 0, x_37);
return x_15;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint8_t x_43; 
x_38 = lean_ctor_get(x_30, 0);
lean_inc(x_38);
lean_dec(x_30);
x_39 = lean_ctor_get(x_26, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_26, 1);
lean_inc(x_40);
lean_dec(x_26);
x_41 = lean_ctor_get(x_38, 0);
lean_inc(x_41);
x_42 = lean_ctor_get(x_38, 1);
lean_inc(x_42);
lean_dec(x_38);
x_43 = lean_nat_dec_eq(x_39, x_41);
lean_dec(x_41);
if (x_43 == 0)
{
lean_object* x_44; 
lean_dec(x_42);
lean_dec(x_40);
lean_dec(x_39);
lean_dec(x_32);
lean_dec(x_27);
lean_dec(x_3);
x_44 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_15, 1, x_31);
lean_ctor_set(x_15, 0, x_44);
return x_15;
}
else
{
lean_object* x_45; uint8_t x_46; 
lean_free_object(x_15);
x_45 = lean_apply_3(x_3, x_39, x_40, x_42);
x_46 = lean_unbox(x_45);
lean_dec(x_45);
if (x_46 == 0)
{
lean_object* x_47; 
x_47 = l_BitVec_reduceGetBit___redArg___closed__3;
x_33 = x_47;
goto block_36;
}
else
{
lean_object* x_48; 
x_48 = l_BitVec_reduceGetBit___redArg___closed__6;
x_33 = x_48;
goto block_36;
}
}
}
block_36:
{
lean_object* x_34; lean_object* x_35; 
if (lean_is_scalar(x_27)) {
 x_34 = lean_alloc_ctor(0, 1, 0);
} else {
 x_34 = x_27;
 lean_ctor_set_tag(x_34, 0);
}
lean_ctor_set(x_34, 0, x_33);
if (lean_is_scalar(x_32)) {
 x_35 = lean_alloc_ctor(0, 2, 0);
} else {
 x_35 = x_32;
}
lean_ctor_set(x_35, 0, x_34);
lean_ctor_set(x_35, 1, x_31);
return x_35;
}
}
else
{
uint8_t x_49; 
lean_dec(x_27);
lean_dec(x_26);
lean_free_object(x_15);
lean_dec(x_3);
x_49 = !lean_is_exclusive(x_29);
if (x_49 == 0)
{
return x_29;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_50 = lean_ctor_get(x_29, 0);
x_51 = lean_ctor_get(x_29, 1);
lean_inc(x_51);
lean_inc(x_50);
lean_dec(x_29);
x_52 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_52, 0, x_50);
lean_ctor_set(x_52, 1, x_51);
return x_52;
}
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_53 = lean_ctor_get(x_15, 1);
lean_inc(x_53);
lean_dec(x_15);
x_54 = lean_ctor_get(x_16, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_16)) {
 lean_ctor_release(x_16, 0);
 x_55 = x_16;
} else {
 lean_dec_ref(x_16);
 x_55 = lean_box(0);
}
x_56 = l_Lean_Expr_appArg_x21(x_4);
x_57 = l_BitVec_fromExpr_x3f___redArg(x_56, x_5, x_6, x_7, x_8, x_53);
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_58 = lean_ctor_get(x_57, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_57, 1);
lean_inc(x_59);
if (lean_is_exclusive(x_57)) {
 lean_ctor_release(x_57, 0);
 lean_ctor_release(x_57, 1);
 x_60 = x_57;
} else {
 lean_dec_ref(x_57);
 x_60 = lean_box(0);
}
if (lean_obj_tag(x_58) == 0)
{
lean_object* x_65; lean_object* x_66; 
lean_dec(x_60);
lean_dec(x_55);
lean_dec(x_54);
lean_dec(x_3);
x_65 = l_BitVec_reduceUnary___redArg___closed__0;
x_66 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_66, 0, x_65);
lean_ctor_set(x_66, 1, x_59);
return x_66;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; uint8_t x_72; 
x_67 = lean_ctor_get(x_58, 0);
lean_inc(x_67);
lean_dec(x_58);
x_68 = lean_ctor_get(x_54, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_54, 1);
lean_inc(x_69);
lean_dec(x_54);
x_70 = lean_ctor_get(x_67, 0);
lean_inc(x_70);
x_71 = lean_ctor_get(x_67, 1);
lean_inc(x_71);
lean_dec(x_67);
x_72 = lean_nat_dec_eq(x_68, x_70);
lean_dec(x_70);
if (x_72 == 0)
{
lean_object* x_73; lean_object* x_74; 
lean_dec(x_71);
lean_dec(x_69);
lean_dec(x_68);
lean_dec(x_60);
lean_dec(x_55);
lean_dec(x_3);
x_73 = l_BitVec_reduceUnary___redArg___closed__0;
x_74 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_74, 0, x_73);
lean_ctor_set(x_74, 1, x_59);
return x_74;
}
else
{
lean_object* x_75; uint8_t x_76; 
x_75 = lean_apply_3(x_3, x_68, x_69, x_71);
x_76 = lean_unbox(x_75);
lean_dec(x_75);
if (x_76 == 0)
{
lean_object* x_77; 
x_77 = l_BitVec_reduceGetBit___redArg___closed__3;
x_61 = x_77;
goto block_64;
}
else
{
lean_object* x_78; 
x_78 = l_BitVec_reduceGetBit___redArg___closed__6;
x_61 = x_78;
goto block_64;
}
}
}
block_64:
{
lean_object* x_62; lean_object* x_63; 
if (lean_is_scalar(x_55)) {
 x_62 = lean_alloc_ctor(0, 1, 0);
} else {
 x_62 = x_55;
 lean_ctor_set_tag(x_62, 0);
}
lean_ctor_set(x_62, 0, x_61);
if (lean_is_scalar(x_60)) {
 x_63 = lean_alloc_ctor(0, 2, 0);
} else {
 x_63 = x_60;
}
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_59);
return x_63;
}
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; 
lean_dec(x_55);
lean_dec(x_54);
lean_dec(x_3);
x_79 = lean_ctor_get(x_57, 0);
lean_inc(x_79);
x_80 = lean_ctor_get(x_57, 1);
lean_inc(x_80);
if (lean_is_exclusive(x_57)) {
 lean_ctor_release(x_57, 0);
 lean_ctor_release(x_57, 1);
 x_81 = x_57;
} else {
 lean_dec_ref(x_57);
 x_81 = lean_box(0);
}
if (lean_is_scalar(x_81)) {
 x_82 = lean_alloc_ctor(1, 2, 0);
} else {
 x_82 = x_81;
}
lean_ctor_set(x_82, 0, x_79);
lean_ctor_set(x_82, 1, x_80);
return x_82;
}
}
}
}
else
{
uint8_t x_83; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
x_83 = !lean_is_exclusive(x_15);
if (x_83 == 0)
{
return x_15;
}
else
{
lean_object* x_84; lean_object* x_85; lean_object* x_86; 
x_84 = lean_ctor_get(x_15, 0);
x_85 = lean_ctor_get(x_15, 1);
lean_inc(x_85);
lean_inc(x_84);
lean_dec(x_15);
x_86 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_86, 0, x_84);
lean_ctor_set(x_86, 1, x_85);
return x_86;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = l_Lean_Expr_appFn_x21(x_4);
x_17 = l_Lean_Expr_appArg_x21(x_16);
lean_dec(x_16);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_18 = l_BitVec_fromExpr_x3f___redArg(x_17, x_8, x_9, x_10, x_11, x_12);
if (lean_obj_tag(x_18) == 0)
{
lean_object* x_19; 
x_19 = lean_ctor_get(x_18, 0);
lean_inc(x_19);
if (lean_obj_tag(x_19) == 0)
{
uint8_t x_20; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_20 = !lean_is_exclusive(x_18);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; 
x_21 = lean_ctor_get(x_18, 0);
lean_dec(x_21);
x_22 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 0, x_22);
return x_18;
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_23 = lean_ctor_get(x_18, 1);
lean_inc(x_23);
lean_dec(x_18);
x_24 = l_BitVec_reduceUnary___redArg___closed__0;
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_23);
return x_25;
}
}
else
{
uint8_t x_26; 
x_26 = !lean_is_exclusive(x_18);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_27 = lean_ctor_get(x_18, 1);
x_28 = lean_ctor_get(x_18, 0);
lean_dec(x_28);
x_29 = lean_ctor_get(x_19, 0);
lean_inc(x_29);
if (lean_is_exclusive(x_19)) {
 lean_ctor_release(x_19, 0);
 x_30 = x_19;
} else {
 lean_dec_ref(x_19);
 x_30 = lean_box(0);
}
x_31 = l_Lean_Expr_appArg_x21(x_4);
x_32 = l_BitVec_fromExpr_x3f___redArg(x_31, x_8, x_9, x_10, x_11, x_27);
if (lean_obj_tag(x_32) == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
if (lean_is_exclusive(x_32)) {
 lean_ctor_release(x_32, 0);
 lean_ctor_release(x_32, 1);
 x_35 = x_32;
} else {
 lean_dec_ref(x_32);
 x_35 = lean_box(0);
}
if (lean_obj_tag(x_33) == 0)
{
lean_object* x_40; 
lean_dec(x_35);
lean_dec(x_30);
lean_dec(x_29);
lean_dec(x_3);
x_40 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 1, x_34);
lean_ctor_set(x_18, 0, x_40);
return x_18;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; uint8_t x_46; 
x_41 = lean_ctor_get(x_33, 0);
lean_inc(x_41);
lean_dec(x_33);
x_42 = lean_ctor_get(x_29, 0);
lean_inc(x_42);
x_43 = lean_ctor_get(x_29, 1);
lean_inc(x_43);
lean_dec(x_29);
x_44 = lean_ctor_get(x_41, 0);
lean_inc(x_44);
x_45 = lean_ctor_get(x_41, 1);
lean_inc(x_45);
lean_dec(x_41);
x_46 = lean_nat_dec_eq(x_42, x_44);
lean_dec(x_44);
if (x_46 == 0)
{
lean_object* x_47; 
lean_dec(x_45);
lean_dec(x_43);
lean_dec(x_42);
lean_dec(x_35);
lean_dec(x_30);
lean_dec(x_3);
x_47 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_18, 1, x_34);
lean_ctor_set(x_18, 0, x_47);
return x_18;
}
else
{
lean_object* x_48; uint8_t x_49; 
lean_free_object(x_18);
x_48 = lean_apply_3(x_3, x_42, x_43, x_45);
x_49 = lean_unbox(x_48);
lean_dec(x_48);
if (x_49 == 0)
{
lean_object* x_50; 
x_50 = l_BitVec_reduceGetBit___redArg___closed__3;
x_36 = x_50;
goto block_39;
}
else
{
lean_object* x_51; 
x_51 = l_BitVec_reduceGetBit___redArg___closed__6;
x_36 = x_51;
goto block_39;
}
}
}
block_39:
{
lean_object* x_37; lean_object* x_38; 
if (lean_is_scalar(x_30)) {
 x_37 = lean_alloc_ctor(0, 1, 0);
} else {
 x_37 = x_30;
 lean_ctor_set_tag(x_37, 0);
}
lean_ctor_set(x_37, 0, x_36);
if (lean_is_scalar(x_35)) {
 x_38 = lean_alloc_ctor(0, 2, 0);
} else {
 x_38 = x_35;
}
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_34);
return x_38;
}
}
else
{
uint8_t x_52; 
lean_dec(x_30);
lean_dec(x_29);
lean_free_object(x_18);
lean_dec(x_3);
x_52 = !lean_is_exclusive(x_32);
if (x_52 == 0)
{
return x_32;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_53 = lean_ctor_get(x_32, 0);
x_54 = lean_ctor_get(x_32, 1);
lean_inc(x_54);
lean_inc(x_53);
lean_dec(x_32);
x_55 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_55, 0, x_53);
lean_ctor_set(x_55, 1, x_54);
return x_55;
}
}
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_56 = lean_ctor_get(x_18, 1);
lean_inc(x_56);
lean_dec(x_18);
x_57 = lean_ctor_get(x_19, 0);
lean_inc(x_57);
if (lean_is_exclusive(x_19)) {
 lean_ctor_release(x_19, 0);
 x_58 = x_19;
} else {
 lean_dec_ref(x_19);
 x_58 = lean_box(0);
}
x_59 = l_Lean_Expr_appArg_x21(x_4);
x_60 = l_BitVec_fromExpr_x3f___redArg(x_59, x_8, x_9, x_10, x_11, x_56);
if (lean_obj_tag(x_60) == 0)
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_61 = lean_ctor_get(x_60, 0);
lean_inc(x_61);
x_62 = lean_ctor_get(x_60, 1);
lean_inc(x_62);
if (lean_is_exclusive(x_60)) {
 lean_ctor_release(x_60, 0);
 lean_ctor_release(x_60, 1);
 x_63 = x_60;
} else {
 lean_dec_ref(x_60);
 x_63 = lean_box(0);
}
if (lean_obj_tag(x_61) == 0)
{
lean_object* x_68; lean_object* x_69; 
lean_dec(x_63);
lean_dec(x_58);
lean_dec(x_57);
lean_dec(x_3);
x_68 = l_BitVec_reduceUnary___redArg___closed__0;
x_69 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_69, 0, x_68);
lean_ctor_set(x_69, 1, x_62);
return x_69;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; uint8_t x_75; 
x_70 = lean_ctor_get(x_61, 0);
lean_inc(x_70);
lean_dec(x_61);
x_71 = lean_ctor_get(x_57, 0);
lean_inc(x_71);
x_72 = lean_ctor_get(x_57, 1);
lean_inc(x_72);
lean_dec(x_57);
x_73 = lean_ctor_get(x_70, 0);
lean_inc(x_73);
x_74 = lean_ctor_get(x_70, 1);
lean_inc(x_74);
lean_dec(x_70);
x_75 = lean_nat_dec_eq(x_71, x_73);
lean_dec(x_73);
if (x_75 == 0)
{
lean_object* x_76; lean_object* x_77; 
lean_dec(x_74);
lean_dec(x_72);
lean_dec(x_71);
lean_dec(x_63);
lean_dec(x_58);
lean_dec(x_3);
x_76 = l_BitVec_reduceUnary___redArg___closed__0;
x_77 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_77, 0, x_76);
lean_ctor_set(x_77, 1, x_62);
return x_77;
}
else
{
lean_object* x_78; uint8_t x_79; 
x_78 = lean_apply_3(x_3, x_71, x_72, x_74);
x_79 = lean_unbox(x_78);
lean_dec(x_78);
if (x_79 == 0)
{
lean_object* x_80; 
x_80 = l_BitVec_reduceGetBit___redArg___closed__3;
x_64 = x_80;
goto block_67;
}
else
{
lean_object* x_81; 
x_81 = l_BitVec_reduceGetBit___redArg___closed__6;
x_64 = x_81;
goto block_67;
}
}
}
block_67:
{
lean_object* x_65; lean_object* x_66; 
if (lean_is_scalar(x_58)) {
 x_65 = lean_alloc_ctor(0, 1, 0);
} else {
 x_65 = x_58;
 lean_ctor_set_tag(x_65, 0);
}
lean_ctor_set(x_65, 0, x_64);
if (lean_is_scalar(x_63)) {
 x_66 = lean_alloc_ctor(0, 2, 0);
} else {
 x_66 = x_63;
}
lean_ctor_set(x_66, 0, x_65);
lean_ctor_set(x_66, 1, x_62);
return x_66;
}
}
else
{
lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; 
lean_dec(x_58);
lean_dec(x_57);
lean_dec(x_3);
x_82 = lean_ctor_get(x_60, 0);
lean_inc(x_82);
x_83 = lean_ctor_get(x_60, 1);
lean_inc(x_83);
if (lean_is_exclusive(x_60)) {
 lean_ctor_release(x_60, 0);
 lean_ctor_release(x_60, 1);
 x_84 = x_60;
} else {
 lean_dec_ref(x_60);
 x_84 = lean_box(0);
}
if (lean_is_scalar(x_84)) {
 x_85 = lean_alloc_ctor(1, 2, 0);
} else {
 x_85 = x_84;
}
lean_ctor_set(x_85, 0, x_82);
lean_ctor_set(x_85, 1, x_83);
return x_85;
}
}
}
}
else
{
uint8_t x_86; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_3);
x_86 = !lean_is_exclusive(x_18);
if (x_86 == 0)
{
return x_18;
}
else
{
lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_87 = lean_ctor_get(x_18, 0);
x_88 = lean_ctor_get(x_18, 1);
lean_inc(x_88);
lean_inc(x_87);
lean_dec(x_18);
x_89 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_89, 0, x_87);
lean_ctor_set(x_89, 1, x_88);
return x_89;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBoolPred___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_1);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceBoolPred(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l_BitVec_reduceNeg___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Neg", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("neg", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___redArg___closed__1;
x_2 = l_BitVec_reduceNeg___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceNeg___redArg___closed__2;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_13);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_23 = lean_ctor_get(x_14, 0);
x_24 = lean_ctor_get(x_13, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_23, 0);
lean_inc(x_25);
x_26 = lean_ctor_get(x_23, 1);
lean_inc(x_26);
lean_dec(x_23);
x_27 = l_BitVec_neg(x_25, x_26);
lean_dec(x_26);
x_28 = l_BitVec_reduceUnary___redArg___closed__4;
x_29 = l_Lean_mkNatLit(x_25);
x_30 = l_Lean_mkNatLit(x_27);
x_31 = l_Lean_mkAppB(x_28, x_29, x_30);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_31);
return x_13;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_32 = lean_ctor_get(x_14, 0);
x_33 = lean_ctor_get(x_13, 1);
lean_inc(x_33);
lean_dec(x_13);
x_34 = lean_ctor_get(x_32, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_32, 1);
lean_inc(x_35);
lean_dec(x_32);
x_36 = l_BitVec_neg(x_34, x_35);
lean_dec(x_35);
x_37 = l_BitVec_reduceUnary___redArg___closed__4;
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkAppB(x_37, x_38, x_39);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_40);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_14);
lean_ctor_set(x_41, 1, x_33);
return x_41;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_42 = lean_ctor_get(x_14, 0);
lean_inc(x_42);
lean_dec(x_14);
x_43 = lean_ctor_get(x_13, 1);
lean_inc(x_43);
if (lean_is_exclusive(x_13)) {
 lean_ctor_release(x_13, 0);
 lean_ctor_release(x_13, 1);
 x_44 = x_13;
} else {
 lean_dec_ref(x_13);
 x_44 = lean_box(0);
}
x_45 = lean_ctor_get(x_42, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_42, 1);
lean_inc(x_46);
lean_dec(x_42);
x_47 = l_BitVec_neg(x_45, x_46);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
if (lean_is_scalar(x_44)) {
 x_53 = lean_alloc_ctor(0, 2, 0);
} else {
 x_53 = x_44;
}
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
x_54 = !lean_is_exclusive(x_13);
if (x_54 == 0)
{
return x_13;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_13, 0);
x_56 = lean_ctor_get(x_13, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_13);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNeg___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceNeg___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNeg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceNeg", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceNeg___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceUnary___redArg___closed__1;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(1u);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(5u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceNeg___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNeg___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1541_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceNot___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Complement", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("complement", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNot___redArg___closed__1;
x_2 = l_BitVec_reduceNot___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceNot___redArg___closed__2;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_13);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_23 = lean_ctor_get(x_14, 0);
x_24 = lean_ctor_get(x_13, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_23, 0);
lean_inc(x_25);
x_26 = lean_ctor_get(x_23, 1);
lean_inc(x_26);
lean_dec(x_23);
x_27 = l_BitVec_not(x_25, x_26);
lean_dec(x_26);
x_28 = l_BitVec_reduceUnary___redArg___closed__4;
x_29 = l_Lean_mkNatLit(x_25);
x_30 = l_Lean_mkNatLit(x_27);
x_31 = l_Lean_mkAppB(x_28, x_29, x_30);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_31);
return x_13;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_32 = lean_ctor_get(x_14, 0);
x_33 = lean_ctor_get(x_13, 1);
lean_inc(x_33);
lean_dec(x_13);
x_34 = lean_ctor_get(x_32, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_32, 1);
lean_inc(x_35);
lean_dec(x_32);
x_36 = l_BitVec_not(x_34, x_35);
lean_dec(x_35);
x_37 = l_BitVec_reduceUnary___redArg___closed__4;
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkAppB(x_37, x_38, x_39);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_40);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_14);
lean_ctor_set(x_41, 1, x_33);
return x_41;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_42 = lean_ctor_get(x_14, 0);
lean_inc(x_42);
lean_dec(x_14);
x_43 = lean_ctor_get(x_13, 1);
lean_inc(x_43);
if (lean_is_exclusive(x_13)) {
 lean_ctor_release(x_13, 0);
 lean_ctor_release(x_13, 1);
 x_44 = x_13;
} else {
 lean_dec_ref(x_13);
 x_44 = lean_box(0);
}
x_45 = lean_ctor_get(x_42, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_42, 1);
lean_inc(x_46);
lean_dec(x_42);
x_47 = l_BitVec_not(x_45, x_46);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
if (lean_is_scalar(x_44)) {
 x_53 = lean_alloc_ctor(0, 2, 0);
} else {
 x_53 = x_44;
}
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
x_54 = !lean_is_exclusive(x_13);
if (x_54 == 0)
{
return x_13;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_13, 0);
x_56 = lean_ctor_get(x_13, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_13);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNot___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceNot___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNot(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceNot", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceNot___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceNot___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNot___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1578_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceAbs___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("abs", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAbs___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAbs___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceAbs___redArg___closed__1;
x_8 = lean_unsigned_to_nat(2u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_13);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_23 = lean_ctor_get(x_14, 0);
x_24 = lean_ctor_get(x_13, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_23, 0);
lean_inc(x_25);
x_26 = lean_ctor_get(x_23, 1);
lean_inc(x_26);
lean_dec(x_23);
x_27 = l_BitVec_abs(x_25, x_26);
lean_dec(x_26);
x_28 = l_BitVec_reduceUnary___redArg___closed__4;
x_29 = l_Lean_mkNatLit(x_25);
x_30 = l_Lean_mkNatLit(x_27);
x_31 = l_Lean_mkAppB(x_28, x_29, x_30);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_31);
return x_13;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_32 = lean_ctor_get(x_14, 0);
x_33 = lean_ctor_get(x_13, 1);
lean_inc(x_33);
lean_dec(x_13);
x_34 = lean_ctor_get(x_32, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_32, 1);
lean_inc(x_35);
lean_dec(x_32);
x_36 = l_BitVec_abs(x_34, x_35);
lean_dec(x_35);
x_37 = l_BitVec_reduceUnary___redArg___closed__4;
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkAppB(x_37, x_38, x_39);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_40);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_14);
lean_ctor_set(x_41, 1, x_33);
return x_41;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_42 = lean_ctor_get(x_14, 0);
lean_inc(x_42);
lean_dec(x_14);
x_43 = lean_ctor_get(x_13, 1);
lean_inc(x_43);
if (lean_is_exclusive(x_13)) {
 lean_ctor_release(x_13, 0);
 lean_ctor_release(x_13, 1);
 x_44 = x_13;
} else {
 lean_dec_ref(x_13);
 x_44 = lean_box(0);
}
x_45 = lean_ctor_get(x_42, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_42, 1);
lean_inc(x_46);
lean_dec(x_42);
x_47 = l_BitVec_abs(x_45, x_46);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
if (lean_is_scalar(x_44)) {
 x_53 = lean_alloc_ctor(0, 2, 0);
} else {
 x_53 = x_44;
}
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
x_54 = !lean_is_exclusive(x_13);
if (x_54 == 0)
{
return x_13;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_13, 0);
x_56 = lean_ctor_get(x_13, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_13);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAbs___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceAbs___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAbs(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceAbs", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceAbs___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceAbs___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAbs___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1600_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceAnd___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HAnd", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hAnd", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAnd___redArg___closed__1;
x_2 = l_BitVec_reduceAnd___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceAnd___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_land(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_land(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_land(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAnd___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceAnd___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAnd(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceAnd", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceAnd___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(10u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceAnd___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAnd___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceOr___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HOr", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hOr", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOr___redArg___closed__1;
x_2 = l_BitVec_reduceOr___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceOr___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_lor(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_lor(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_lor(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOr___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceOr___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOr(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceOr", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceOr___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceOr___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOr___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1680_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceXOr___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HXor", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hXor", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceXOr___redArg___closed__1;
x_2 = l_BitVec_reduceXOr___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceXOr___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_lxor(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_lxor(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_lxor(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceXOr___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceXOr___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceXOr(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceXOr", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceXOr___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceXOr___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceXOr___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceAdd___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HAdd", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hAdd", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAdd___redArg___closed__1;
x_2 = l_BitVec_reduceAdd___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceAdd___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_add(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_add(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_add(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAdd___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceAdd___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAdd(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceAdd", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceAdd___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceAdd___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAdd___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1760_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceMul___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HMul", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hMul", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMul___redArg___closed__1;
x_2 = l_BitVec_reduceMul___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceMul___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_mul(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_mul(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_mul(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceMul___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceMul___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceMul(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceMul", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceMul___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceMul___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMul___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1800_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSub___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HSub", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hSub", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSub___redArg___closed__1;
x_2 = l_BitVec_reduceSub___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSub___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_sub(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_sub(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_sub(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSub___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSub___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSub(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSub", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceSub___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSub___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSub___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1840_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceDiv___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HDiv", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hDiv", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceDiv___redArg___closed__1;
x_2 = l_BitVec_reduceDiv___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceDiv___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_div(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_div(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_div(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceDiv___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceDiv___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceDiv", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceDiv___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceDiv___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceDiv___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceMod___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HMod", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hMod", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMod___redArg___closed__1;
x_2 = l_BitVec_reduceMod___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceMod___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_mod(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_mod(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_mod(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceMod___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceMod___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceMod(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceMod", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceMod___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceMod___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMod___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUMod___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("umod", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUMod___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUMod___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceUMod___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_mod(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_mod(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_mod(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUMod___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceUMod___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUMod(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceUMod", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceUMod___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceUMod___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUMod___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1947_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("udiv", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUDiv___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceUDiv___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = lean_nat_div(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = lean_nat_div(x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = lean_nat_div(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUDiv___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceUDiv___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceUDiv", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceUDiv___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceUDiv___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUDiv___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1974_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("smtUDiv", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTUDiv___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSMTUDiv___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_smtUDiv(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_smtUDiv(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_smtUDiv(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMTUDiv___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSMTUDiv___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMTUDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSMTUDiv", 13, 13);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSMTUDiv___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSMTUDiv___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTUDiv___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2001_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSMod___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("smod", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMod___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMod___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSMod___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_smod(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_smod(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_smod(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMod___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSMod___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMod(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSMod", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSMod___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSMod___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMod___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2028_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSRem___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("srem", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSRem___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSRem___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSRem___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_srem(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_srem(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_srem(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSRem___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSRem___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSRem(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSRem", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSRem___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSRem___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSRem___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2055_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSDiv___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("sdiv", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSDiv___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSDiv___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSDiv___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_sdiv(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_sdiv(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_sdiv(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSDiv___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSDiv___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSDiv", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSDiv___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSDiv___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSDiv___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2082_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("smtSDiv", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTSDiv___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSMTSDiv___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_26);
if (x_33 == 0)
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_26, 0);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_35, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_37);
lean_free_object(x_26);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_43 = l_BitVec_smtSDiv(x_37, x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__4;
x_45 = l_Lean_mkNatLit(x_37);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_Lean_mkAppB(x_44, x_45, x_46);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_48 = lean_ctor_get(x_26, 0);
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
x_52 = lean_ctor_get(x_48, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = lean_nat_dec_eq(x_50, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; 
lean_dec(x_53);
lean_dec(x_51);
lean_dec(x_50);
lean_free_object(x_26);
x_55 = l_BitVec_reduceUnary___redArg___closed__0;
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_49);
return x_56;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_57 = l_BitVec_smtSDiv(x_50, x_51, x_53);
lean_dec(x_53);
lean_dec(x_51);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_50);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_61);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_26);
lean_ctor_set(x_62, 1, x_49);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_63 = lean_ctor_get(x_26, 0);
lean_inc(x_63);
lean_dec(x_26);
x_64 = lean_ctor_get(x_25, 1);
lean_inc(x_64);
if (lean_is_exclusive(x_25)) {
 lean_ctor_release(x_25, 0);
 lean_ctor_release(x_25, 1);
 x_65 = x_25;
} else {
 lean_dec_ref(x_25);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_23, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_23, 1);
lean_inc(x_67);
lean_dec(x_23);
x_68 = lean_ctor_get(x_63, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_63, 1);
lean_inc(x_69);
lean_dec(x_63);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_65;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_64);
return x_72;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_73 = l_BitVec_smtSDiv(x_66, x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
x_74 = l_BitVec_reduceUnary___redArg___closed__4;
x_75 = l_Lean_mkNatLit(x_66);
x_76 = l_Lean_mkNatLit(x_73);
x_77 = l_Lean_mkAppB(x_74, x_75, x_76);
x_78 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_78, 0, x_77);
if (lean_is_scalar(x_65)) {
 x_79 = lean_alloc_ctor(0, 2, 0);
} else {
 x_79 = x_65;
}
lean_ctor_set(x_79, 0, x_78);
lean_ctor_set(x_79, 1, x_64);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_23);
x_80 = !lean_is_exclusive(x_25);
if (x_80 == 0)
{
return x_25;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_25, 0);
x_82 = lean_ctor_get(x_25, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_25);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
else
{
uint8_t x_84; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_84 = !lean_is_exclusive(x_14);
if (x_84 == 0)
{
return x_14;
}
else
{
lean_object* x_85; lean_object* x_86; lean_object* x_87; 
x_85 = lean_ctor_get(x_14, 0);
x_86 = lean_ctor_get(x_14, 1);
lean_inc(x_86);
lean_inc(x_85);
lean_dec(x_14);
x_87 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_87, 0, x_85);
lean_ctor_set(x_87, 1, x_86);
return x_87;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMTSDiv___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSMTSDiv___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSMTSDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSMTSDiv", 13, 13);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSMTSDiv___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSMTSDiv___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTSDiv___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2109_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("getLsbD", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetLsb___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceGetLsb___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_Lean_Meta_getNatValue_x3f(x_27, x_2, x_3, x_4, x_5, x_23);
lean_dec(x_27);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; uint8_t x_39; 
lean_free_object(x_14);
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 1);
lean_inc(x_38);
lean_dec(x_25);
x_39 = l_Nat_testBit(x_38, x_37);
lean_dec(x_37);
lean_dec(x_38);
if (x_39 == 0)
{
lean_object* x_40; 
x_40 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_40;
goto block_35;
}
else
{
lean_object* x_41; 
x_41 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_41;
goto block_35;
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_42; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_42 = !lean_is_exclusive(x_28);
if (x_42 == 0)
{
return x_28;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_43 = lean_ctor_get(x_28, 0);
x_44 = lean_ctor_get(x_28, 1);
lean_inc(x_44);
lean_inc(x_43);
lean_dec(x_28);
x_45 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_45, 0, x_43);
lean_ctor_set(x_45, 1, x_44);
return x_45;
}
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_46 = lean_ctor_get(x_14, 1);
lean_inc(x_46);
lean_dec(x_14);
x_47 = lean_ctor_get(x_15, 0);
lean_inc(x_47);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_48 = x_15;
} else {
 lean_dec_ref(x_15);
 x_48 = lean_box(0);
}
x_49 = l_Lean_Expr_appArg_x21(x_1);
x_50 = l_Lean_Meta_getNatValue_x3f(x_49, x_2, x_3, x_4, x_5, x_46);
lean_dec(x_49);
if (lean_obj_tag(x_50) == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_50, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 1);
lean_inc(x_52);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_53 = x_50;
} else {
 lean_dec_ref(x_50);
 x_53 = lean_box(0);
}
if (lean_obj_tag(x_51) == 0)
{
lean_object* x_58; lean_object* x_59; 
lean_dec(x_53);
lean_dec(x_48);
lean_dec(x_47);
x_58 = l_BitVec_reduceUnary___redArg___closed__0;
x_59 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_52);
return x_59;
}
else
{
lean_object* x_60; lean_object* x_61; uint8_t x_62; 
x_60 = lean_ctor_get(x_51, 0);
lean_inc(x_60);
lean_dec(x_51);
x_61 = lean_ctor_get(x_47, 1);
lean_inc(x_61);
lean_dec(x_47);
x_62 = l_Nat_testBit(x_61, x_60);
lean_dec(x_60);
lean_dec(x_61);
if (x_62 == 0)
{
lean_object* x_63; 
x_63 = l_BitVec_reduceGetBit___redArg___closed__3;
x_54 = x_63;
goto block_57;
}
else
{
lean_object* x_64; 
x_64 = l_BitVec_reduceGetBit___redArg___closed__6;
x_54 = x_64;
goto block_57;
}
}
block_57:
{
lean_object* x_55; lean_object* x_56; 
if (lean_is_scalar(x_48)) {
 x_55 = lean_alloc_ctor(0, 1, 0);
} else {
 x_55 = x_48;
 lean_ctor_set_tag(x_55, 0);
}
lean_ctor_set(x_55, 0, x_54);
if (lean_is_scalar(x_53)) {
 x_56 = lean_alloc_ctor(0, 2, 0);
} else {
 x_56 = x_53;
}
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_52);
return x_56;
}
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; 
lean_dec(x_48);
lean_dec(x_47);
x_65 = lean_ctor_get(x_50, 0);
lean_inc(x_65);
x_66 = lean_ctor_get(x_50, 1);
lean_inc(x_66);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_67 = x_50;
} else {
 lean_dec_ref(x_50);
 x_67 = lean_box(0);
}
if (lean_is_scalar(x_67)) {
 x_68 = lean_alloc_ctor(1, 2, 0);
} else {
 x_68 = x_67;
}
lean_ctor_set(x_68, 0, x_65);
lean_ctor_set(x_68, 1, x_66);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetLsb___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceGetLsb___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetLsb(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceGetLsb", 12, 12);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceGetLsb___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceGetLsb___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetLsb___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2131_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("getMsbD", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetMsb___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceGetMsb___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_Lean_Meta_getNatValue_x3f(x_27, x_2, x_3, x_4, x_5, x_23);
lean_dec(x_27);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; uint8_t x_36; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_40; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_40 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_40);
return x_14;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_14);
x_41 = lean_ctor_get(x_29, 0);
lean_inc(x_41);
lean_dec(x_29);
x_42 = lean_ctor_get(x_25, 0);
lean_inc(x_42);
x_43 = lean_ctor_get(x_25, 1);
lean_inc(x_43);
lean_dec(x_25);
x_44 = lean_nat_dec_lt(x_41, x_42);
if (x_44 == 0)
{
lean_dec(x_43);
lean_dec(x_42);
lean_dec(x_41);
x_36 = x_44;
goto block_39;
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_45 = lean_unsigned_to_nat(1u);
x_46 = lean_nat_sub(x_42, x_45);
lean_dec(x_42);
x_47 = lean_nat_sub(x_46, x_41);
lean_dec(x_41);
lean_dec(x_46);
x_48 = l_Nat_testBit(x_43, x_47);
lean_dec(x_47);
lean_dec(x_43);
x_36 = x_48;
goto block_39;
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
block_39:
{
if (x_36 == 0)
{
lean_object* x_37; 
x_37 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_37;
goto block_35;
}
else
{
lean_object* x_38; 
x_38 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_38;
goto block_35;
}
}
}
else
{
uint8_t x_49; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_49 = !lean_is_exclusive(x_28);
if (x_49 == 0)
{
return x_28;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_50 = lean_ctor_get(x_28, 0);
x_51 = lean_ctor_get(x_28, 1);
lean_inc(x_51);
lean_inc(x_50);
lean_dec(x_28);
x_52 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_52, 0, x_50);
lean_ctor_set(x_52, 1, x_51);
return x_52;
}
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_53 = lean_ctor_get(x_14, 1);
lean_inc(x_53);
lean_dec(x_14);
x_54 = lean_ctor_get(x_15, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_55 = x_15;
} else {
 lean_dec_ref(x_15);
 x_55 = lean_box(0);
}
x_56 = l_Lean_Expr_appArg_x21(x_1);
x_57 = l_Lean_Meta_getNatValue_x3f(x_56, x_2, x_3, x_4, x_5, x_53);
lean_dec(x_56);
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; uint8_t x_65; 
x_58 = lean_ctor_get(x_57, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_57, 1);
lean_inc(x_59);
if (lean_is_exclusive(x_57)) {
 lean_ctor_release(x_57, 0);
 lean_ctor_release(x_57, 1);
 x_60 = x_57;
} else {
 lean_dec_ref(x_57);
 x_60 = lean_box(0);
}
if (lean_obj_tag(x_58) == 0)
{
lean_object* x_69; lean_object* x_70; 
lean_dec(x_60);
lean_dec(x_55);
lean_dec(x_54);
x_69 = l_BitVec_reduceUnary___redArg___closed__0;
x_70 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_70, 0, x_69);
lean_ctor_set(x_70, 1, x_59);
return x_70;
}
else
{
lean_object* x_71; lean_object* x_72; lean_object* x_73; uint8_t x_74; 
x_71 = lean_ctor_get(x_58, 0);
lean_inc(x_71);
lean_dec(x_58);
x_72 = lean_ctor_get(x_54, 0);
lean_inc(x_72);
x_73 = lean_ctor_get(x_54, 1);
lean_inc(x_73);
lean_dec(x_54);
x_74 = lean_nat_dec_lt(x_71, x_72);
if (x_74 == 0)
{
lean_dec(x_73);
lean_dec(x_72);
lean_dec(x_71);
x_65 = x_74;
goto block_68;
}
else
{
lean_object* x_75; lean_object* x_76; lean_object* x_77; uint8_t x_78; 
x_75 = lean_unsigned_to_nat(1u);
x_76 = lean_nat_sub(x_72, x_75);
lean_dec(x_72);
x_77 = lean_nat_sub(x_76, x_71);
lean_dec(x_71);
lean_dec(x_76);
x_78 = l_Nat_testBit(x_73, x_77);
lean_dec(x_77);
lean_dec(x_73);
x_65 = x_78;
goto block_68;
}
}
block_64:
{
lean_object* x_62; lean_object* x_63; 
if (lean_is_scalar(x_55)) {
 x_62 = lean_alloc_ctor(0, 1, 0);
} else {
 x_62 = x_55;
 lean_ctor_set_tag(x_62, 0);
}
lean_ctor_set(x_62, 0, x_61);
if (lean_is_scalar(x_60)) {
 x_63 = lean_alloc_ctor(0, 2, 0);
} else {
 x_63 = x_60;
}
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_59);
return x_63;
}
block_68:
{
if (x_65 == 0)
{
lean_object* x_66; 
x_66 = l_BitVec_reduceGetBit___redArg___closed__3;
x_61 = x_66;
goto block_64;
}
else
{
lean_object* x_67; 
x_67 = l_BitVec_reduceGetBit___redArg___closed__6;
x_61 = x_67;
goto block_64;
}
}
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; 
lean_dec(x_55);
lean_dec(x_54);
x_79 = lean_ctor_get(x_57, 0);
lean_inc(x_79);
x_80 = lean_ctor_get(x_57, 1);
lean_inc(x_80);
if (lean_is_exclusive(x_57)) {
 lean_ctor_release(x_57, 0);
 lean_ctor_release(x_57, 1);
 x_81 = x_57;
} else {
 lean_dec_ref(x_57);
 x_81 = lean_box(0);
}
if (lean_is_scalar(x_81)) {
 x_82 = lean_alloc_ctor(1, 2, 0);
} else {
 x_82 = x_81;
}
lean_ctor_set(x_82, 0, x_79);
lean_ctor_set(x_82, 1, x_80);
return x_82;
}
}
}
}
else
{
uint8_t x_83; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_83 = !lean_is_exclusive(x_14);
if (x_83 == 0)
{
return x_14;
}
else
{
lean_object* x_84; lean_object* x_85; lean_object* x_86; 
x_84 = lean_ctor_get(x_14, 0);
x_85 = lean_ctor_get(x_14, 1);
lean_inc(x_85);
lean_inc(x_84);
lean_dec(x_14);
x_86 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_86, 0, x_84);
lean_ctor_set(x_86, 1, x_85);
return x_86;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetMsb___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceGetMsb___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetMsb(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceGetMsb", 12, 12);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceGetMsb___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceGetMsb___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetMsb___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2153_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceClz___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("clz", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceClz___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceClz___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceClz___redArg___closed__1;
x_8 = lean_unsigned_to_nat(2u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_13);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_23 = lean_ctor_get(x_14, 0);
x_24 = lean_ctor_get(x_13, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_23, 0);
lean_inc(x_25);
x_26 = lean_ctor_get(x_23, 1);
lean_inc(x_26);
lean_dec(x_23);
x_27 = l_BitVec_clz(x_25, x_26);
lean_dec(x_26);
x_28 = l_BitVec_reduceUnary___redArg___closed__4;
x_29 = l_Lean_mkNatLit(x_25);
x_30 = l_Lean_mkNatLit(x_27);
x_31 = l_Lean_mkAppB(x_28, x_29, x_30);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_31);
return x_13;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_32 = lean_ctor_get(x_14, 0);
x_33 = lean_ctor_get(x_13, 1);
lean_inc(x_33);
lean_dec(x_13);
x_34 = lean_ctor_get(x_32, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_32, 1);
lean_inc(x_35);
lean_dec(x_32);
x_36 = l_BitVec_clz(x_34, x_35);
lean_dec(x_35);
x_37 = l_BitVec_reduceUnary___redArg___closed__4;
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkAppB(x_37, x_38, x_39);
lean_ctor_set_tag(x_14, 0);
lean_ctor_set(x_14, 0, x_40);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_14);
lean_ctor_set(x_41, 1, x_33);
return x_41;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_42 = lean_ctor_get(x_14, 0);
lean_inc(x_42);
lean_dec(x_14);
x_43 = lean_ctor_get(x_13, 1);
lean_inc(x_43);
if (lean_is_exclusive(x_13)) {
 lean_ctor_release(x_13, 0);
 lean_ctor_release(x_13, 1);
 x_44 = x_13;
} else {
 lean_dec_ref(x_13);
 x_44 = lean_box(0);
}
x_45 = lean_ctor_get(x_42, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_42, 1);
lean_inc(x_46);
lean_dec(x_42);
x_47 = l_BitVec_clz(x_45, x_46);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
if (lean_is_scalar(x_44)) {
 x_53 = lean_alloc_ctor(0, 2, 0);
} else {
 x_53 = x_44;
}
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
x_54 = !lean_is_exclusive(x_13);
if (x_54 == 0)
{
return x_13;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_13, 0);
x_56 = lean_ctor_get(x_13, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_13);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceClz___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceClz___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceClz(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceClz", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceClz___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceClz___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceClz___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2175_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceGetElem___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("GetElem", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetElem___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("getElem", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetElem___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetElem___redArg___closed__1;
x_2 = l_BitVec_reduceGetElem___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_11; uint8_t x_12; 
x_11 = l_Lean_Expr_cleanupAnnotations(x_1);
x_12 = l_Lean_Expr_isApp(x_11);
if (x_12 == 0)
{
lean_dec(x_11);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_13; uint8_t x_14; 
x_13 = l_Lean_Expr_appFnCleanup___redArg(x_11);
x_14 = l_Lean_Expr_isApp(x_13);
if (x_14 == 0)
{
lean_dec(x_13);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_15; lean_object* x_16; uint8_t x_17; 
x_15 = lean_ctor_get(x_13, 1);
lean_inc(x_15);
x_16 = l_Lean_Expr_appFnCleanup___redArg(x_13);
x_17 = l_Lean_Expr_isApp(x_16);
if (x_17 == 0)
{
lean_dec(x_16);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_18; lean_object* x_19; uint8_t x_20; 
x_18 = lean_ctor_get(x_16, 1);
lean_inc(x_18);
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_16);
x_20 = l_Lean_Expr_isApp(x_19);
if (x_20 == 0)
{
lean_dec(x_19);
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_21; uint8_t x_22; 
x_21 = l_Lean_Expr_appFnCleanup___redArg(x_19);
x_22 = l_Lean_Expr_isApp(x_21);
if (x_22 == 0)
{
lean_dec(x_21);
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_23; uint8_t x_24; 
x_23 = l_Lean_Expr_appFnCleanup___redArg(x_21);
x_24 = l_Lean_Expr_isApp(x_23);
if (x_24 == 0)
{
lean_dec(x_23);
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_25; uint8_t x_26; 
x_25 = l_Lean_Expr_appFnCleanup___redArg(x_23);
x_26 = l_Lean_Expr_isApp(x_25);
if (x_26 == 0)
{
lean_dec(x_25);
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_27; uint8_t x_28; 
x_27 = l_Lean_Expr_appFnCleanup___redArg(x_25);
x_28 = l_Lean_Expr_isApp(x_27);
if (x_28 == 0)
{
lean_dec(x_27);
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_29; lean_object* x_30; uint8_t x_31; 
x_29 = l_Lean_Expr_appFnCleanup___redArg(x_27);
x_30 = l_BitVec_reduceGetElem___redArg___closed__2;
x_31 = l_Lean_Expr_isConstOf(x_29, x_30);
lean_dec(x_29);
if (x_31 == 0)
{
lean_dec(x_18);
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_7 = x_6;
goto block_10;
}
else
{
lean_object* x_32; 
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_32 = l_BitVec_fromExpr_x3f___redArg(x_18, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_32) == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
if (lean_obj_tag(x_33) == 0)
{
uint8_t x_34; 
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_34 = !lean_is_exclusive(x_32);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; 
x_35 = lean_ctor_get(x_32, 0);
lean_dec(x_35);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_32, 0, x_36);
return x_32;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_37 = lean_ctor_get(x_32, 1);
lean_inc(x_37);
lean_dec(x_32);
x_38 = l_BitVec_reduceUnary___redArg___closed__0;
x_39 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_39, 0, x_38);
lean_ctor_set(x_39, 1, x_37);
return x_39;
}
}
else
{
uint8_t x_40; 
x_40 = !lean_is_exclusive(x_32);
if (x_40 == 0)
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_41 = lean_ctor_get(x_32, 1);
x_42 = lean_ctor_get(x_32, 0);
lean_dec(x_42);
x_43 = lean_ctor_get(x_33, 0);
lean_inc(x_43);
if (lean_is_exclusive(x_33)) {
 lean_ctor_release(x_33, 0);
 x_44 = x_33;
} else {
 lean_dec_ref(x_33);
 x_44 = lean_box(0);
}
x_45 = l_Lean_Meta_getNatValue_x3f(x_15, x_2, x_3, x_4, x_5, x_41);
lean_dec(x_15);
if (lean_obj_tag(x_45) == 0)
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_46 = lean_ctor_get(x_45, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 1);
lean_inc(x_47);
if (lean_is_exclusive(x_45)) {
 lean_ctor_release(x_45, 0);
 lean_ctor_release(x_45, 1);
 x_48 = x_45;
} else {
 lean_dec_ref(x_45);
 x_48 = lean_box(0);
}
if (lean_obj_tag(x_46) == 0)
{
lean_object* x_53; 
lean_dec(x_48);
lean_dec(x_44);
lean_dec(x_43);
x_53 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_32, 1, x_47);
lean_ctor_set(x_32, 0, x_53);
return x_32;
}
else
{
lean_object* x_54; lean_object* x_55; uint8_t x_56; 
lean_free_object(x_32);
x_54 = lean_ctor_get(x_46, 0);
lean_inc(x_54);
lean_dec(x_46);
x_55 = lean_ctor_get(x_43, 1);
lean_inc(x_55);
lean_dec(x_43);
x_56 = l_Nat_testBit(x_55, x_54);
lean_dec(x_54);
lean_dec(x_55);
if (x_56 == 0)
{
lean_object* x_57; 
x_57 = l_BitVec_reduceGetBit___redArg___closed__3;
x_49 = x_57;
goto block_52;
}
else
{
lean_object* x_58; 
x_58 = l_BitVec_reduceGetBit___redArg___closed__6;
x_49 = x_58;
goto block_52;
}
}
block_52:
{
lean_object* x_50; lean_object* x_51; 
if (lean_is_scalar(x_44)) {
 x_50 = lean_alloc_ctor(0, 1, 0);
} else {
 x_50 = x_44;
 lean_ctor_set_tag(x_50, 0);
}
lean_ctor_set(x_50, 0, x_49);
if (lean_is_scalar(x_48)) {
 x_51 = lean_alloc_ctor(0, 2, 0);
} else {
 x_51 = x_48;
}
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_47);
return x_51;
}
}
else
{
uint8_t x_59; 
lean_dec(x_44);
lean_dec(x_43);
lean_free_object(x_32);
x_59 = !lean_is_exclusive(x_45);
if (x_59 == 0)
{
return x_45;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_45, 0);
x_61 = lean_ctor_get(x_45, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_45);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_63 = lean_ctor_get(x_32, 1);
lean_inc(x_63);
lean_dec(x_32);
x_64 = lean_ctor_get(x_33, 0);
lean_inc(x_64);
if (lean_is_exclusive(x_33)) {
 lean_ctor_release(x_33, 0);
 x_65 = x_33;
} else {
 lean_dec_ref(x_33);
 x_65 = lean_box(0);
}
x_66 = l_Lean_Meta_getNatValue_x3f(x_15, x_2, x_3, x_4, x_5, x_63);
lean_dec(x_15);
if (lean_obj_tag(x_66) == 0)
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_67 = lean_ctor_get(x_66, 0);
lean_inc(x_67);
x_68 = lean_ctor_get(x_66, 1);
lean_inc(x_68);
if (lean_is_exclusive(x_66)) {
 lean_ctor_release(x_66, 0);
 lean_ctor_release(x_66, 1);
 x_69 = x_66;
} else {
 lean_dec_ref(x_66);
 x_69 = lean_box(0);
}
if (lean_obj_tag(x_67) == 0)
{
lean_object* x_74; lean_object* x_75; 
lean_dec(x_69);
lean_dec(x_65);
lean_dec(x_64);
x_74 = l_BitVec_reduceUnary___redArg___closed__0;
x_75 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_75, 0, x_74);
lean_ctor_set(x_75, 1, x_68);
return x_75;
}
else
{
lean_object* x_76; lean_object* x_77; uint8_t x_78; 
x_76 = lean_ctor_get(x_67, 0);
lean_inc(x_76);
lean_dec(x_67);
x_77 = lean_ctor_get(x_64, 1);
lean_inc(x_77);
lean_dec(x_64);
x_78 = l_Nat_testBit(x_77, x_76);
lean_dec(x_76);
lean_dec(x_77);
if (x_78 == 0)
{
lean_object* x_79; 
x_79 = l_BitVec_reduceGetBit___redArg___closed__3;
x_70 = x_79;
goto block_73;
}
else
{
lean_object* x_80; 
x_80 = l_BitVec_reduceGetBit___redArg___closed__6;
x_70 = x_80;
goto block_73;
}
}
block_73:
{
lean_object* x_71; lean_object* x_72; 
if (lean_is_scalar(x_65)) {
 x_71 = lean_alloc_ctor(0, 1, 0);
} else {
 x_71 = x_65;
 lean_ctor_set_tag(x_71, 0);
}
lean_ctor_set(x_71, 0, x_70);
if (lean_is_scalar(x_69)) {
 x_72 = lean_alloc_ctor(0, 2, 0);
} else {
 x_72 = x_69;
}
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_68);
return x_72;
}
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; 
lean_dec(x_65);
lean_dec(x_64);
x_81 = lean_ctor_get(x_66, 0);
lean_inc(x_81);
x_82 = lean_ctor_get(x_66, 1);
lean_inc(x_82);
if (lean_is_exclusive(x_66)) {
 lean_ctor_release(x_66, 0);
 lean_ctor_release(x_66, 1);
 x_83 = x_66;
} else {
 lean_dec_ref(x_66);
 x_83 = lean_box(0);
}
if (lean_is_scalar(x_83)) {
 x_84 = lean_alloc_ctor(1, 2, 0);
} else {
 x_84 = x_83;
}
lean_ctor_set(x_84, 0, x_81);
lean_ctor_set(x_84, 1, x_82);
return x_84;
}
}
}
}
else
{
uint8_t x_85; 
lean_dec(x_15);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_85 = !lean_is_exclusive(x_32);
if (x_85 == 0)
{
return x_32;
}
else
{
lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_86 = lean_ctor_get(x_32, 0);
x_87 = lean_ctor_get(x_32, 1);
lean_inc(x_87);
lean_inc(x_86);
lean_dec(x_32);
x_88 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_88, 0, x_86);
lean_ctor_set(x_88, 1, x_87);
return x_88;
}
}
}
}
}
}
}
}
}
}
}
block_10:
{
lean_object* x_8; lean_object* x_9; 
x_8 = l_BitVec_reduceUnary___redArg___closed__0;
x_9 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_9, 0, x_8);
lean_ctor_set(x_9, 1, x_7);
return x_9;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetElem___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGetElem(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceGetElem", 13, 13);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(8u);
x_2 = l_BitVec_reduceGetElem___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceGetElem___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetElem___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2642_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("shiftLeft", 9, 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeft___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceShiftLeft___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = l_BitVec_shiftLeft(x_37, x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = l_BitVec_shiftLeft(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = l_BitVec_shiftLeft(x_56, x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeft___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceShiftLeft___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceShiftLeft", 15, 15);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceShiftLeft___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeft___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeft___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2665_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ushiftRight", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUShiftRight___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceUShiftRight___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_nat_shiftr(x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = lean_nat_shiftr(x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = lean_nat_shiftr(x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUShiftRight___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceUShiftRight___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceUShiftRight", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceUShiftRight___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceUShiftRight___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUShiftRight___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2688_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("sshiftRight", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSShiftRight___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSShiftRight___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = l_BitVec_sshiftRight(x_37, x_38, x_36);
lean_dec(x_36);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = l_BitVec_sshiftRight(x_45, x_46, x_44);
lean_dec(x_44);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = l_BitVec_sshiftRight(x_56, x_57, x_54);
lean_dec(x_54);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSShiftRight___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSShiftRight___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSShiftRight", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSShiftRight___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSShiftRight___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSShiftRight___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2711_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HShiftLeft", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hShiftLeft", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftLeft___redArg___closed__1;
x_2 = l_BitVec_reduceHShiftLeft___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftLeft___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = l_BitVec_shiftLeft(x_37, x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = l_BitVec_shiftLeft(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = l_BitVec_shiftLeft(x_56, x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceHShiftLeft___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceHShiftLeft", 16, 16);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceHShiftLeft___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(8u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2751_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftLeft___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_22 = lean_ctor_get(x_14, 0);
x_23 = lean_ctor_get(x_13, 1);
lean_inc(x_23);
lean_dec(x_13);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_Lean_Expr_appFn_x21(x_1);
x_26 = l_Lean_Expr_appArg_x21(x_25);
lean_dec(x_25);
x_27 = l_Lean_mkNatLit(x_24);
x_28 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_29 = lean_array_push(x_28, x_26);
x_30 = lean_array_push(x_29, x_27);
x_31 = l_Lean_Meta_mkAppM(x_7, x_30, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_31) == 0)
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_31);
if (x_32 == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_31, 0);
lean_ctor_set(x_14, 0, x_33);
lean_ctor_set(x_31, 0, x_14);
return x_31;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_31, 0);
x_35 = lean_ctor_get(x_31, 1);
lean_inc(x_35);
lean_inc(x_34);
lean_dec(x_31);
lean_ctor_set(x_14, 0, x_34);
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_14);
lean_ctor_set(x_36, 1, x_35);
return x_36;
}
}
else
{
uint8_t x_37; 
lean_free_object(x_14);
x_37 = !lean_is_exclusive(x_31);
if (x_37 == 0)
{
return x_31;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_31, 0);
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_inc(x_38);
lean_dec(x_31);
x_40 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_40, 0, x_38);
lean_ctor_set(x_40, 1, x_39);
return x_40;
}
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_41 = lean_ctor_get(x_14, 0);
lean_inc(x_41);
lean_dec(x_14);
x_42 = lean_ctor_get(x_13, 1);
lean_inc(x_42);
lean_dec(x_13);
x_43 = lean_ctor_get(x_41, 1);
lean_inc(x_43);
lean_dec(x_41);
x_44 = l_Lean_Expr_appFn_x21(x_1);
x_45 = l_Lean_Expr_appArg_x21(x_44);
lean_dec(x_44);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_48 = lean_array_push(x_47, x_45);
x_49 = lean_array_push(x_48, x_46);
x_50 = l_Lean_Meta_mkAppM(x_7, x_49, x_2, x_3, x_4, x_5, x_42);
if (lean_obj_tag(x_50) == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_50, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 1);
lean_inc(x_52);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_53 = x_50;
} else {
 lean_dec_ref(x_50);
 x_53 = lean_box(0);
}
x_54 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_54, 0, x_51);
if (lean_is_scalar(x_53)) {
 x_55 = lean_alloc_ctor(0, 2, 0);
} else {
 x_55 = x_53;
}
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_52);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_50, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_50, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_58 = x_50;
} else {
 lean_dec_ref(x_50);
 x_58 = lean_box(0);
}
if (lean_is_scalar(x_58)) {
 x_59 = lean_alloc_ctor(1, 2, 0);
} else {
 x_59 = x_58;
}
lean_ctor_set(x_59, 0, x_56);
lean_ctor_set(x_59, 1, x_57);
return x_59;
}
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_60 = !lean_is_exclusive(x_13);
if (x_60 == 0)
{
return x_13;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_13, 0);
x_62 = lean_ctor_get(x_13, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_13);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft_x27___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceHShiftLeft_x27___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft_x27(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceHShiftLeft'", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(9u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft_x27___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft_x27___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2781_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HShiftRight", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hShiftRight", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftRight___redArg___closed__1;
x_2 = l_BitVec_reduceHShiftRight___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftRight___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_nat_shiftr(x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = lean_nat_shiftr(x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = lean_nat_shiftr(x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceHShiftRight___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceHShiftRight", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceHShiftRight___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2821_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftRight___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_14);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_22 = lean_ctor_get(x_14, 0);
x_23 = lean_ctor_get(x_13, 1);
lean_inc(x_23);
lean_dec(x_13);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_Lean_Expr_appFn_x21(x_1);
x_26 = l_Lean_Expr_appArg_x21(x_25);
lean_dec(x_25);
x_27 = l_Lean_mkNatLit(x_24);
x_28 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_29 = lean_array_push(x_28, x_26);
x_30 = lean_array_push(x_29, x_27);
x_31 = l_Lean_Meta_mkAppM(x_7, x_30, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_31) == 0)
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_31);
if (x_32 == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_31, 0);
lean_ctor_set(x_14, 0, x_33);
lean_ctor_set(x_31, 0, x_14);
return x_31;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = lean_ctor_get(x_31, 0);
x_35 = lean_ctor_get(x_31, 1);
lean_inc(x_35);
lean_inc(x_34);
lean_dec(x_31);
lean_ctor_set(x_14, 0, x_34);
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_14);
lean_ctor_set(x_36, 1, x_35);
return x_36;
}
}
else
{
uint8_t x_37; 
lean_free_object(x_14);
x_37 = !lean_is_exclusive(x_31);
if (x_37 == 0)
{
return x_31;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_31, 0);
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_inc(x_38);
lean_dec(x_31);
x_40 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_40, 0, x_38);
lean_ctor_set(x_40, 1, x_39);
return x_40;
}
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_41 = lean_ctor_get(x_14, 0);
lean_inc(x_41);
lean_dec(x_14);
x_42 = lean_ctor_get(x_13, 1);
lean_inc(x_42);
lean_dec(x_13);
x_43 = lean_ctor_get(x_41, 1);
lean_inc(x_43);
lean_dec(x_41);
x_44 = l_Lean_Expr_appFn_x21(x_1);
x_45 = l_Lean_Expr_appArg_x21(x_44);
lean_dec(x_44);
x_46 = l_Lean_mkNatLit(x_43);
x_47 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
x_48 = lean_array_push(x_47, x_45);
x_49 = lean_array_push(x_48, x_46);
x_50 = l_Lean_Meta_mkAppM(x_7, x_49, x_2, x_3, x_4, x_5, x_42);
if (lean_obj_tag(x_50) == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_50, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 1);
lean_inc(x_52);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_53 = x_50;
} else {
 lean_dec_ref(x_50);
 x_53 = lean_box(0);
}
x_54 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_54, 0, x_51);
if (lean_is_scalar(x_53)) {
 x_55 = lean_alloc_ctor(0, 2, 0);
} else {
 x_55 = x_53;
}
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_52);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_50, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_50, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_50)) {
 lean_ctor_release(x_50, 0);
 lean_ctor_release(x_50, 1);
 x_58 = x_50;
} else {
 lean_dec_ref(x_50);
 x_58 = lean_box(0);
}
if (lean_is_scalar(x_58)) {
 x_59 = lean_alloc_ctor(1, 2, 0);
} else {
 x_59 = x_58;
}
lean_ctor_set(x_59, 0, x_56);
lean_ctor_set(x_59, 1, x_57);
return x_59;
}
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_60 = !lean_is_exclusive(x_13);
if (x_60 == 0)
{
return x_13;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_13, 0);
x_62 = lean_ctor_get(x_13, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_13);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight_x27___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceHShiftRight_x27___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight_x27(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceHShiftRight'", 18, 18);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight_x27___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight_x27___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2851_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("rotateLeft", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateLeft___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceRotateLeft___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = l_BitVec_rotateLeft(x_37, x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = l_BitVec_rotateLeft(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = l_BitVec_rotateLeft(x_56, x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceRotateLeft___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceRotateLeft___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceRotateLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceRotateLeft", 16, 16);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceRotateLeft___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceRotateLeft___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateLeft___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("rotateRight", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateRight___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceRotateRight___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = l_BitVec_rotateRight(x_37, x_38, x_36);
lean_dec(x_36);
lean_dec(x_38);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_23, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_23, 1);
lean_inc(x_46);
lean_dec(x_23);
x_47 = l_BitVec_rotateRight(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_23, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_23, 1);
lean_inc(x_57);
lean_dec(x_23);
x_58 = l_BitVec_rotateRight(x_56, x_57, x_54);
lean_dec(x_54);
lean_dec(x_57);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_56);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_23);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_14);
if (x_69 == 0)
{
return x_14;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_14, 0);
x_71 = lean_ctor_get(x_14, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_14);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceRotateRight___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceRotateRight___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceRotateRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceRotateRight", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceRotateRight___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceRotateRight___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateRight___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2897_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceAppend___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("HAppend", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("hAppend", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAppend___redArg___closed__1;
x_2 = l_BitVec_reduceAppend___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_dec(x_20);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; uint8_t x_23; 
x_22 = l_Lean_Expr_appFnCleanup___redArg(x_20);
x_23 = l_Lean_Expr_isApp(x_22);
if (x_23 == 0)
{
lean_dec(x_22);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_24; uint8_t x_25; 
x_24 = l_Lean_Expr_appFnCleanup___redArg(x_22);
x_25 = l_Lean_Expr_isApp(x_24);
if (x_25 == 0)
{
lean_dec(x_24);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_26; uint8_t x_27; 
x_26 = l_Lean_Expr_appFnCleanup___redArg(x_24);
x_27 = l_Lean_Expr_isApp(x_26);
if (x_27 == 0)
{
lean_dec(x_26);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_28; lean_object* x_29; uint8_t x_30; 
x_28 = l_Lean_Expr_appFnCleanup___redArg(x_26);
x_29 = l_BitVec_reduceAppend___redArg___closed__2;
x_30 = l_Lean_Expr_isConstOf(x_28, x_29);
lean_dec(x_28);
if (x_30 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_31; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_31 = l_BitVec_fromExpr_x3f___redArg(x_19, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_31) == 0)
{
lean_object* x_32; 
x_32 = lean_ctor_get(x_31, 0);
lean_inc(x_32);
if (lean_obj_tag(x_32) == 0)
{
uint8_t x_33; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_33 = !lean_is_exclusive(x_31);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; 
x_34 = lean_ctor_get(x_31, 0);
lean_dec(x_34);
x_35 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_31, 0, x_35);
return x_31;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_36 = lean_ctor_get(x_31, 1);
lean_inc(x_36);
lean_dec(x_31);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
x_38 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_36);
return x_38;
}
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_dec(x_31);
x_40 = lean_ctor_get(x_32, 0);
lean_inc(x_40);
lean_dec(x_32);
x_41 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_39);
if (lean_obj_tag(x_41) == 0)
{
lean_object* x_42; 
x_42 = lean_ctor_get(x_41, 0);
lean_inc(x_42);
if (lean_obj_tag(x_42) == 0)
{
uint8_t x_43; 
lean_dec(x_40);
x_43 = !lean_is_exclusive(x_41);
if (x_43 == 0)
{
lean_object* x_44; lean_object* x_45; 
x_44 = lean_ctor_get(x_41, 0);
lean_dec(x_44);
x_45 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_41, 0, x_45);
return x_41;
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; 
x_46 = lean_ctor_get(x_41, 1);
lean_inc(x_46);
lean_dec(x_41);
x_47 = l_BitVec_reduceUnary___redArg___closed__0;
x_48 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_48, 0, x_47);
lean_ctor_set(x_48, 1, x_46);
return x_48;
}
}
else
{
uint8_t x_49; 
x_49 = !lean_is_exclusive(x_42);
if (x_49 == 0)
{
uint8_t x_50; 
x_50 = !lean_is_exclusive(x_41);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_51 = lean_ctor_get(x_42, 0);
x_52 = lean_ctor_get(x_41, 0);
lean_dec(x_52);
x_53 = lean_ctor_get(x_40, 0);
lean_inc(x_53);
x_54 = lean_ctor_get(x_40, 1);
lean_inc(x_54);
lean_dec(x_40);
x_55 = lean_ctor_get(x_51, 0);
lean_inc(x_55);
x_56 = lean_ctor_get(x_51, 1);
lean_inc(x_56);
lean_dec(x_51);
x_57 = lean_nat_add(x_53, x_55);
lean_dec(x_53);
x_58 = l_BitVec_append___redArg(x_55, x_54, x_56);
lean_dec(x_56);
lean_dec(x_54);
lean_dec(x_55);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
lean_ctor_set_tag(x_42, 0);
lean_ctor_set(x_42, 0, x_62);
return x_41;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_63 = lean_ctor_get(x_42, 0);
x_64 = lean_ctor_get(x_41, 1);
lean_inc(x_64);
lean_dec(x_41);
x_65 = lean_ctor_get(x_40, 0);
lean_inc(x_65);
x_66 = lean_ctor_get(x_40, 1);
lean_inc(x_66);
lean_dec(x_40);
x_67 = lean_ctor_get(x_63, 0);
lean_inc(x_67);
x_68 = lean_ctor_get(x_63, 1);
lean_inc(x_68);
lean_dec(x_63);
x_69 = lean_nat_add(x_65, x_67);
lean_dec(x_65);
x_70 = l_BitVec_append___redArg(x_67, x_66, x_68);
lean_dec(x_68);
lean_dec(x_66);
lean_dec(x_67);
x_71 = l_BitVec_reduceUnary___redArg___closed__4;
x_72 = l_Lean_mkNatLit(x_69);
x_73 = l_Lean_mkNatLit(x_70);
x_74 = l_Lean_mkAppB(x_71, x_72, x_73);
lean_ctor_set_tag(x_42, 0);
lean_ctor_set(x_42, 0, x_74);
x_75 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_75, 0, x_42);
lean_ctor_set(x_75, 1, x_64);
return x_75;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; lean_object* x_90; 
x_76 = lean_ctor_get(x_42, 0);
lean_inc(x_76);
lean_dec(x_42);
x_77 = lean_ctor_get(x_41, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_41)) {
 lean_ctor_release(x_41, 0);
 lean_ctor_release(x_41, 1);
 x_78 = x_41;
} else {
 lean_dec_ref(x_41);
 x_78 = lean_box(0);
}
x_79 = lean_ctor_get(x_40, 0);
lean_inc(x_79);
x_80 = lean_ctor_get(x_40, 1);
lean_inc(x_80);
lean_dec(x_40);
x_81 = lean_ctor_get(x_76, 0);
lean_inc(x_81);
x_82 = lean_ctor_get(x_76, 1);
lean_inc(x_82);
lean_dec(x_76);
x_83 = lean_nat_add(x_79, x_81);
lean_dec(x_79);
x_84 = l_BitVec_append___redArg(x_81, x_80, x_82);
lean_dec(x_82);
lean_dec(x_80);
lean_dec(x_81);
x_85 = l_BitVec_reduceUnary___redArg___closed__4;
x_86 = l_Lean_mkNatLit(x_83);
x_87 = l_Lean_mkNatLit(x_84);
x_88 = l_Lean_mkAppB(x_85, x_86, x_87);
x_89 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_89, 0, x_88);
if (lean_is_scalar(x_78)) {
 x_90 = lean_alloc_ctor(0, 2, 0);
} else {
 x_90 = x_78;
}
lean_ctor_set(x_90, 0, x_89);
lean_ctor_set(x_90, 1, x_77);
return x_90;
}
}
}
else
{
uint8_t x_91; 
lean_dec(x_40);
x_91 = !lean_is_exclusive(x_41);
if (x_91 == 0)
{
return x_41;
}
else
{
lean_object* x_92; lean_object* x_93; lean_object* x_94; 
x_92 = lean_ctor_get(x_41, 0);
x_93 = lean_ctor_get(x_41, 1);
lean_inc(x_93);
lean_inc(x_92);
lean_dec(x_41);
x_94 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_94, 0, x_92);
lean_ctor_set(x_94, 1, x_93);
return x_94;
}
}
}
}
else
{
uint8_t x_95; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_95 = !lean_is_exclusive(x_31);
if (x_95 == 0)
{
return x_31;
}
else
{
lean_object* x_96; lean_object* x_97; lean_object* x_98; 
x_96 = lean_ctor_get(x_31, 0);
x_97 = lean_ctor_get(x_31, 1);
lean_inc(x_97);
lean_inc(x_96);
lean_dec(x_31);
x_98 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_98, 0, x_96);
lean_ctor_set(x_98, 1, x_97);
return x_98;
}
}
}
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAppend___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAppend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceAppend", 12, 12);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = l_BitVec_reduceAppend___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceAppend___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAppend___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3264_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceCast___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("cast", 4, 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceCast___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceCast___redArg___closed__0;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; uint8_t x_20; 
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_20 = l_Lean_Expr_isApp(x_19);
if (x_20 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_21; lean_object* x_22; uint8_t x_23; 
x_21 = lean_ctor_get(x_19, 1);
lean_inc(x_21);
x_22 = l_Lean_Expr_appFnCleanup___redArg(x_19);
x_23 = l_Lean_Expr_isApp(x_22);
if (x_23 == 0)
{
lean_dec(x_22);
lean_dec(x_21);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appFnCleanup___redArg(x_22);
x_25 = l_BitVec_reduceCast___redArg___closed__1;
x_26 = l_Lean_Expr_isConstOf(x_24, x_25);
lean_dec(x_24);
if (x_26 == 0)
{
lean_dec(x_21);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_27; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_27 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_27) == 0)
{
lean_object* x_28; 
x_28 = lean_ctor_get(x_27, 0);
lean_inc(x_28);
if (lean_obj_tag(x_28) == 0)
{
uint8_t x_29; 
lean_dec(x_21);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_29 = !lean_is_exclusive(x_27);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; 
x_30 = lean_ctor_get(x_27, 0);
lean_dec(x_30);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_27, 0, x_31);
return x_27;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; 
x_32 = lean_ctor_get(x_27, 1);
lean_inc(x_32);
lean_dec(x_27);
x_33 = l_BitVec_reduceUnary___redArg___closed__0;
x_34 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_32);
return x_34;
}
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; 
x_35 = lean_ctor_get(x_27, 1);
lean_inc(x_35);
lean_dec(x_27);
x_36 = lean_ctor_get(x_28, 0);
lean_inc(x_36);
lean_dec(x_28);
x_37 = l_Lean_Meta_getNatValue_x3f(x_21, x_2, x_3, x_4, x_5, x_35);
lean_dec(x_21);
if (lean_obj_tag(x_37) == 0)
{
lean_object* x_38; 
x_38 = lean_ctor_get(x_37, 0);
lean_inc(x_38);
if (lean_obj_tag(x_38) == 0)
{
uint8_t x_39; 
lean_dec(x_36);
x_39 = !lean_is_exclusive(x_37);
if (x_39 == 0)
{
lean_object* x_40; lean_object* x_41; 
x_40 = lean_ctor_get(x_37, 0);
lean_dec(x_40);
x_41 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_37, 0, x_41);
return x_37;
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; 
x_42 = lean_ctor_get(x_37, 1);
lean_inc(x_42);
lean_dec(x_37);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
x_44 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_44, 1, x_42);
return x_44;
}
}
else
{
uint8_t x_45; 
x_45 = !lean_is_exclusive(x_37);
if (x_45 == 0)
{
lean_object* x_46; uint8_t x_47; 
x_46 = lean_ctor_get(x_37, 0);
lean_dec(x_46);
x_47 = !lean_is_exclusive(x_38);
if (x_47 == 0)
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_48 = lean_ctor_get(x_38, 0);
x_49 = lean_ctor_get(x_36, 1);
lean_inc(x_49);
lean_dec(x_36);
x_50 = l_BitVec_ofNat(x_48, x_49);
lean_dec(x_49);
x_51 = l_BitVec_reduceUnary___redArg___closed__4;
x_52 = l_Lean_mkNatLit(x_48);
x_53 = l_Lean_mkNatLit(x_50);
x_54 = l_Lean_mkAppB(x_51, x_52, x_53);
lean_ctor_set_tag(x_38, 0);
lean_ctor_set(x_38, 0, x_54);
return x_37;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_55 = lean_ctor_get(x_38, 0);
lean_inc(x_55);
lean_dec(x_38);
x_56 = lean_ctor_get(x_36, 1);
lean_inc(x_56);
lean_dec(x_36);
x_57 = l_BitVec_ofNat(x_55, x_56);
lean_dec(x_56);
x_58 = l_BitVec_reduceUnary___redArg___closed__4;
x_59 = l_Lean_mkNatLit(x_55);
x_60 = l_Lean_mkNatLit(x_57);
x_61 = l_Lean_mkAppB(x_58, x_59, x_60);
x_62 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_37, 0, x_62);
return x_37;
}
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; 
x_63 = lean_ctor_get(x_37, 1);
lean_inc(x_63);
lean_dec(x_37);
x_64 = lean_ctor_get(x_38, 0);
lean_inc(x_64);
if (lean_is_exclusive(x_38)) {
 lean_ctor_release(x_38, 0);
 x_65 = x_38;
} else {
 lean_dec_ref(x_38);
 x_65 = lean_box(0);
}
x_66 = lean_ctor_get(x_36, 1);
lean_inc(x_66);
lean_dec(x_36);
x_67 = l_BitVec_ofNat(x_64, x_66);
lean_dec(x_66);
x_68 = l_BitVec_reduceUnary___redArg___closed__4;
x_69 = l_Lean_mkNatLit(x_64);
x_70 = l_Lean_mkNatLit(x_67);
x_71 = l_Lean_mkAppB(x_68, x_69, x_70);
if (lean_is_scalar(x_65)) {
 x_72 = lean_alloc_ctor(0, 1, 0);
} else {
 x_72 = x_65;
 lean_ctor_set_tag(x_72, 0);
}
lean_ctor_set(x_72, 0, x_71);
x_73 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_73, 0, x_72);
lean_ctor_set(x_73, 1, x_63);
return x_73;
}
}
}
else
{
uint8_t x_74; 
lean_dec(x_36);
x_74 = !lean_is_exclusive(x_37);
if (x_74 == 0)
{
return x_37;
}
else
{
lean_object* x_75; lean_object* x_76; lean_object* x_77; 
x_75 = lean_ctor_get(x_37, 0);
x_76 = lean_ctor_get(x_37, 1);
lean_inc(x_76);
lean_inc(x_75);
lean_dec(x_37);
x_77 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_77, 0, x_75);
lean_ctor_set(x_77, 1, x_76);
return x_77;
}
}
}
}
else
{
uint8_t x_78; 
lean_dec(x_21);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_78 = !lean_is_exclusive(x_27);
if (x_78 == 0)
{
return x_27;
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; 
x_79 = lean_ctor_get(x_27, 0);
x_80 = lean_ctor_get(x_27, 1);
lean_inc(x_80);
lean_inc(x_79);
lean_dec(x_27);
x_81 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_81, 0, x_79);
lean_ctor_set(x_81, 1, x_80);
return x_81;
}
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceCast___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceCast(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceCast", 10, 10);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceCast___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceCast___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceCast___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3563_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceToNat___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("toNat", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToNat___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToNat___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_20 = l_BitVec_reduceToNat___redArg___closed__1;
x_21 = l_Lean_Expr_isConstOf(x_19, x_20);
lean_dec(x_19);
if (x_21 == 0)
{
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; 
lean_dec(x_10);
x_22 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_22) == 0)
{
lean_object* x_23; 
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
if (lean_obj_tag(x_23) == 0)
{
uint8_t x_24; 
x_24 = !lean_is_exclusive(x_22);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; 
x_25 = lean_ctor_get(x_22, 0);
lean_dec(x_25);
x_26 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_22, 0, x_26);
return x_22;
}
else
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_27 = lean_ctor_get(x_22, 1);
lean_inc(x_27);
lean_dec(x_22);
x_28 = l_BitVec_reduceUnary___redArg___closed__0;
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_29, 1, x_27);
return x_29;
}
}
else
{
uint8_t x_30; 
x_30 = !lean_is_exclusive(x_23);
if (x_30 == 0)
{
uint8_t x_31; 
x_31 = !lean_is_exclusive(x_22);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_32 = lean_ctor_get(x_23, 0);
x_33 = lean_ctor_get(x_22, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
lean_dec(x_32);
x_35 = l_Lean_mkNatLit(x_34);
lean_ctor_set_tag(x_23, 0);
lean_ctor_set(x_23, 0, x_35);
return x_22;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_36 = lean_ctor_get(x_23, 0);
x_37 = lean_ctor_get(x_22, 1);
lean_inc(x_37);
lean_dec(x_22);
x_38 = lean_ctor_get(x_36, 1);
lean_inc(x_38);
lean_dec(x_36);
x_39 = l_Lean_mkNatLit(x_38);
lean_ctor_set_tag(x_23, 0);
lean_ctor_set(x_23, 0, x_39);
x_40 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_40, 0, x_23);
lean_ctor_set(x_40, 1, x_37);
return x_40;
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_41 = lean_ctor_get(x_23, 0);
lean_inc(x_41);
lean_dec(x_23);
x_42 = lean_ctor_get(x_22, 1);
lean_inc(x_42);
if (lean_is_exclusive(x_22)) {
 lean_ctor_release(x_22, 0);
 lean_ctor_release(x_22, 1);
 x_43 = x_22;
} else {
 lean_dec_ref(x_22);
 x_43 = lean_box(0);
}
x_44 = lean_ctor_get(x_41, 1);
lean_inc(x_44);
lean_dec(x_41);
x_45 = l_Lean_mkNatLit(x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
if (lean_is_scalar(x_43)) {
 x_47 = lean_alloc_ctor(0, 2, 0);
} else {
 x_47 = x_43;
}
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_47, 1, x_42);
return x_47;
}
}
}
else
{
uint8_t x_48; 
x_48 = !lean_is_exclusive(x_22);
if (x_48 == 0)
{
return x_22;
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; 
x_49 = lean_ctor_get(x_22, 0);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_inc(x_49);
lean_dec(x_22);
x_51 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_51, 0, x_49);
lean_ctor_set(x_51, 1, x_50);
return x_51;
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToNat___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToNat(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceToNat", 11, 11);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceToNat___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceToNat___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToNat___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("toInt", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = l_Lean_Level_ofNat(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___redArg___closed__3;
x_3 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___redArg___closed__4;
x_2 = l_BitVec_reduceNeg___redArg___closed__2;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__6() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Int", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceToInt___redArg___closed__6;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___redArg___closed__7;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("instNegInt", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___redArg___closed__9;
x_2 = l_BitVec_reduceToInt___redArg___closed__6;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___redArg___closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___redArg___closed__10;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_20 = l_BitVec_reduceToInt___redArg___closed__1;
x_21 = l_Lean_Expr_isConstOf(x_19, x_20);
lean_dec(x_19);
if (x_21 == 0)
{
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; 
lean_dec(x_10);
x_22 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_22) == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
if (lean_is_exclusive(x_22)) {
 lean_ctor_release(x_22, 0);
 lean_ctor_release(x_22, 1);
 x_25 = x_22;
} else {
 lean_dec_ref(x_22);
 x_25 = lean_box(0);
}
if (lean_obj_tag(x_23) == 0)
{
lean_object* x_30; lean_object* x_31; 
lean_dec(x_25);
x_30 = l_BitVec_reduceUnary___redArg___closed__0;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_24);
return x_31;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_32 = lean_ctor_get(x_23, 0);
lean_inc(x_32);
lean_dec(x_23);
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
lean_dec(x_32);
x_35 = l_BitVec_toInt(x_33, x_34);
lean_dec(x_33);
x_36 = l_BitVec_reduceToInt___redArg___closed__2;
x_37 = lean_int_dec_le(x_36, x_35);
if (x_37 == 0)
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; 
x_38 = l_BitVec_reduceToInt___redArg___closed__5;
x_39 = l_BitVec_reduceToInt___redArg___closed__8;
x_40 = l_BitVec_reduceToInt___redArg___closed__11;
x_41 = lean_int_neg(x_35);
lean_dec(x_35);
x_42 = l_Int_toNat(x_41);
lean_dec(x_41);
x_43 = l_Lean_instToExprInt_mkNat(x_42);
x_44 = l_Lean_mkApp3(x_38, x_39, x_40, x_43);
x_26 = x_44;
goto block_29;
}
else
{
lean_object* x_45; lean_object* x_46; 
x_45 = l_Int_toNat(x_35);
lean_dec(x_35);
x_46 = l_Lean_instToExprInt_mkNat(x_45);
x_26 = x_46;
goto block_29;
}
}
block_29:
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_27, 0, x_26);
if (lean_is_scalar(x_25)) {
 x_28 = lean_alloc_ctor(0, 2, 0);
} else {
 x_28 = x_25;
}
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_24);
return x_28;
}
}
else
{
uint8_t x_47; 
x_47 = !lean_is_exclusive(x_22);
if (x_47 == 0)
{
return x_22;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_22, 0);
x_49 = lean_ctor_get(x_22, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_22);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToInt___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToInt(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceToInt", 11, 11);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceToInt___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceToInt___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToInt___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3937_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ofInt", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOfInt___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; uint8_t x_22; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_BitVec_reduceOfInt___redArg___closed__1;
x_22 = l_Lean_Expr_isConstOf(x_20, x_21);
lean_dec(x_20);
if (x_22 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_23; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_23 = l_Lean_Meta_getNatValue_x3f(x_19, x_2, x_3, x_4, x_5, x_9);
lean_dec(x_19);
if (lean_obj_tag(x_23) == 0)
{
lean_object* x_24; 
x_24 = lean_ctor_get(x_23, 0);
lean_inc(x_24);
if (lean_obj_tag(x_24) == 0)
{
uint8_t x_25; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_25 = !lean_is_exclusive(x_23);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; 
x_26 = lean_ctor_get(x_23, 0);
lean_dec(x_26);
x_27 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_23, 0, x_27);
return x_23;
}
else
{
lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_28 = lean_ctor_get(x_23, 1);
lean_inc(x_28);
lean_dec(x_23);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
x_30 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_30, 1, x_28);
return x_30;
}
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_23, 1);
lean_inc(x_31);
lean_dec(x_23);
x_32 = lean_ctor_get(x_24, 0);
lean_inc(x_32);
lean_dec(x_24);
x_33 = l_Lean_Meta_getIntValue_x3f(x_16, x_2, x_3, x_4, x_5, x_31);
if (lean_obj_tag(x_33) == 0)
{
lean_object* x_34; 
x_34 = lean_ctor_get(x_33, 0);
lean_inc(x_34);
if (lean_obj_tag(x_34) == 0)
{
uint8_t x_35; 
lean_dec(x_32);
x_35 = !lean_is_exclusive(x_33);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; 
x_36 = lean_ctor_get(x_33, 0);
lean_dec(x_36);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_33, 0, x_37);
return x_33;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_33, 1);
lean_inc(x_38);
lean_dec(x_33);
x_39 = l_BitVec_reduceUnary___redArg___closed__0;
x_40 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_40, 1, x_38);
return x_40;
}
}
else
{
uint8_t x_41; 
x_41 = !lean_is_exclusive(x_33);
if (x_41 == 0)
{
lean_object* x_42; uint8_t x_43; 
x_42 = lean_ctor_get(x_33, 0);
lean_dec(x_42);
x_43 = !lean_is_exclusive(x_34);
if (x_43 == 0)
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_44 = lean_ctor_get(x_34, 0);
x_45 = l_BitVec_ofInt(x_32, x_44);
lean_dec(x_44);
x_46 = l_BitVec_reduceUnary___redArg___closed__4;
x_47 = l_Lean_mkNatLit(x_32);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkAppB(x_46, x_47, x_48);
lean_ctor_set_tag(x_34, 0);
lean_ctor_set(x_34, 0, x_49);
return x_33;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_50 = lean_ctor_get(x_34, 0);
lean_inc(x_50);
lean_dec(x_34);
x_51 = l_BitVec_ofInt(x_32, x_50);
lean_dec(x_50);
x_52 = l_BitVec_reduceUnary___redArg___closed__4;
x_53 = l_Lean_mkNatLit(x_32);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkAppB(x_52, x_53, x_54);
x_56 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_33, 0, x_56);
return x_33;
}
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_57 = lean_ctor_get(x_33, 1);
lean_inc(x_57);
lean_dec(x_33);
x_58 = lean_ctor_get(x_34, 0);
lean_inc(x_58);
if (lean_is_exclusive(x_34)) {
 lean_ctor_release(x_34, 0);
 x_59 = x_34;
} else {
 lean_dec_ref(x_34);
 x_59 = lean_box(0);
}
x_60 = l_BitVec_ofInt(x_32, x_58);
lean_dec(x_58);
x_61 = l_BitVec_reduceUnary___redArg___closed__4;
x_62 = l_Lean_mkNatLit(x_32);
x_63 = l_Lean_mkNatLit(x_60);
x_64 = l_Lean_mkAppB(x_61, x_62, x_63);
if (lean_is_scalar(x_59)) {
 x_65 = lean_alloc_ctor(0, 1, 0);
} else {
 x_65 = x_59;
 lean_ctor_set_tag(x_65, 0);
}
lean_ctor_set(x_65, 0, x_64);
x_66 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_66, 0, x_65);
lean_ctor_set(x_66, 1, x_57);
return x_66;
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_32);
x_67 = !lean_is_exclusive(x_33);
if (x_67 == 0)
{
return x_33;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_33, 0);
x_69 = lean_ctor_get(x_33, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_33);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
else
{
uint8_t x_71; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_71 = !lean_is_exclusive(x_23);
if (x_71 == 0)
{
return x_23;
}
else
{
lean_object* x_72; lean_object* x_73; lean_object* x_74; 
x_72 = lean_ctor_get(x_23, 0);
x_73 = lean_ctor_get(x_23, 1);
lean_inc(x_73);
lean_inc(x_72);
lean_dec(x_23);
x_74 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_74, 0, x_72);
lean_ctor_set(x_74, 1, x_73);
return x_74;
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOfInt___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOfInt(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceOfInt", 11, 11);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceOfInt___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceOfInt___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfInt___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4176_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; uint8_t x_22; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_BitVec_reduceUnary___redArg___closed__3;
x_22 = l_Lean_Expr_isConstOf(x_20, x_21);
lean_dec(x_20);
if (x_22 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_23; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_23 = l_Lean_Meta_getNatValue_x3f(x_19, x_2, x_3, x_4, x_5, x_9);
lean_dec(x_19);
if (lean_obj_tag(x_23) == 0)
{
lean_object* x_24; 
x_24 = lean_ctor_get(x_23, 0);
lean_inc(x_24);
if (lean_obj_tag(x_24) == 0)
{
uint8_t x_25; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_25 = !lean_is_exclusive(x_23);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; 
x_26 = lean_ctor_get(x_23, 0);
lean_dec(x_26);
x_27 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_23, 0, x_27);
return x_23;
}
else
{
lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_28 = lean_ctor_get(x_23, 1);
lean_inc(x_28);
lean_dec(x_23);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
x_30 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_30, 1, x_28);
return x_30;
}
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_23, 1);
lean_inc(x_31);
lean_dec(x_23);
x_32 = lean_ctor_get(x_24, 0);
lean_inc(x_32);
lean_dec(x_24);
x_33 = l_Lean_Meta_getNatValue_x3f(x_16, x_2, x_3, x_4, x_5, x_31);
lean_dec(x_16);
if (lean_obj_tag(x_33) == 0)
{
lean_object* x_34; 
x_34 = lean_ctor_get(x_33, 0);
lean_inc(x_34);
if (lean_obj_tag(x_34) == 0)
{
uint8_t x_35; 
lean_dec(x_32);
x_35 = !lean_is_exclusive(x_33);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; 
x_36 = lean_ctor_get(x_33, 0);
lean_dec(x_36);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_33, 0, x_37);
return x_33;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_33, 1);
lean_inc(x_38);
lean_dec(x_33);
x_39 = l_BitVec_reduceUnary___redArg___closed__0;
x_40 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_40, 1, x_38);
return x_40;
}
}
else
{
uint8_t x_41; 
x_41 = !lean_is_exclusive(x_33);
if (x_41 == 0)
{
lean_object* x_42; uint8_t x_43; 
x_42 = lean_ctor_get(x_33, 0);
lean_dec(x_42);
x_43 = !lean_is_exclusive(x_34);
if (x_43 == 0)
{
lean_object* x_44; lean_object* x_45; uint8_t x_46; 
x_44 = lean_ctor_get(x_34, 0);
x_45 = l_BitVec_ofNat(x_32, x_44);
x_46 = lean_nat_dec_eq(x_45, x_44);
lean_dec(x_44);
if (x_46 == 0)
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_47 = l_BitVec_reduceUnary___redArg___closed__4;
x_48 = l_Lean_mkNatLit(x_32);
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkAppB(x_47, x_48, x_49);
lean_ctor_set_tag(x_34, 0);
lean_ctor_set(x_34, 0, x_50);
return x_33;
}
else
{
lean_object* x_51; 
lean_dec(x_45);
lean_free_object(x_34);
lean_dec(x_32);
x_51 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_33, 0, x_51);
return x_33;
}
}
else
{
lean_object* x_52; lean_object* x_53; uint8_t x_54; 
x_52 = lean_ctor_get(x_34, 0);
lean_inc(x_52);
lean_dec(x_34);
x_53 = l_BitVec_ofNat(x_32, x_52);
x_54 = lean_nat_dec_eq(x_53, x_52);
lean_dec(x_52);
if (x_54 == 0)
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_55 = l_BitVec_reduceUnary___redArg___closed__4;
x_56 = l_Lean_mkNatLit(x_32);
x_57 = l_Lean_mkNatLit(x_53);
x_58 = l_Lean_mkAppB(x_55, x_56, x_57);
x_59 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_33, 0, x_59);
return x_33;
}
else
{
lean_object* x_60; 
lean_dec(x_53);
lean_dec(x_32);
x_60 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_33, 0, x_60);
return x_33;
}
}
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; uint8_t x_65; 
x_61 = lean_ctor_get(x_33, 1);
lean_inc(x_61);
lean_dec(x_33);
x_62 = lean_ctor_get(x_34, 0);
lean_inc(x_62);
if (lean_is_exclusive(x_34)) {
 lean_ctor_release(x_34, 0);
 x_63 = x_34;
} else {
 lean_dec_ref(x_34);
 x_63 = lean_box(0);
}
x_64 = l_BitVec_ofNat(x_32, x_62);
x_65 = lean_nat_dec_eq(x_64, x_62);
lean_dec(x_62);
if (x_65 == 0)
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_66 = l_BitVec_reduceUnary___redArg___closed__4;
x_67 = l_Lean_mkNatLit(x_32);
x_68 = l_Lean_mkNatLit(x_64);
x_69 = l_Lean_mkAppB(x_66, x_67, x_68);
if (lean_is_scalar(x_63)) {
 x_70 = lean_alloc_ctor(0, 1, 0);
} else {
 x_70 = x_63;
 lean_ctor_set_tag(x_70, 0);
}
lean_ctor_set(x_70, 0, x_69);
x_71 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_71, 0, x_70);
lean_ctor_set(x_71, 1, x_61);
return x_71;
}
else
{
lean_object* x_72; lean_object* x_73; 
lean_dec(x_64);
lean_dec(x_63);
lean_dec(x_32);
x_72 = l_BitVec_reduceUnary___redArg___closed__0;
x_73 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_73, 0, x_72);
lean_ctor_set(x_73, 1, x_61);
return x_73;
}
}
}
}
else
{
uint8_t x_74; 
lean_dec(x_32);
x_74 = !lean_is_exclusive(x_33);
if (x_74 == 0)
{
return x_33;
}
else
{
lean_object* x_75; lean_object* x_76; lean_object* x_77; 
x_75 = lean_ctor_get(x_33, 0);
x_76 = lean_ctor_get(x_33, 1);
lean_inc(x_76);
lean_inc(x_75);
lean_dec(x_33);
x_77 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_77, 0, x_75);
lean_ctor_set(x_77, 1, x_76);
return x_77;
}
}
}
}
else
{
uint8_t x_78; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_78 = !lean_is_exclusive(x_23);
if (x_78 == 0)
{
return x_23;
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; 
x_79 = lean_ctor_get(x_23, 0);
x_80 = lean_ctor_get(x_23, 1);
lean_inc(x_80);
lean_inc(x_79);
lean_dec(x_23);
x_81 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_81, 0, x_79);
lean_ctor_set(x_81, 1, x_80);
return x_81;
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOfNat___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceOfNat(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceOfNat", 11, 11);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceUnary___redArg___closed__3;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceOfNat___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfNat___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4467_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceEq___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Eq", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceEq___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceEq___redArg___closed__0;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceEq___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceEq___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; lean_object* x_44; 
lean_free_object(x_25);
x_43 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_43, x_2, x_3, x_4, x_5, x_35);
return x_44;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_45 = lean_ctor_get(x_25, 1);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
x_48 = lean_ctor_get(x_33, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_33, 1);
lean_inc(x_49);
lean_dec(x_33);
x_50 = lean_nat_dec_eq(x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_49);
lean_dec(x_47);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___redArg___closed__0;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_45);
return x_52;
}
else
{
uint8_t x_53; lean_object* x_54; 
x_53 = lean_nat_dec_eq(x_47, x_49);
lean_dec(x_49);
lean_dec(x_47);
x_54 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_53, x_2, x_3, x_4, x_5, x_45);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceEq(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceEq___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceEq___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceEq(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceEq", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceEq___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceEq___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceEq___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4508_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceNe___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Ne", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNe___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceNe___redArg___closed__0;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNe___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceNe___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; uint8_t x_44; lean_object* x_45; 
lean_free_object(x_25);
x_43 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_instDecidableNot___redArg(x_43);
x_45 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_44, x_2, x_3, x_4, x_5, x_35);
return x_45;
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_46 = lean_ctor_get(x_25, 1);
lean_inc(x_46);
lean_dec(x_25);
x_47 = lean_ctor_get(x_23, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_23, 1);
lean_inc(x_48);
lean_dec(x_23);
x_49 = lean_ctor_get(x_33, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_33, 1);
lean_inc(x_50);
lean_dec(x_33);
x_51 = lean_nat_dec_eq(x_47, x_49);
lean_dec(x_49);
lean_dec(x_47);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_50);
lean_dec(x_48);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_52 = l_BitVec_reduceBinPred___redArg___closed__0;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_46);
return x_53;
}
else
{
uint8_t x_54; uint8_t x_55; lean_object* x_56; 
x_54 = lean_nat_dec_eq(x_48, x_50);
lean_dec(x_50);
lean_dec(x_48);
x_55 = l_instDecidableNot___redArg(x_54);
x_56 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_55, x_2, x_3, x_4, x_5, x_46);
return x_56;
}
}
}
}
else
{
uint8_t x_57; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_57 = !lean_is_exclusive(x_25);
if (x_57 == 0)
{
return x_25;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_25, 0);
x_59 = lean_ctor_get(x_25, 1);
lean_inc(x_59);
lean_inc(x_58);
lean_dec(x_25);
x_60 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
return x_60;
}
}
}
}
else
{
uint8_t x_61; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_61 = !lean_is_exclusive(x_14);
if (x_61 == 0)
{
return x_14;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_62 = lean_ctor_get(x_14, 0);
x_63 = lean_ctor_get(x_14, 1);
lean_inc(x_63);
lean_inc(x_62);
lean_dec(x_14);
x_64 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
return x_64;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNe(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNe___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNe___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNe(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceNe", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Not", 3, 3);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(1u);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceNe___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNe___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4548_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceBEq___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("BEq", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBEq___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("beq", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBEq___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBEq___redArg___closed__1;
x_2 = l_BitVec_reduceBEq___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceBEq___redArg___closed__2;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_25, 1);
lean_inc(x_39);
lean_dec(x_25);
x_40 = lean_ctor_get(x_37, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_37, 1);
lean_inc(x_41);
lean_dec(x_37);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_31);
lean_dec(x_26);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_43);
return x_14;
}
else
{
uint8_t x_44; 
lean_free_object(x_14);
x_44 = lean_nat_dec_eq(x_39, x_41);
lean_dec(x_41);
lean_dec(x_39);
if (x_44 == 0)
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_45;
goto block_35;
}
else
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_46;
goto block_35;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_47; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_47 = !lean_is_exclusive(x_28);
if (x_47 == 0)
{
return x_28;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_28, 0);
x_49 = lean_ctor_get(x_28, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_28);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_14, 1);
lean_inc(x_51);
lean_dec(x_14);
x_52 = lean_ctor_get(x_15, 0);
lean_inc(x_52);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_53 = x_15;
} else {
 lean_dec_ref(x_15);
 x_53 = lean_box(0);
}
x_54 = l_Lean_Expr_appArg_x21(x_1);
x_55 = l_BitVec_fromExpr_x3f___redArg(x_54, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_55) == 0)
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_55, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_55, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_58 = x_55;
} else {
 lean_dec_ref(x_55);
 x_58 = lean_box(0);
}
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_63; lean_object* x_64; 
lean_dec(x_58);
lean_dec(x_53);
lean_dec(x_52);
x_63 = l_BitVec_reduceUnary___redArg___closed__0;
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_57);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_65 = lean_ctor_get(x_56, 0);
lean_inc(x_65);
lean_dec(x_56);
x_66 = lean_ctor_get(x_52, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_52, 1);
lean_inc(x_67);
lean_dec(x_52);
x_68 = lean_ctor_get(x_65, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_65, 1);
lean_inc(x_69);
lean_dec(x_65);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
lean_dec(x_66);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_58);
lean_dec(x_53);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
x_72 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_57);
return x_72;
}
else
{
uint8_t x_73; 
x_73 = lean_nat_dec_eq(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
if (x_73 == 0)
{
lean_object* x_74; 
x_74 = l_BitVec_reduceGetBit___redArg___closed__3;
x_59 = x_74;
goto block_62;
}
else
{
lean_object* x_75; 
x_75 = l_BitVec_reduceGetBit___redArg___closed__6;
x_59 = x_75;
goto block_62;
}
}
}
block_62:
{
lean_object* x_60; lean_object* x_61; 
if (lean_is_scalar(x_53)) {
 x_60 = lean_alloc_ctor(0, 1, 0);
} else {
 x_60 = x_53;
 lean_ctor_set_tag(x_60, 0);
}
lean_ctor_set(x_60, 0, x_59);
if (lean_is_scalar(x_58)) {
 x_61 = lean_alloc_ctor(0, 2, 0);
} else {
 x_61 = x_58;
}
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_57);
return x_61;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
lean_dec(x_53);
lean_dec(x_52);
x_76 = lean_ctor_get(x_55, 0);
lean_inc(x_76);
x_77 = lean_ctor_get(x_55, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_78 = x_55;
} else {
 lean_dec_ref(x_55);
 x_78 = lean_box(0);
}
if (lean_is_scalar(x_78)) {
 x_79 = lean_alloc_ctor(1, 2, 0);
} else {
 x_79 = x_78;
}
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_77);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_80 = !lean_is_exclusive(x_14);
if (x_80 == 0)
{
return x_14;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_14, 0);
x_82 = lean_ctor_get(x_14, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_14);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBEq___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceBEq___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBEq(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceBEq", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceBEq___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceBEq___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBEq___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4589_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceBNe___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("bne", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBNe___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBNe___redArg___closed__0;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceBNe___redArg___closed__1;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_38; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_38 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_38);
return x_14;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
x_39 = lean_ctor_get(x_29, 0);
lean_inc(x_39);
lean_dec(x_29);
x_40 = lean_ctor_get(x_25, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_25, 1);
lean_inc(x_41);
lean_dec(x_25);
x_42 = lean_ctor_get(x_39, 0);
lean_inc(x_42);
x_43 = lean_ctor_get(x_39, 1);
lean_inc(x_43);
lean_dec(x_39);
x_44 = lean_nat_dec_eq(x_40, x_42);
lean_dec(x_42);
lean_dec(x_40);
if (x_44 == 0)
{
lean_object* x_45; 
lean_dec(x_43);
lean_dec(x_41);
lean_dec(x_31);
lean_dec(x_26);
x_45 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_45);
return x_14;
}
else
{
uint8_t x_46; 
lean_free_object(x_14);
x_46 = lean_nat_dec_eq(x_41, x_43);
lean_dec(x_43);
lean_dec(x_41);
if (x_46 == 0)
{
if (x_9 == 0)
{
goto block_37;
}
else
{
lean_object* x_47; 
x_47 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_47;
goto block_35;
}
}
else
{
goto block_37;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
block_37:
{
lean_object* x_36; 
x_36 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_36;
goto block_35;
}
}
else
{
uint8_t x_48; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_48 = !lean_is_exclusive(x_28);
if (x_48 == 0)
{
return x_28;
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; 
x_49 = lean_ctor_get(x_28, 0);
x_50 = lean_ctor_get(x_28, 1);
lean_inc(x_50);
lean_inc(x_49);
lean_dec(x_28);
x_51 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_51, 0, x_49);
lean_ctor_set(x_51, 1, x_50);
return x_51;
}
}
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_52 = lean_ctor_get(x_14, 1);
lean_inc(x_52);
lean_dec(x_14);
x_53 = lean_ctor_get(x_15, 0);
lean_inc(x_53);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_54 = x_15;
} else {
 lean_dec_ref(x_15);
 x_54 = lean_box(0);
}
x_55 = l_Lean_Expr_appArg_x21(x_1);
x_56 = l_BitVec_fromExpr_x3f___redArg(x_55, x_2, x_3, x_4, x_5, x_52);
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_57 = lean_ctor_get(x_56, 0);
lean_inc(x_57);
x_58 = lean_ctor_get(x_56, 1);
lean_inc(x_58);
if (lean_is_exclusive(x_56)) {
 lean_ctor_release(x_56, 0);
 lean_ctor_release(x_56, 1);
 x_59 = x_56;
} else {
 lean_dec_ref(x_56);
 x_59 = lean_box(0);
}
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_66; lean_object* x_67; 
lean_dec(x_59);
lean_dec(x_54);
lean_dec(x_53);
x_66 = l_BitVec_reduceUnary___redArg___closed__0;
x_67 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_67, 0, x_66);
lean_ctor_set(x_67, 1, x_58);
return x_67;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; uint8_t x_73; 
x_68 = lean_ctor_get(x_57, 0);
lean_inc(x_68);
lean_dec(x_57);
x_69 = lean_ctor_get(x_53, 0);
lean_inc(x_69);
x_70 = lean_ctor_get(x_53, 1);
lean_inc(x_70);
lean_dec(x_53);
x_71 = lean_ctor_get(x_68, 0);
lean_inc(x_71);
x_72 = lean_ctor_get(x_68, 1);
lean_inc(x_72);
lean_dec(x_68);
x_73 = lean_nat_dec_eq(x_69, x_71);
lean_dec(x_71);
lean_dec(x_69);
if (x_73 == 0)
{
lean_object* x_74; lean_object* x_75; 
lean_dec(x_72);
lean_dec(x_70);
lean_dec(x_59);
lean_dec(x_54);
x_74 = l_BitVec_reduceUnary___redArg___closed__0;
x_75 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_75, 0, x_74);
lean_ctor_set(x_75, 1, x_58);
return x_75;
}
else
{
uint8_t x_76; 
x_76 = lean_nat_dec_eq(x_70, x_72);
lean_dec(x_72);
lean_dec(x_70);
if (x_76 == 0)
{
if (x_9 == 0)
{
goto block_65;
}
else
{
lean_object* x_77; 
x_77 = l_BitVec_reduceGetBit___redArg___closed__6;
x_60 = x_77;
goto block_63;
}
}
else
{
goto block_65;
}
}
}
block_63:
{
lean_object* x_61; lean_object* x_62; 
if (lean_is_scalar(x_54)) {
 x_61 = lean_alloc_ctor(0, 1, 0);
} else {
 x_61 = x_54;
 lean_ctor_set_tag(x_61, 0);
}
lean_ctor_set(x_61, 0, x_60);
if (lean_is_scalar(x_59)) {
 x_62 = lean_alloc_ctor(0, 2, 0);
} else {
 x_62 = x_59;
}
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_58);
return x_62;
}
block_65:
{
lean_object* x_64; 
x_64 = l_BitVec_reduceGetBit___redArg___closed__3;
x_60 = x_64;
goto block_63;
}
}
else
{
lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; 
lean_dec(x_54);
lean_dec(x_53);
x_78 = lean_ctor_get(x_56, 0);
lean_inc(x_78);
x_79 = lean_ctor_get(x_56, 1);
lean_inc(x_79);
if (lean_is_exclusive(x_56)) {
 lean_ctor_release(x_56, 0);
 lean_ctor_release(x_56, 1);
 x_80 = x_56;
} else {
 lean_dec_ref(x_56);
 x_80 = lean_box(0);
}
if (lean_is_scalar(x_80)) {
 x_81 = lean_alloc_ctor(1, 2, 0);
} else {
 x_81 = x_80;
}
lean_ctor_set(x_81, 0, x_78);
lean_ctor_set(x_81, 1, x_79);
return x_81;
}
}
}
}
else
{
uint8_t x_82; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_82 = !lean_is_exclusive(x_14);
if (x_82 == 0)
{
return x_14;
}
else
{
lean_object* x_83; lean_object* x_84; lean_object* x_85; 
x_83 = lean_ctor_get(x_14, 0);
x_84 = lean_ctor_get(x_14, 1);
lean_inc(x_84);
lean_inc(x_83);
lean_dec(x_14);
x_85 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
return x_85;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBNe___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceBNe___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBNe(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceBNe", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceBNe___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceBNe___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBNe___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4629_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceLT___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("LT", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("lt", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLT___redArg___closed__1;
x_2 = l_BitVec_reduceLT___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceLT___redArg___closed__2;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; lean_object* x_44; 
lean_free_object(x_25);
x_43 = lean_nat_dec_lt(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_43, x_2, x_3, x_4, x_5, x_35);
return x_44;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_45 = lean_ctor_get(x_25, 1);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
x_48 = lean_ctor_get(x_33, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_33, 1);
lean_inc(x_49);
lean_dec(x_33);
x_50 = lean_nat_dec_eq(x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_49);
lean_dec(x_47);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___redArg___closed__0;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_45);
return x_52;
}
else
{
uint8_t x_53; lean_object* x_54; 
x_53 = lean_nat_dec_lt(x_47, x_49);
lean_dec(x_49);
lean_dec(x_47);
x_54 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_53, x_2, x_3, x_4, x_5, x_45);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceLT___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceLT(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceLT", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceLT___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceLT___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLT___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4670_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceLE___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("LE", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("le", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLE___redArg___closed__1;
x_2 = l_BitVec_reduceLE___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceLE___redArg___closed__2;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; lean_object* x_44; 
lean_free_object(x_25);
x_43 = lean_nat_dec_le(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
x_44 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_43, x_2, x_3, x_4, x_5, x_35);
return x_44;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_45 = lean_ctor_get(x_25, 1);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
x_48 = lean_ctor_get(x_33, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_33, 1);
lean_inc(x_49);
lean_dec(x_33);
x_50 = lean_nat_dec_eq(x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_49);
lean_dec(x_47);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___redArg___closed__0;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_45);
return x_52;
}
else
{
uint8_t x_53; lean_object* x_54; 
x_53 = lean_nat_dec_le(x_47, x_49);
lean_dec(x_49);
lean_dec(x_47);
x_54 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_53, x_2, x_3, x_4, x_5, x_45);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceLE___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceLE(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceLE", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceLE___redArg___closed__2;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceLE___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLE___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4711_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceGT___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("GT", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("gt", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGT___redArg___closed__1;
x_2 = l_BitVec_reduceGT___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceGT___redArg___closed__2;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; lean_object* x_44; 
lean_free_object(x_25);
x_43 = lean_nat_dec_lt(x_40, x_38);
lean_dec(x_38);
lean_dec(x_40);
x_44 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_43, x_2, x_3, x_4, x_5, x_35);
return x_44;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_45 = lean_ctor_get(x_25, 1);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
x_48 = lean_ctor_get(x_33, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_33, 1);
lean_inc(x_49);
lean_dec(x_33);
x_50 = lean_nat_dec_eq(x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_49);
lean_dec(x_47);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___redArg___closed__0;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_45);
return x_52;
}
else
{
uint8_t x_53; lean_object* x_54; 
x_53 = lean_nat_dec_lt(x_49, x_47);
lean_dec(x_47);
lean_dec(x_49);
x_54 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_53, x_2, x_3, x_4, x_5, x_45);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGT___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGT(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceGT", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceGT___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGT___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4752_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceGE___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("GE", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___redArg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ge", 2, 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___redArg___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGE___redArg___closed__1;
x_2 = l_BitVec_reduceGE___redArg___closed__0;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceGE___redArg___closed__2;
x_8 = lean_unsigned_to_nat(4u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_24, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = lean_ctor_get(x_26, 0);
lean_inc(x_33);
lean_dec(x_26);
x_34 = !lean_is_exclusive(x_25);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_35 = lean_ctor_get(x_25, 1);
x_36 = lean_ctor_get(x_25, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_23, 1);
lean_inc(x_38);
lean_dec(x_23);
x_39 = lean_ctor_get(x_33, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_33, 1);
lean_inc(x_40);
lean_dec(x_33);
x_41 = lean_nat_dec_eq(x_37, x_39);
lean_dec(x_39);
lean_dec(x_37);
if (x_41 == 0)
{
lean_object* x_42; 
lean_dec(x_40);
lean_dec(x_38);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_42 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_25, 0, x_42);
return x_25;
}
else
{
uint8_t x_43; lean_object* x_44; 
lean_free_object(x_25);
x_43 = lean_nat_dec_le(x_40, x_38);
lean_dec(x_38);
lean_dec(x_40);
x_44 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_43, x_2, x_3, x_4, x_5, x_35);
return x_44;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_45 = lean_ctor_get(x_25, 1);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
x_48 = lean_ctor_get(x_33, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_33, 1);
lean_inc(x_49);
lean_dec(x_33);
x_50 = lean_nat_dec_eq(x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_49);
lean_dec(x_47);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___redArg___closed__0;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_45);
return x_52;
}
else
{
uint8_t x_53; lean_object* x_54; 
x_53 = lean_nat_dec_le(x_49, x_47);
lean_dec(x_47);
lean_dec(x_49);
x_54 = l_Lean_Meta_Simp_evalPropStep___redArg(x_1, x_53, x_2, x_3, x_4, x_5, x_45);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGE___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceGE(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceGE", 8, 8);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceGE___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGE___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4793_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceULT___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ult", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULT___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULT___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceULT___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_25, 1);
lean_inc(x_39);
lean_dec(x_25);
x_40 = lean_ctor_get(x_37, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_37, 1);
lean_inc(x_41);
lean_dec(x_37);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_31);
lean_dec(x_26);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_43);
return x_14;
}
else
{
uint8_t x_44; 
lean_free_object(x_14);
x_44 = lean_nat_dec_lt(x_39, x_41);
lean_dec(x_41);
lean_dec(x_39);
if (x_44 == 0)
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_45;
goto block_35;
}
else
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_46;
goto block_35;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_47; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_47 = !lean_is_exclusive(x_28);
if (x_47 == 0)
{
return x_28;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_28, 0);
x_49 = lean_ctor_get(x_28, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_28);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_14, 1);
lean_inc(x_51);
lean_dec(x_14);
x_52 = lean_ctor_get(x_15, 0);
lean_inc(x_52);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_53 = x_15;
} else {
 lean_dec_ref(x_15);
 x_53 = lean_box(0);
}
x_54 = l_Lean_Expr_appArg_x21(x_1);
x_55 = l_BitVec_fromExpr_x3f___redArg(x_54, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_55) == 0)
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_55, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_55, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_58 = x_55;
} else {
 lean_dec_ref(x_55);
 x_58 = lean_box(0);
}
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_63; lean_object* x_64; 
lean_dec(x_58);
lean_dec(x_53);
lean_dec(x_52);
x_63 = l_BitVec_reduceUnary___redArg___closed__0;
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_57);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_65 = lean_ctor_get(x_56, 0);
lean_inc(x_65);
lean_dec(x_56);
x_66 = lean_ctor_get(x_52, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_52, 1);
lean_inc(x_67);
lean_dec(x_52);
x_68 = lean_ctor_get(x_65, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_65, 1);
lean_inc(x_69);
lean_dec(x_65);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
lean_dec(x_66);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_58);
lean_dec(x_53);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
x_72 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_57);
return x_72;
}
else
{
uint8_t x_73; 
x_73 = lean_nat_dec_lt(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
if (x_73 == 0)
{
lean_object* x_74; 
x_74 = l_BitVec_reduceGetBit___redArg___closed__3;
x_59 = x_74;
goto block_62;
}
else
{
lean_object* x_75; 
x_75 = l_BitVec_reduceGetBit___redArg___closed__6;
x_59 = x_75;
goto block_62;
}
}
}
block_62:
{
lean_object* x_60; lean_object* x_61; 
if (lean_is_scalar(x_53)) {
 x_60 = lean_alloc_ctor(0, 1, 0);
} else {
 x_60 = x_53;
 lean_ctor_set_tag(x_60, 0);
}
lean_ctor_set(x_60, 0, x_59);
if (lean_is_scalar(x_58)) {
 x_61 = lean_alloc_ctor(0, 2, 0);
} else {
 x_61 = x_58;
}
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_57);
return x_61;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
lean_dec(x_53);
lean_dec(x_52);
x_76 = lean_ctor_get(x_55, 0);
lean_inc(x_76);
x_77 = lean_ctor_get(x_55, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_78 = x_55;
} else {
 lean_dec_ref(x_55);
 x_78 = lean_box(0);
}
if (lean_is_scalar(x_78)) {
 x_79 = lean_alloc_ctor(1, 2, 0);
} else {
 x_79 = x_78;
}
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_77);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_80 = !lean_is_exclusive(x_14);
if (x_80 == 0)
{
return x_14;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_14, 0);
x_82 = lean_ctor_get(x_14, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_14);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceULT___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceULT___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceULT(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceULT", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceULT___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceULT___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULT___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4816_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceULE___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ule", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULE___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULE___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceULE___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_25, 1);
lean_inc(x_39);
lean_dec(x_25);
x_40 = lean_ctor_get(x_37, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_37, 1);
lean_inc(x_41);
lean_dec(x_37);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
lean_dec(x_38);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_31);
lean_dec(x_26);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_43);
return x_14;
}
else
{
uint8_t x_44; 
lean_free_object(x_14);
x_44 = lean_nat_dec_le(x_39, x_41);
lean_dec(x_41);
lean_dec(x_39);
if (x_44 == 0)
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_45;
goto block_35;
}
else
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_46;
goto block_35;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_47; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_47 = !lean_is_exclusive(x_28);
if (x_47 == 0)
{
return x_28;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_28, 0);
x_49 = lean_ctor_get(x_28, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_28);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_14, 1);
lean_inc(x_51);
lean_dec(x_14);
x_52 = lean_ctor_get(x_15, 0);
lean_inc(x_52);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_53 = x_15;
} else {
 lean_dec_ref(x_15);
 x_53 = lean_box(0);
}
x_54 = l_Lean_Expr_appArg_x21(x_1);
x_55 = l_BitVec_fromExpr_x3f___redArg(x_54, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_55) == 0)
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_55, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_55, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_58 = x_55;
} else {
 lean_dec_ref(x_55);
 x_58 = lean_box(0);
}
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_63; lean_object* x_64; 
lean_dec(x_58);
lean_dec(x_53);
lean_dec(x_52);
x_63 = l_BitVec_reduceUnary___redArg___closed__0;
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_57);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_65 = lean_ctor_get(x_56, 0);
lean_inc(x_65);
lean_dec(x_56);
x_66 = lean_ctor_get(x_52, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_52, 1);
lean_inc(x_67);
lean_dec(x_52);
x_68 = lean_ctor_get(x_65, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_65, 1);
lean_inc(x_69);
lean_dec(x_65);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
lean_dec(x_66);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_58);
lean_dec(x_53);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
x_72 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_57);
return x_72;
}
else
{
uint8_t x_73; 
x_73 = lean_nat_dec_le(x_67, x_69);
lean_dec(x_69);
lean_dec(x_67);
if (x_73 == 0)
{
lean_object* x_74; 
x_74 = l_BitVec_reduceGetBit___redArg___closed__3;
x_59 = x_74;
goto block_62;
}
else
{
lean_object* x_75; 
x_75 = l_BitVec_reduceGetBit___redArg___closed__6;
x_59 = x_75;
goto block_62;
}
}
}
block_62:
{
lean_object* x_60; lean_object* x_61; 
if (lean_is_scalar(x_53)) {
 x_60 = lean_alloc_ctor(0, 1, 0);
} else {
 x_60 = x_53;
 lean_ctor_set_tag(x_60, 0);
}
lean_ctor_set(x_60, 0, x_59);
if (lean_is_scalar(x_58)) {
 x_61 = lean_alloc_ctor(0, 2, 0);
} else {
 x_61 = x_58;
}
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_57);
return x_61;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
lean_dec(x_53);
lean_dec(x_52);
x_76 = lean_ctor_get(x_55, 0);
lean_inc(x_76);
x_77 = lean_ctor_get(x_55, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_78 = x_55;
} else {
 lean_dec_ref(x_55);
 x_78 = lean_box(0);
}
if (lean_is_scalar(x_78)) {
 x_79 = lean_alloc_ctor(1, 2, 0);
} else {
 x_79 = x_78;
}
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_77);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_80 = !lean_is_exclusive(x_14);
if (x_80 == 0)
{
return x_14;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_14, 0);
x_82 = lean_ctor_get(x_14, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_14);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceULE___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceULE___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceULE(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceULE", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceULE___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceULE___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULE___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4839_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSLT___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("slt", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLT___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLT___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSLT___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_25, 1);
lean_inc(x_39);
lean_dec(x_25);
x_40 = lean_ctor_get(x_37, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_37, 1);
lean_inc(x_41);
lean_dec(x_37);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_38);
lean_dec(x_31);
lean_dec(x_26);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_43);
return x_14;
}
else
{
uint8_t x_44; 
lean_free_object(x_14);
x_44 = l_BitVec_slt(x_38, x_39, x_41);
lean_dec(x_38);
if (x_44 == 0)
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_45;
goto block_35;
}
else
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_46;
goto block_35;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_47; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_47 = !lean_is_exclusive(x_28);
if (x_47 == 0)
{
return x_28;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_28, 0);
x_49 = lean_ctor_get(x_28, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_28);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_14, 1);
lean_inc(x_51);
lean_dec(x_14);
x_52 = lean_ctor_get(x_15, 0);
lean_inc(x_52);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_53 = x_15;
} else {
 lean_dec_ref(x_15);
 x_53 = lean_box(0);
}
x_54 = l_Lean_Expr_appArg_x21(x_1);
x_55 = l_BitVec_fromExpr_x3f___redArg(x_54, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_55) == 0)
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_55, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_55, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_58 = x_55;
} else {
 lean_dec_ref(x_55);
 x_58 = lean_box(0);
}
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_63; lean_object* x_64; 
lean_dec(x_58);
lean_dec(x_53);
lean_dec(x_52);
x_63 = l_BitVec_reduceUnary___redArg___closed__0;
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_57);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_65 = lean_ctor_get(x_56, 0);
lean_inc(x_65);
lean_dec(x_56);
x_66 = lean_ctor_get(x_52, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_52, 1);
lean_inc(x_67);
lean_dec(x_52);
x_68 = lean_ctor_get(x_65, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_65, 1);
lean_inc(x_69);
lean_dec(x_65);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
lean_dec(x_58);
lean_dec(x_53);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
x_72 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_57);
return x_72;
}
else
{
uint8_t x_73; 
x_73 = l_BitVec_slt(x_66, x_67, x_69);
lean_dec(x_66);
if (x_73 == 0)
{
lean_object* x_74; 
x_74 = l_BitVec_reduceGetBit___redArg___closed__3;
x_59 = x_74;
goto block_62;
}
else
{
lean_object* x_75; 
x_75 = l_BitVec_reduceGetBit___redArg___closed__6;
x_59 = x_75;
goto block_62;
}
}
}
block_62:
{
lean_object* x_60; lean_object* x_61; 
if (lean_is_scalar(x_53)) {
 x_60 = lean_alloc_ctor(0, 1, 0);
} else {
 x_60 = x_53;
 lean_ctor_set_tag(x_60, 0);
}
lean_ctor_set(x_60, 0, x_59);
if (lean_is_scalar(x_58)) {
 x_61 = lean_alloc_ctor(0, 2, 0);
} else {
 x_61 = x_58;
}
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_57);
return x_61;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
lean_dec(x_53);
lean_dec(x_52);
x_76 = lean_ctor_get(x_55, 0);
lean_inc(x_76);
x_77 = lean_ctor_get(x_55, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_78 = x_55;
} else {
 lean_dec_ref(x_55);
 x_78 = lean_box(0);
}
if (lean_is_scalar(x_78)) {
 x_79 = lean_alloc_ctor(1, 2, 0);
} else {
 x_79 = x_78;
}
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_77);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_80 = !lean_is_exclusive(x_14);
if (x_80 == 0)
{
return x_14;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_14, 0);
x_82 = lean_ctor_get(x_14, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_14);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSLT___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSLT___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSLT(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSLT", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSLT___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSLT___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLT___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4862_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSLE___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("sle", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLE___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLE___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSLE___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_14 = l_BitVec_fromExpr_x3f___redArg(x_13, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = lean_ctor_get(x_15, 0);
lean_inc(x_25);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_26 = x_15;
} else {
 lean_dec_ref(x_15);
 x_26 = lean_box(0);
}
x_27 = l_Lean_Expr_appArg_x21(x_1);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_27, x_2, x_3, x_4, x_5, x_23);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
x_30 = lean_ctor_get(x_28, 1);
lean_inc(x_30);
if (lean_is_exclusive(x_28)) {
 lean_ctor_release(x_28, 0);
 lean_ctor_release(x_28, 1);
 x_31 = x_28;
} else {
 lean_dec_ref(x_28);
 x_31 = lean_box(0);
}
if (lean_obj_tag(x_29) == 0)
{
lean_object* x_36; 
lean_dec(x_31);
lean_dec(x_26);
lean_dec(x_25);
x_36 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_36);
return x_14;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
x_38 = lean_ctor_get(x_25, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_25, 1);
lean_inc(x_39);
lean_dec(x_25);
x_40 = lean_ctor_get(x_37, 0);
lean_inc(x_40);
x_41 = lean_ctor_get(x_37, 1);
lean_inc(x_41);
lean_dec(x_37);
x_42 = lean_nat_dec_eq(x_38, x_40);
lean_dec(x_40);
if (x_42 == 0)
{
lean_object* x_43; 
lean_dec(x_41);
lean_dec(x_39);
lean_dec(x_38);
lean_dec(x_31);
lean_dec(x_26);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_14, 1, x_30);
lean_ctor_set(x_14, 0, x_43);
return x_14;
}
else
{
uint8_t x_44; 
lean_free_object(x_14);
x_44 = l_BitVec_sle(x_38, x_39, x_41);
lean_dec(x_38);
if (x_44 == 0)
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___redArg___closed__3;
x_32 = x_45;
goto block_35;
}
else
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___redArg___closed__6;
x_32 = x_46;
goto block_35;
}
}
}
block_35:
{
lean_object* x_33; lean_object* x_34; 
if (lean_is_scalar(x_26)) {
 x_33 = lean_alloc_ctor(0, 1, 0);
} else {
 x_33 = x_26;
 lean_ctor_set_tag(x_33, 0);
}
lean_ctor_set(x_33, 0, x_32);
if (lean_is_scalar(x_31)) {
 x_34 = lean_alloc_ctor(0, 2, 0);
} else {
 x_34 = x_31;
}
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_30);
return x_34;
}
}
else
{
uint8_t x_47; 
lean_dec(x_26);
lean_dec(x_25);
lean_free_object(x_14);
x_47 = !lean_is_exclusive(x_28);
if (x_47 == 0)
{
return x_28;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_28, 0);
x_49 = lean_ctor_get(x_28, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_28);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_51 = lean_ctor_get(x_14, 1);
lean_inc(x_51);
lean_dec(x_14);
x_52 = lean_ctor_get(x_15, 0);
lean_inc(x_52);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_53 = x_15;
} else {
 lean_dec_ref(x_15);
 x_53 = lean_box(0);
}
x_54 = l_Lean_Expr_appArg_x21(x_1);
x_55 = l_BitVec_fromExpr_x3f___redArg(x_54, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_55) == 0)
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_56 = lean_ctor_get(x_55, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_55, 1);
lean_inc(x_57);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_58 = x_55;
} else {
 lean_dec_ref(x_55);
 x_58 = lean_box(0);
}
if (lean_obj_tag(x_56) == 0)
{
lean_object* x_63; lean_object* x_64; 
lean_dec(x_58);
lean_dec(x_53);
lean_dec(x_52);
x_63 = l_BitVec_reduceUnary___redArg___closed__0;
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_57);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; uint8_t x_70; 
x_65 = lean_ctor_get(x_56, 0);
lean_inc(x_65);
lean_dec(x_56);
x_66 = lean_ctor_get(x_52, 0);
lean_inc(x_66);
x_67 = lean_ctor_get(x_52, 1);
lean_inc(x_67);
lean_dec(x_52);
x_68 = lean_ctor_get(x_65, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_65, 1);
lean_inc(x_69);
lean_dec(x_65);
x_70 = lean_nat_dec_eq(x_66, x_68);
lean_dec(x_68);
if (x_70 == 0)
{
lean_object* x_71; lean_object* x_72; 
lean_dec(x_69);
lean_dec(x_67);
lean_dec(x_66);
lean_dec(x_58);
lean_dec(x_53);
x_71 = l_BitVec_reduceUnary___redArg___closed__0;
x_72 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_72, 0, x_71);
lean_ctor_set(x_72, 1, x_57);
return x_72;
}
else
{
uint8_t x_73; 
x_73 = l_BitVec_sle(x_66, x_67, x_69);
lean_dec(x_66);
if (x_73 == 0)
{
lean_object* x_74; 
x_74 = l_BitVec_reduceGetBit___redArg___closed__3;
x_59 = x_74;
goto block_62;
}
else
{
lean_object* x_75; 
x_75 = l_BitVec_reduceGetBit___redArg___closed__6;
x_59 = x_75;
goto block_62;
}
}
}
block_62:
{
lean_object* x_60; lean_object* x_61; 
if (lean_is_scalar(x_53)) {
 x_60 = lean_alloc_ctor(0, 1, 0);
} else {
 x_60 = x_53;
 lean_ctor_set_tag(x_60, 0);
}
lean_ctor_set(x_60, 0, x_59);
if (lean_is_scalar(x_58)) {
 x_61 = lean_alloc_ctor(0, 2, 0);
} else {
 x_61 = x_58;
}
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_57);
return x_61;
}
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; 
lean_dec(x_53);
lean_dec(x_52);
x_76 = lean_ctor_get(x_55, 0);
lean_inc(x_76);
x_77 = lean_ctor_get(x_55, 1);
lean_inc(x_77);
if (lean_is_exclusive(x_55)) {
 lean_ctor_release(x_55, 0);
 lean_ctor_release(x_55, 1);
 x_78 = x_55;
} else {
 lean_dec_ref(x_55);
 x_78 = lean_box(0);
}
if (lean_is_scalar(x_78)) {
 x_79 = lean_alloc_ctor(1, 2, 0);
} else {
 x_79 = x_78;
}
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_77);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_80 = !lean_is_exclusive(x_14);
if (x_80 == 0)
{
return x_14;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_14, 0);
x_82 = lean_ctor_get(x_14, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_14);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSLE___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSLE___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSLE(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSLE", 9, 9);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSLE___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSLE___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLE___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4885_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth_x27___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("setWidth'", 9, 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth_x27___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSetWidth_x27___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; uint8_t x_20; 
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_20 = l_Lean_Expr_isApp(x_19);
if (x_20 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_21; lean_object* x_22; uint8_t x_23; 
x_21 = lean_ctor_get(x_19, 1);
lean_inc(x_21);
x_22 = l_Lean_Expr_appFnCleanup___redArg(x_19);
x_23 = l_Lean_Expr_isApp(x_22);
if (x_23 == 0)
{
lean_dec(x_22);
lean_dec(x_21);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appFnCleanup___redArg(x_22);
x_25 = l_BitVec_reduceSetWidth_x27___redArg___closed__1;
x_26 = l_Lean_Expr_isConstOf(x_24, x_25);
lean_dec(x_24);
if (x_26 == 0)
{
lean_dec(x_21);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_27; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_27 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_27) == 0)
{
lean_object* x_28; 
x_28 = lean_ctor_get(x_27, 0);
lean_inc(x_28);
if (lean_obj_tag(x_28) == 0)
{
uint8_t x_29; 
lean_dec(x_21);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_29 = !lean_is_exclusive(x_27);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; 
x_30 = lean_ctor_get(x_27, 0);
lean_dec(x_30);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_27, 0, x_31);
return x_27;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; 
x_32 = lean_ctor_get(x_27, 1);
lean_inc(x_32);
lean_dec(x_27);
x_33 = l_BitVec_reduceUnary___redArg___closed__0;
x_34 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_34, 1, x_32);
return x_34;
}
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; 
x_35 = lean_ctor_get(x_27, 1);
lean_inc(x_35);
lean_dec(x_27);
x_36 = lean_ctor_get(x_28, 0);
lean_inc(x_36);
lean_dec(x_28);
x_37 = l_Lean_Meta_getNatValue_x3f(x_21, x_2, x_3, x_4, x_5, x_35);
lean_dec(x_21);
if (lean_obj_tag(x_37) == 0)
{
lean_object* x_38; 
x_38 = lean_ctor_get(x_37, 0);
lean_inc(x_38);
if (lean_obj_tag(x_38) == 0)
{
uint8_t x_39; 
lean_dec(x_36);
x_39 = !lean_is_exclusive(x_37);
if (x_39 == 0)
{
lean_object* x_40; lean_object* x_41; 
x_40 = lean_ctor_get(x_37, 0);
lean_dec(x_40);
x_41 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_37, 0, x_41);
return x_37;
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; 
x_42 = lean_ctor_get(x_37, 1);
lean_inc(x_42);
lean_dec(x_37);
x_43 = l_BitVec_reduceUnary___redArg___closed__0;
x_44 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_44, 1, x_42);
return x_44;
}
}
else
{
uint8_t x_45; 
x_45 = !lean_is_exclusive(x_37);
if (x_45 == 0)
{
lean_object* x_46; uint8_t x_47; 
x_46 = lean_ctor_get(x_37, 0);
lean_dec(x_46);
x_47 = !lean_is_exclusive(x_38);
if (x_47 == 0)
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_48 = lean_ctor_get(x_38, 0);
x_49 = lean_ctor_get(x_36, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_36, 1);
lean_inc(x_50);
lean_dec(x_36);
x_51 = lean_nat_dec_le(x_49, x_48);
lean_dec(x_49);
if (x_51 == 0)
{
lean_object* x_52; 
lean_dec(x_50);
lean_free_object(x_38);
lean_dec(x_48);
x_52 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_37, 0, x_52);
return x_37;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_53 = l_BitVec_reduceUnary___redArg___closed__4;
x_54 = l_Lean_mkNatLit(x_48);
x_55 = l_Lean_mkNatLit(x_50);
x_56 = l_Lean_mkAppB(x_53, x_54, x_55);
lean_ctor_set_tag(x_38, 0);
lean_ctor_set(x_38, 0, x_56);
return x_37;
}
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; uint8_t x_60; 
x_57 = lean_ctor_get(x_38, 0);
lean_inc(x_57);
lean_dec(x_38);
x_58 = lean_ctor_get(x_36, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_36, 1);
lean_inc(x_59);
lean_dec(x_36);
x_60 = lean_nat_dec_le(x_58, x_57);
lean_dec(x_58);
if (x_60 == 0)
{
lean_object* x_61; 
lean_dec(x_59);
lean_dec(x_57);
x_61 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_37, 0, x_61);
return x_37;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_62 = l_BitVec_reduceUnary___redArg___closed__4;
x_63 = l_Lean_mkNatLit(x_57);
x_64 = l_Lean_mkNatLit(x_59);
x_65 = l_Lean_mkAppB(x_62, x_63, x_64);
x_66 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_66, 0, x_65);
lean_ctor_set(x_37, 0, x_66);
return x_37;
}
}
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; uint8_t x_72; 
x_67 = lean_ctor_get(x_37, 1);
lean_inc(x_67);
lean_dec(x_37);
x_68 = lean_ctor_get(x_38, 0);
lean_inc(x_68);
if (lean_is_exclusive(x_38)) {
 lean_ctor_release(x_38, 0);
 x_69 = x_38;
} else {
 lean_dec_ref(x_38);
 x_69 = lean_box(0);
}
x_70 = lean_ctor_get(x_36, 0);
lean_inc(x_70);
x_71 = lean_ctor_get(x_36, 1);
lean_inc(x_71);
lean_dec(x_36);
x_72 = lean_nat_dec_le(x_70, x_68);
lean_dec(x_70);
if (x_72 == 0)
{
lean_object* x_73; lean_object* x_74; 
lean_dec(x_71);
lean_dec(x_69);
lean_dec(x_68);
x_73 = l_BitVec_reduceUnary___redArg___closed__0;
x_74 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_74, 0, x_73);
lean_ctor_set(x_74, 1, x_67);
return x_74;
}
else
{
lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; 
x_75 = l_BitVec_reduceUnary___redArg___closed__4;
x_76 = l_Lean_mkNatLit(x_68);
x_77 = l_Lean_mkNatLit(x_71);
x_78 = l_Lean_mkAppB(x_75, x_76, x_77);
if (lean_is_scalar(x_69)) {
 x_79 = lean_alloc_ctor(0, 1, 0);
} else {
 x_79 = x_69;
 lean_ctor_set_tag(x_79, 0);
}
lean_ctor_set(x_79, 0, x_78);
x_80 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_80, 0, x_79);
lean_ctor_set(x_80, 1, x_67);
return x_80;
}
}
}
}
else
{
uint8_t x_81; 
lean_dec(x_36);
x_81 = !lean_is_exclusive(x_37);
if (x_81 == 0)
{
return x_37;
}
else
{
lean_object* x_82; lean_object* x_83; lean_object* x_84; 
x_82 = lean_ctor_get(x_37, 0);
x_83 = lean_ctor_get(x_37, 1);
lean_inc(x_83);
lean_inc(x_82);
lean_dec(x_37);
x_84 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_84, 0, x_82);
lean_ctor_set(x_84, 1, x_83);
return x_84;
}
}
}
}
else
{
uint8_t x_85; 
lean_dec(x_21);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_85 = !lean_is_exclusive(x_27);
if (x_85 == 0)
{
return x_27;
}
else
{
lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_86 = lean_ctor_get(x_27, 0);
x_87 = lean_ctor_get(x_27, 1);
lean_inc(x_87);
lean_inc(x_86);
lean_dec(x_27);
x_88 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_88, 0, x_86);
lean_ctor_set(x_88, 1, x_87);
return x_88;
}
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSetWidth_x27___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSetWidth_x27(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSetWidth'", 15, 15);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceSetWidth_x27___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSetWidth_x27___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSetWidth_x27___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5211_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("shiftLeftZeroExtend", 19, 19);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_dec(x_20);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; lean_object* x_23; uint8_t x_24; 
x_22 = l_Lean_Expr_appFnCleanup___redArg(x_20);
x_23 = l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1;
x_24 = l_Lean_Expr_isConstOf(x_22, x_23);
lean_dec(x_22);
if (x_24 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_25; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_19, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_33 = lean_ctor_get(x_25, 1);
lean_inc(x_33);
lean_dec(x_25);
x_34 = lean_ctor_get(x_26, 0);
lean_inc(x_34);
lean_dec(x_26);
x_35 = l_Lean_Meta_getNatValue_x3f(x_16, x_2, x_3, x_4, x_5, x_33);
lean_dec(x_16);
if (lean_obj_tag(x_35) == 0)
{
lean_object* x_36; 
x_36 = lean_ctor_get(x_35, 0);
lean_inc(x_36);
if (lean_obj_tag(x_36) == 0)
{
uint8_t x_37; 
lean_dec(x_34);
x_37 = !lean_is_exclusive(x_35);
if (x_37 == 0)
{
lean_object* x_38; lean_object* x_39; 
x_38 = lean_ctor_get(x_35, 0);
lean_dec(x_38);
x_39 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_35, 0, x_39);
return x_35;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = l_BitVec_reduceUnary___redArg___closed__0;
x_42 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_42, 1, x_40);
return x_42;
}
}
else
{
uint8_t x_43; 
x_43 = !lean_is_exclusive(x_35);
if (x_43 == 0)
{
lean_object* x_44; uint8_t x_45; 
x_44 = lean_ctor_get(x_35, 0);
lean_dec(x_44);
x_45 = !lean_is_exclusive(x_36);
if (x_45 == 0)
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_46 = lean_ctor_get(x_36, 0);
x_47 = lean_ctor_get(x_34, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_34, 1);
lean_inc(x_48);
lean_dec(x_34);
x_49 = lean_nat_add(x_47, x_46);
lean_dec(x_47);
x_50 = lean_nat_shiftl(x_48, x_46);
lean_dec(x_46);
lean_dec(x_48);
x_51 = l_BitVec_reduceUnary___redArg___closed__4;
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_50);
x_54 = l_Lean_mkAppB(x_51, x_52, x_53);
lean_ctor_set_tag(x_36, 0);
lean_ctor_set(x_36, 0, x_54);
return x_35;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_55 = lean_ctor_get(x_36, 0);
lean_inc(x_55);
lean_dec(x_36);
x_56 = lean_ctor_get(x_34, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_34, 1);
lean_inc(x_57);
lean_dec(x_34);
x_58 = lean_nat_add(x_56, x_55);
lean_dec(x_56);
x_59 = lean_nat_shiftl(x_57, x_55);
lean_dec(x_55);
lean_dec(x_57);
x_60 = l_BitVec_reduceUnary___redArg___closed__4;
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkNatLit(x_59);
x_63 = l_Lean_mkAppB(x_60, x_61, x_62);
x_64 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_35, 0, x_64);
return x_35;
}
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; 
x_65 = lean_ctor_get(x_35, 1);
lean_inc(x_65);
lean_dec(x_35);
x_66 = lean_ctor_get(x_36, 0);
lean_inc(x_66);
if (lean_is_exclusive(x_36)) {
 lean_ctor_release(x_36, 0);
 x_67 = x_36;
} else {
 lean_dec_ref(x_36);
 x_67 = lean_box(0);
}
x_68 = lean_ctor_get(x_34, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_34, 1);
lean_inc(x_69);
lean_dec(x_34);
x_70 = lean_nat_add(x_68, x_66);
lean_dec(x_68);
x_71 = lean_nat_shiftl(x_69, x_66);
lean_dec(x_66);
lean_dec(x_69);
x_72 = l_BitVec_reduceUnary___redArg___closed__4;
x_73 = l_Lean_mkNatLit(x_70);
x_74 = l_Lean_mkNatLit(x_71);
x_75 = l_Lean_mkAppB(x_72, x_73, x_74);
if (lean_is_scalar(x_67)) {
 x_76 = lean_alloc_ctor(0, 1, 0);
} else {
 x_76 = x_67;
 lean_ctor_set_tag(x_76, 0);
}
lean_ctor_set(x_76, 0, x_75);
x_77 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_77, 0, x_76);
lean_ctor_set(x_77, 1, x_65);
return x_77;
}
}
}
else
{
uint8_t x_78; 
lean_dec(x_34);
x_78 = !lean_is_exclusive(x_35);
if (x_78 == 0)
{
return x_35;
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; 
x_79 = lean_ctor_get(x_35, 0);
x_80 = lean_ctor_get(x_35, 1);
lean_inc(x_80);
lean_inc(x_79);
lean_dec(x_35);
x_81 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_81, 0, x_79);
lean_ctor_set(x_81, 1, x_80);
return x_81;
}
}
}
}
else
{
uint8_t x_82; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_82 = !lean_is_exclusive(x_25);
if (x_82 == 0)
{
return x_25;
}
else
{
lean_object* x_83; lean_object* x_84; lean_object* x_85; 
x_83 = lean_ctor_get(x_25, 0);
x_84 = lean_ctor_get(x_25, 1);
lean_inc(x_84);
lean_inc(x_83);
lean_dec(x_25);
x_85 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
return x_85;
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeftZeroExtend___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeftZeroExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceShiftLeftZeroExtend", 25, 25);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftZeroExtend___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftZeroExtend___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5479_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("extractLsb'", 11, 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceExtracLsb_x27___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_dec(x_20);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; lean_object* x_23; uint8_t x_24; 
x_22 = lean_ctor_get(x_20, 1);
lean_inc(x_22);
x_23 = l_Lean_Expr_appFnCleanup___redArg(x_20);
x_24 = l_Lean_Expr_isApp(x_23);
if (x_24 == 0)
{
lean_dec(x_23);
lean_dec(x_22);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_25; lean_object* x_26; uint8_t x_27; 
x_25 = l_Lean_Expr_appFnCleanup___redArg(x_23);
x_26 = l_BitVec_reduceExtracLsb_x27___redArg___closed__1;
x_27 = l_Lean_Expr_isConstOf(x_25, x_26);
lean_dec(x_25);
if (x_27 == 0)
{
lean_dec(x_22);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_28; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_28 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_28) == 0)
{
lean_object* x_29; 
x_29 = lean_ctor_get(x_28, 0);
lean_inc(x_29);
if (lean_obj_tag(x_29) == 0)
{
uint8_t x_30; 
lean_dec(x_22);
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_30 = !lean_is_exclusive(x_28);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; 
x_31 = lean_ctor_get(x_28, 0);
lean_dec(x_31);
x_32 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_28, 0, x_32);
return x_28;
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_33 = lean_ctor_get(x_28, 1);
lean_inc(x_33);
lean_dec(x_28);
x_34 = l_BitVec_reduceUnary___redArg___closed__0;
x_35 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_35, 0, x_34);
lean_ctor_set(x_35, 1, x_33);
return x_35;
}
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_36 = lean_ctor_get(x_28, 1);
lean_inc(x_36);
lean_dec(x_28);
x_37 = lean_ctor_get(x_29, 0);
lean_inc(x_37);
lean_dec(x_29);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_38 = l_Lean_Meta_getNatValue_x3f(x_22, x_2, x_3, x_4, x_5, x_36);
lean_dec(x_22);
if (lean_obj_tag(x_38) == 0)
{
lean_object* x_39; 
x_39 = lean_ctor_get(x_38, 0);
lean_inc(x_39);
if (lean_obj_tag(x_39) == 0)
{
uint8_t x_40; 
lean_dec(x_37);
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_40 = !lean_is_exclusive(x_38);
if (x_40 == 0)
{
lean_object* x_41; lean_object* x_42; 
x_41 = lean_ctor_get(x_38, 0);
lean_dec(x_41);
x_42 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_38, 0, x_42);
return x_38;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_43 = lean_ctor_get(x_38, 1);
lean_inc(x_43);
lean_dec(x_38);
x_44 = l_BitVec_reduceUnary___redArg___closed__0;
x_45 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_45, 0, x_44);
lean_ctor_set(x_45, 1, x_43);
return x_45;
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; 
x_46 = lean_ctor_get(x_38, 1);
lean_inc(x_46);
lean_dec(x_38);
x_47 = lean_ctor_get(x_39, 0);
lean_inc(x_47);
lean_dec(x_39);
x_48 = l_Lean_Meta_getNatValue_x3f(x_19, x_2, x_3, x_4, x_5, x_46);
lean_dec(x_19);
if (lean_obj_tag(x_48) == 0)
{
lean_object* x_49; 
x_49 = lean_ctor_get(x_48, 0);
lean_inc(x_49);
if (lean_obj_tag(x_49) == 0)
{
uint8_t x_50; 
lean_dec(x_47);
lean_dec(x_37);
x_50 = !lean_is_exclusive(x_48);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
x_51 = lean_ctor_get(x_48, 0);
lean_dec(x_51);
x_52 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_48, 0, x_52);
return x_48;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_53 = lean_ctor_get(x_48, 1);
lean_inc(x_53);
lean_dec(x_48);
x_54 = l_BitVec_reduceUnary___redArg___closed__0;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_53);
return x_55;
}
}
else
{
uint8_t x_56; 
x_56 = !lean_is_exclusive(x_48);
if (x_56 == 0)
{
lean_object* x_57; uint8_t x_58; 
x_57 = lean_ctor_get(x_48, 0);
lean_dec(x_57);
x_58 = !lean_is_exclusive(x_49);
if (x_58 == 0)
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_59 = lean_ctor_get(x_49, 0);
x_60 = lean_ctor_get(x_37, 1);
lean_inc(x_60);
lean_dec(x_37);
x_61 = l_BitVec_extractLsb_x27___redArg(x_47, x_59, x_60);
lean_dec(x_60);
lean_dec(x_47);
x_62 = l_BitVec_reduceUnary___redArg___closed__4;
x_63 = l_Lean_mkNatLit(x_59);
x_64 = l_Lean_mkNatLit(x_61);
x_65 = l_Lean_mkAppB(x_62, x_63, x_64);
lean_ctor_set_tag(x_49, 0);
lean_ctor_set(x_49, 0, x_65);
return x_48;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; 
x_66 = lean_ctor_get(x_49, 0);
lean_inc(x_66);
lean_dec(x_49);
x_67 = lean_ctor_get(x_37, 1);
lean_inc(x_67);
lean_dec(x_37);
x_68 = l_BitVec_extractLsb_x27___redArg(x_47, x_66, x_67);
lean_dec(x_67);
lean_dec(x_47);
x_69 = l_BitVec_reduceUnary___redArg___closed__4;
x_70 = l_Lean_mkNatLit(x_66);
x_71 = l_Lean_mkNatLit(x_68);
x_72 = l_Lean_mkAppB(x_69, x_70, x_71);
x_73 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_73, 0, x_72);
lean_ctor_set(x_48, 0, x_73);
return x_48;
}
}
else
{
lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; 
x_74 = lean_ctor_get(x_48, 1);
lean_inc(x_74);
lean_dec(x_48);
x_75 = lean_ctor_get(x_49, 0);
lean_inc(x_75);
if (lean_is_exclusive(x_49)) {
 lean_ctor_release(x_49, 0);
 x_76 = x_49;
} else {
 lean_dec_ref(x_49);
 x_76 = lean_box(0);
}
x_77 = lean_ctor_get(x_37, 1);
lean_inc(x_77);
lean_dec(x_37);
x_78 = l_BitVec_extractLsb_x27___redArg(x_47, x_75, x_77);
lean_dec(x_77);
lean_dec(x_47);
x_79 = l_BitVec_reduceUnary___redArg___closed__4;
x_80 = l_Lean_mkNatLit(x_75);
x_81 = l_Lean_mkNatLit(x_78);
x_82 = l_Lean_mkAppB(x_79, x_80, x_81);
if (lean_is_scalar(x_76)) {
 x_83 = lean_alloc_ctor(0, 1, 0);
} else {
 x_83 = x_76;
 lean_ctor_set_tag(x_83, 0);
}
lean_ctor_set(x_83, 0, x_82);
x_84 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_84, 0, x_83);
lean_ctor_set(x_84, 1, x_74);
return x_84;
}
}
}
else
{
uint8_t x_85; 
lean_dec(x_47);
lean_dec(x_37);
x_85 = !lean_is_exclusive(x_48);
if (x_85 == 0)
{
return x_48;
}
else
{
lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_86 = lean_ctor_get(x_48, 0);
x_87 = lean_ctor_get(x_48, 1);
lean_inc(x_87);
lean_inc(x_86);
lean_dec(x_48);
x_88 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_88, 0, x_86);
lean_ctor_set(x_88, 1, x_87);
return x_88;
}
}
}
}
else
{
uint8_t x_89; 
lean_dec(x_37);
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_89 = !lean_is_exclusive(x_38);
if (x_89 == 0)
{
return x_38;
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; 
x_90 = lean_ctor_get(x_38, 0);
x_91 = lean_ctor_get(x_38, 1);
lean_inc(x_91);
lean_inc(x_90);
lean_dec(x_38);
x_92 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_92, 0, x_90);
lean_ctor_set(x_92, 1, x_91);
return x_92;
}
}
}
}
else
{
uint8_t x_93; 
lean_dec(x_22);
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_93 = !lean_is_exclusive(x_28);
if (x_93 == 0)
{
return x_28;
}
else
{
lean_object* x_94; lean_object* x_95; lean_object* x_96; 
x_94 = lean_ctor_get(x_28, 0);
x_95 = lean_ctor_get(x_28, 1);
lean_inc(x_95);
lean_inc(x_94);
lean_dec(x_28);
x_96 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_96, 0, x_94);
lean_ctor_set(x_96, 1, x_95);
return x_96;
}
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceExtracLsb_x27___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceExtracLsb_x27(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceExtracLsb'", 16, 16);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = l_BitVec_reduceExtracLsb_x27___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceExtracLsb_x27___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceExtracLsb_x27___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5827_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("replicate", 9, 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceReplicate___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_dec(x_20);
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; lean_object* x_23; uint8_t x_24; 
x_22 = l_Lean_Expr_appFnCleanup___redArg(x_20);
x_23 = l_BitVec_reduceReplicate___redArg___closed__1;
x_24 = l_Lean_Expr_isConstOf(x_22, x_23);
lean_dec(x_22);
if (x_24 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_25; 
lean_dec(x_10);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_25 = l_BitVec_fromExpr_x3f___redArg(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_33 = lean_ctor_get(x_25, 1);
lean_inc(x_33);
lean_dec(x_25);
x_34 = lean_ctor_get(x_26, 0);
lean_inc(x_34);
lean_dec(x_26);
x_35 = l_Lean_Meta_getNatValue_x3f(x_19, x_2, x_3, x_4, x_5, x_33);
lean_dec(x_19);
if (lean_obj_tag(x_35) == 0)
{
lean_object* x_36; 
x_36 = lean_ctor_get(x_35, 0);
lean_inc(x_36);
if (lean_obj_tag(x_36) == 0)
{
uint8_t x_37; 
lean_dec(x_34);
x_37 = !lean_is_exclusive(x_35);
if (x_37 == 0)
{
lean_object* x_38; lean_object* x_39; 
x_38 = lean_ctor_get(x_35, 0);
lean_dec(x_38);
x_39 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_35, 0, x_39);
return x_35;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = l_BitVec_reduceUnary___redArg___closed__0;
x_42 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_42, 1, x_40);
return x_42;
}
}
else
{
uint8_t x_43; 
x_43 = !lean_is_exclusive(x_35);
if (x_43 == 0)
{
lean_object* x_44; uint8_t x_45; 
x_44 = lean_ctor_get(x_35, 0);
lean_dec(x_44);
x_45 = !lean_is_exclusive(x_36);
if (x_45 == 0)
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_46 = lean_ctor_get(x_36, 0);
x_47 = lean_ctor_get(x_34, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_34, 1);
lean_inc(x_48);
lean_dec(x_34);
x_49 = lean_nat_mul(x_47, x_46);
x_50 = l_BitVec_replicate(x_47, x_46, x_48);
lean_dec(x_48);
lean_dec(x_46);
lean_dec(x_47);
x_51 = l_BitVec_reduceUnary___redArg___closed__4;
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_50);
x_54 = l_Lean_mkAppB(x_51, x_52, x_53);
lean_ctor_set_tag(x_36, 0);
lean_ctor_set(x_36, 0, x_54);
return x_35;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_55 = lean_ctor_get(x_36, 0);
lean_inc(x_55);
lean_dec(x_36);
x_56 = lean_ctor_get(x_34, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_34, 1);
lean_inc(x_57);
lean_dec(x_34);
x_58 = lean_nat_mul(x_56, x_55);
x_59 = l_BitVec_replicate(x_56, x_55, x_57);
lean_dec(x_57);
lean_dec(x_55);
lean_dec(x_56);
x_60 = l_BitVec_reduceUnary___redArg___closed__4;
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkNatLit(x_59);
x_63 = l_Lean_mkAppB(x_60, x_61, x_62);
x_64 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_35, 0, x_64);
return x_35;
}
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; 
x_65 = lean_ctor_get(x_35, 1);
lean_inc(x_65);
lean_dec(x_35);
x_66 = lean_ctor_get(x_36, 0);
lean_inc(x_66);
if (lean_is_exclusive(x_36)) {
 lean_ctor_release(x_36, 0);
 x_67 = x_36;
} else {
 lean_dec_ref(x_36);
 x_67 = lean_box(0);
}
x_68 = lean_ctor_get(x_34, 0);
lean_inc(x_68);
x_69 = lean_ctor_get(x_34, 1);
lean_inc(x_69);
lean_dec(x_34);
x_70 = lean_nat_mul(x_68, x_66);
x_71 = l_BitVec_replicate(x_68, x_66, x_69);
lean_dec(x_69);
lean_dec(x_66);
lean_dec(x_68);
x_72 = l_BitVec_reduceUnary___redArg___closed__4;
x_73 = l_Lean_mkNatLit(x_70);
x_74 = l_Lean_mkNatLit(x_71);
x_75 = l_Lean_mkAppB(x_72, x_73, x_74);
if (lean_is_scalar(x_67)) {
 x_76 = lean_alloc_ctor(0, 1, 0);
} else {
 x_76 = x_67;
 lean_ctor_set_tag(x_76, 0);
}
lean_ctor_set(x_76, 0, x_75);
x_77 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_77, 0, x_76);
lean_ctor_set(x_77, 1, x_65);
return x_77;
}
}
}
else
{
uint8_t x_78; 
lean_dec(x_34);
x_78 = !lean_is_exclusive(x_35);
if (x_78 == 0)
{
return x_35;
}
else
{
lean_object* x_79; lean_object* x_80; lean_object* x_81; 
x_79 = lean_ctor_get(x_35, 0);
x_80 = lean_ctor_get(x_35, 1);
lean_inc(x_80);
lean_inc(x_79);
lean_dec(x_35);
x_81 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_81, 0, x_79);
lean_ctor_set(x_81, 1, x_80);
return x_81;
}
}
}
}
else
{
uint8_t x_82; 
lean_dec(x_19);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_82 = !lean_is_exclusive(x_25);
if (x_82 == 0)
{
return x_25;
}
else
{
lean_object* x_83; lean_object* x_84; lean_object* x_85; 
x_83 = lean_ctor_get(x_25, 0);
x_84 = lean_ctor_get(x_25, 1);
lean_inc(x_84);
lean_inc(x_83);
lean_dec(x_25);
x_85 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
return x_85;
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceReplicate___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceReplicate(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceReplicate", 15, 15);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceReplicate___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceReplicate___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceReplicate___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6095_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("setWidth", 8, 8);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSetWidth___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSetWidth___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appFn_x21(x_1);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_21);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_22, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_22, 1);
lean_inc(x_38);
lean_dec(x_22);
x_39 = l_BitVec_setWidth(x_37, x_36, x_38);
lean_dec(x_38);
lean_dec(x_37);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_36);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_setWidth(x_45, x_44, x_46);
lean_dec(x_46);
lean_dec(x_45);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_44);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_22, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_22, 1);
lean_inc(x_57);
lean_dec(x_22);
x_58 = l_BitVec_setWidth(x_56, x_54, x_57);
lean_dec(x_57);
lean_dec(x_56);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_54);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_22);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_13);
if (x_69 == 0)
{
return x_13;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_13, 0);
x_71 = lean_ctor_get(x_13, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_13);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSetWidth___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSetWidth___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSetWidth(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSetWidth", 14, 14);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSetWidth___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSetWidth___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSetWidth___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6117_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("zeroExtend", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceZeroExtend___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceZeroExtend___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appFn_x21(x_1);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_21);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_22, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_22, 1);
lean_inc(x_38);
lean_dec(x_22);
x_39 = l_BitVec_setWidth(x_37, x_36, x_38);
lean_dec(x_38);
lean_dec(x_37);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_36);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_setWidth(x_45, x_44, x_46);
lean_dec(x_46);
lean_dec(x_45);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_44);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_22, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_22, 1);
lean_inc(x_57);
lean_dec(x_22);
x_58 = l_BitVec_setWidth(x_56, x_54, x_57);
lean_dec(x_57);
lean_dec(x_56);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_54);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_22);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_13);
if (x_69 == 0)
{
return x_13;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_13, 0);
x_71 = lean_ctor_get(x_13, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_13);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceZeroExtend___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceZeroExtend___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceZeroExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceZeroExtend", 16, 16);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6139_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("signExtend", 10, 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSignExtend___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceSignExtend___redArg___closed__1;
x_8 = lean_unsigned_to_nat(3u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceUnary___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_BitVec_fromExpr_x3f___redArg(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appFn_x21(x_1);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_2, x_3, x_4, x_5, x_21);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___redArg___closed__0;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; uint8_t x_35; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = !lean_is_exclusive(x_26);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_36 = lean_ctor_get(x_26, 0);
x_37 = lean_ctor_get(x_22, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_22, 1);
lean_inc(x_38);
lean_dec(x_22);
x_39 = l_BitVec_signExtend(x_37, x_36, x_38);
lean_dec(x_37);
x_40 = l_BitVec_reduceUnary___redArg___closed__4;
x_41 = l_Lean_mkNatLit(x_36);
x_42 = l_Lean_mkNatLit(x_39);
x_43 = l_Lean_mkAppB(x_40, x_41, x_42);
lean_ctor_set_tag(x_26, 0);
lean_ctor_set(x_26, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_ctor_get(x_26, 0);
lean_inc(x_44);
lean_dec(x_26);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_signExtend(x_45, x_44, x_46);
lean_dec(x_45);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_44);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_25, 0, x_52);
return x_25;
}
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_53 = lean_ctor_get(x_25, 1);
lean_inc(x_53);
lean_dec(x_25);
x_54 = lean_ctor_get(x_26, 0);
lean_inc(x_54);
if (lean_is_exclusive(x_26)) {
 lean_ctor_release(x_26, 0);
 x_55 = x_26;
} else {
 lean_dec_ref(x_26);
 x_55 = lean_box(0);
}
x_56 = lean_ctor_get(x_22, 0);
lean_inc(x_56);
x_57 = lean_ctor_get(x_22, 1);
lean_inc(x_57);
lean_dec(x_22);
x_58 = l_BitVec_signExtend(x_56, x_54, x_57);
lean_dec(x_56);
x_59 = l_BitVec_reduceUnary___redArg___closed__4;
x_60 = l_Lean_mkNatLit(x_54);
x_61 = l_Lean_mkNatLit(x_58);
x_62 = l_Lean_mkAppB(x_59, x_60, x_61);
if (lean_is_scalar(x_55)) {
 x_63 = lean_alloc_ctor(0, 1, 0);
} else {
 x_63 = x_55;
 lean_ctor_set_tag(x_63, 0);
}
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_53);
return x_64;
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_22);
x_65 = !lean_is_exclusive(x_25);
if (x_65 == 0)
{
return x_25;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_25, 0);
x_67 = lean_ctor_get(x_25, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_25);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_69 = !lean_is_exclusive(x_13);
if (x_69 == 0)
{
return x_13;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_13, 0);
x_71 = lean_ctor_get(x_13, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_13);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSignExtend___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceSignExtend___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceSignExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceSignExtend", 16, 16);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = l_BitVec_reduceSignExtend___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceSignExtend___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSignExtend___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6161_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("allOnes", 7, 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAllOnes___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; uint8_t x_19; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_BitVec_reduceAllOnes___redArg___closed__1;
x_19 = l_Lean_Expr_isConstOf(x_17, x_18);
lean_dec(x_17);
if (x_19 == 0)
{
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_20; 
lean_dec(x_10);
x_20 = l_Lean_Meta_getNatValue_x3f(x_16, x_2, x_3, x_4, x_5, x_9);
lean_dec(x_16);
if (lean_obj_tag(x_20) == 0)
{
lean_object* x_21; 
x_21 = lean_ctor_get(x_20, 0);
lean_inc(x_21);
if (lean_obj_tag(x_21) == 0)
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_20);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; 
x_23 = lean_ctor_get(x_20, 0);
lean_dec(x_23);
x_24 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_20, 0, x_24);
return x_20;
}
else
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; 
x_25 = lean_ctor_get(x_20, 1);
lean_inc(x_25);
lean_dec(x_20);
x_26 = l_BitVec_reduceUnary___redArg___closed__0;
x_27 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_27, 0, x_26);
lean_ctor_set(x_27, 1, x_25);
return x_27;
}
}
else
{
uint8_t x_28; 
x_28 = !lean_is_exclusive(x_20);
if (x_28 == 0)
{
lean_object* x_29; uint8_t x_30; 
x_29 = lean_ctor_get(x_20, 0);
lean_dec(x_29);
x_30 = !lean_is_exclusive(x_21);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_31 = lean_ctor_get(x_21, 0);
x_32 = l_BitVec_allOnes(x_31);
x_33 = l_BitVec_reduceUnary___redArg___closed__4;
x_34 = l_Lean_mkNatLit(x_31);
x_35 = l_Lean_mkNatLit(x_32);
x_36 = l_Lean_mkAppB(x_33, x_34, x_35);
lean_ctor_set_tag(x_21, 0);
lean_ctor_set(x_21, 0, x_36);
return x_20;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_37 = lean_ctor_get(x_21, 0);
lean_inc(x_37);
lean_dec(x_21);
x_38 = l_BitVec_allOnes(x_37);
x_39 = l_BitVec_reduceUnary___redArg___closed__4;
x_40 = l_Lean_mkNatLit(x_37);
x_41 = l_Lean_mkNatLit(x_38);
x_42 = l_Lean_mkAppB(x_39, x_40, x_41);
x_43 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_43, 0, x_42);
lean_ctor_set(x_20, 0, x_43);
return x_20;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_44 = lean_ctor_get(x_20, 1);
lean_inc(x_44);
lean_dec(x_20);
x_45 = lean_ctor_get(x_21, 0);
lean_inc(x_45);
if (lean_is_exclusive(x_21)) {
 lean_ctor_release(x_21, 0);
 x_46 = x_21;
} else {
 lean_dec_ref(x_21);
 x_46 = lean_box(0);
}
x_47 = l_BitVec_allOnes(x_45);
x_48 = l_BitVec_reduceUnary___redArg___closed__4;
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_47);
x_51 = l_Lean_mkAppB(x_48, x_49, x_50);
if (lean_is_scalar(x_46)) {
 x_52 = lean_alloc_ctor(0, 1, 0);
} else {
 x_52 = x_46;
 lean_ctor_set_tag(x_52, 0);
}
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_44);
return x_53;
}
}
}
else
{
uint8_t x_54; 
x_54 = !lean_is_exclusive(x_20);
if (x_54 == 0)
{
return x_20;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_20, 0);
x_56 = lean_ctor_get(x_20, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_20);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAllOnes___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAllOnes(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceAllOnes", 13, 13);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(1u);
x_2 = l_BitVec_reduceAllOnes___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceAllOnes___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAllOnes___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6321_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("ofFin", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecOfFin___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; uint8_t x_22; 
x_19 = lean_ctor_get(x_17, 1);
lean_inc(x_19);
x_20 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_21 = l_BitVec_reduceBitVecOfFin___redArg___closed__1;
x_22 = l_Lean_Expr_isConstOf(x_20, x_21);
lean_dec(x_20);
if (x_22 == 0)
{
lean_dec(x_19);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_23; lean_object* x_24; 
lean_dec(x_10);
lean_inc(x_4);
x_23 = l_Lean_Meta_evalNat(x_19, x_2, x_3, x_4, x_5, x_9);
x_24 = lean_ctor_get(x_23, 0);
lean_inc(x_24);
if (lean_obj_tag(x_24) == 0)
{
uint8_t x_25; 
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_25 = !lean_is_exclusive(x_23);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; 
x_26 = lean_ctor_get(x_23, 0);
lean_dec(x_26);
x_27 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_23, 0, x_27);
return x_23;
}
else
{
lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_28 = lean_ctor_get(x_23, 1);
lean_inc(x_28);
lean_dec(x_23);
x_29 = l_BitVec_reduceUnary___redArg___closed__0;
x_30 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_30, 1, x_28);
return x_30;
}
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_23, 1);
lean_inc(x_31);
lean_dec(x_23);
x_32 = lean_ctor_get(x_24, 0);
lean_inc(x_32);
lean_dec(x_24);
x_33 = l_Lean_Meta_getFinValue_x3f(x_16, x_2, x_3, x_4, x_5, x_31);
if (lean_obj_tag(x_33) == 0)
{
lean_object* x_34; 
x_34 = lean_ctor_get(x_33, 0);
lean_inc(x_34);
if (lean_obj_tag(x_34) == 0)
{
uint8_t x_35; 
lean_dec(x_32);
x_35 = !lean_is_exclusive(x_33);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; 
x_36 = lean_ctor_get(x_33, 0);
lean_dec(x_36);
x_37 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_33, 0, x_37);
return x_33;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_38 = lean_ctor_get(x_33, 1);
lean_inc(x_38);
lean_dec(x_33);
x_39 = l_BitVec_reduceUnary___redArg___closed__0;
x_40 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_40, 1, x_38);
return x_40;
}
}
else
{
uint8_t x_41; 
x_41 = !lean_is_exclusive(x_34);
if (x_41 == 0)
{
uint8_t x_42; 
x_42 = !lean_is_exclusive(x_33);
if (x_42 == 0)
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_43 = lean_ctor_get(x_34, 0);
x_44 = lean_ctor_get(x_33, 0);
lean_dec(x_44);
x_45 = lean_ctor_get(x_43, 1);
lean_inc(x_45);
lean_dec(x_43);
x_46 = l_BitVec_ofNat(x_32, x_45);
lean_dec(x_45);
x_47 = l_BitVec_reduceUnary___redArg___closed__4;
x_48 = l_Lean_mkNatLit(x_32);
x_49 = l_Lean_mkNatLit(x_46);
x_50 = l_Lean_mkAppB(x_47, x_48, x_49);
lean_ctor_set_tag(x_34, 0);
lean_ctor_set(x_34, 0, x_50);
return x_33;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_51 = lean_ctor_get(x_34, 0);
x_52 = lean_ctor_get(x_33, 1);
lean_inc(x_52);
lean_dec(x_33);
x_53 = lean_ctor_get(x_51, 1);
lean_inc(x_53);
lean_dec(x_51);
x_54 = l_BitVec_ofNat(x_32, x_53);
lean_dec(x_53);
x_55 = l_BitVec_reduceUnary___redArg___closed__4;
x_56 = l_Lean_mkNatLit(x_32);
x_57 = l_Lean_mkNatLit(x_54);
x_58 = l_Lean_mkAppB(x_55, x_56, x_57);
lean_ctor_set_tag(x_34, 0);
lean_ctor_set(x_34, 0, x_58);
x_59 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_59, 0, x_34);
lean_ctor_set(x_59, 1, x_52);
return x_59;
}
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_60 = lean_ctor_get(x_34, 0);
lean_inc(x_60);
lean_dec(x_34);
x_61 = lean_ctor_get(x_33, 1);
lean_inc(x_61);
if (lean_is_exclusive(x_33)) {
 lean_ctor_release(x_33, 0);
 lean_ctor_release(x_33, 1);
 x_62 = x_33;
} else {
 lean_dec_ref(x_33);
 x_62 = lean_box(0);
}
x_63 = lean_ctor_get(x_60, 1);
lean_inc(x_63);
lean_dec(x_60);
x_64 = l_BitVec_ofNat(x_32, x_63);
lean_dec(x_63);
x_65 = l_BitVec_reduceUnary___redArg___closed__4;
x_66 = l_Lean_mkNatLit(x_32);
x_67 = l_Lean_mkNatLit(x_64);
x_68 = l_Lean_mkAppB(x_65, x_66, x_67);
x_69 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_69, 0, x_68);
if (lean_is_scalar(x_62)) {
 x_70 = lean_alloc_ctor(0, 2, 0);
} else {
 x_70 = x_62;
}
lean_ctor_set(x_70, 0, x_69);
lean_ctor_set(x_70, 1, x_61);
return x_70;
}
}
}
else
{
uint8_t x_71; 
lean_dec(x_32);
x_71 = !lean_is_exclusive(x_33);
if (x_71 == 0)
{
return x_33;
}
else
{
lean_object* x_72; lean_object* x_73; lean_object* x_74; 
x_72 = lean_ctor_get(x_33, 0);
x_73 = lean_ctor_get(x_33, 1);
lean_inc(x_73);
lean_inc(x_72);
lean_dec(x_33);
x_74 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_74, 0, x_72);
lean_ctor_set(x_74, 1, x_73);
return x_74;
}
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBitVecOfFin___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBitVecOfFin(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceBitVecOfFin", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = l_BitVec_reduceBitVecOfFin___redArg___closed__1;
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecOfFin___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecOfFin___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6571_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("toFin", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("OfNat", 5, 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___redArg___closed__2;
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__2;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___redArg___closed__4;
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__3;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__5() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Fin", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBitVecToFin___redArg___closed__5;
x_2 = l_Lean_Name_mkStr1(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__6;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("instOfNat", 9, 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___redArg___closed__8;
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__5;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__9;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__11() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("Nat", 3, 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("instNeZeroSucc", 14, 14);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___redArg___closed__12;
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__11;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___redArg___closed__14() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___redArg___closed__13;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; lean_object* x_9; lean_object* x_10; lean_object* x_14; uint8_t x_15; 
x_7 = l_Lean_Meta_instantiateMVarsIfMVarApp___redArg(x_1, x_3, x_6);
x_8 = lean_ctor_get(x_7, 0);
lean_inc(x_8);
x_9 = lean_ctor_get(x_7, 1);
lean_inc(x_9);
if (lean_is_exclusive(x_7)) {
 lean_ctor_release(x_7, 0);
 lean_ctor_release(x_7, 1);
 x_10 = x_7;
} else {
 lean_dec_ref(x_7);
 x_10 = lean_box(0);
}
x_14 = l_Lean_Expr_cleanupAnnotations(x_8);
x_15 = l_Lean_Expr_isApp(x_14);
if (x_15 == 0)
{
lean_dec(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_16; lean_object* x_17; uint8_t x_18; 
x_16 = lean_ctor_get(x_14, 1);
lean_inc(x_16);
x_17 = l_Lean_Expr_appFnCleanup___redArg(x_14);
x_18 = l_Lean_Expr_isApp(x_17);
if (x_18 == 0)
{
lean_dec(x_17);
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appFnCleanup___redArg(x_17);
x_20 = l_BitVec_reduceBitVecToFin___redArg___closed__1;
x_21 = l_Lean_Expr_isConstOf(x_19, x_20);
lean_dec(x_19);
if (x_21 == 0)
{
lean_dec(x_16);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
goto block_13;
}
else
{
lean_object* x_22; 
lean_dec(x_10);
x_22 = l_Lean_Meta_getBitVecValue_x3f(x_16, x_2, x_3, x_4, x_5, x_9);
if (lean_obj_tag(x_22) == 0)
{
lean_object* x_23; 
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
if (lean_obj_tag(x_23) == 0)
{
uint8_t x_24; 
x_24 = !lean_is_exclusive(x_22);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; 
x_25 = lean_ctor_get(x_22, 0);
lean_dec(x_25);
x_26 = l_BitVec_reduceUnary___redArg___closed__0;
lean_ctor_set(x_22, 0, x_26);
return x_22;
}
else
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_27 = lean_ctor_get(x_22, 1);
lean_inc(x_27);
lean_dec(x_22);
x_28 = l_BitVec_reduceUnary___redArg___closed__0;
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_29, 1, x_27);
return x_29;
}
}
else
{
uint8_t x_30; 
x_30 = !lean_is_exclusive(x_23);
if (x_30 == 0)
{
uint8_t x_31; 
x_31 = !lean_is_exclusive(x_22);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_32 = lean_ctor_get(x_23, 0);
x_33 = lean_ctor_get(x_22, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_32, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_32, 1);
lean_inc(x_35);
lean_dec(x_32);
x_36 = lean_unsigned_to_nat(2u);
x_37 = lean_nat_pow(x_36, x_34);
lean_dec(x_34);
x_38 = l_Lean_mkRawNatLit(x_35);
x_39 = l_BitVec_reduceBitVecToFin___redArg___closed__4;
x_40 = l_BitVec_reduceBitVecToFin___redArg___closed__7;
lean_inc(x_37);
x_41 = l_Lean_mkNatLit(x_37);
lean_inc(x_41);
x_42 = l_Lean_Expr_app___override(x_40, x_41);
x_43 = l_BitVec_reduceBitVecToFin___redArg___closed__10;
x_44 = l_BitVec_reduceBitVecToFin___redArg___closed__14;
x_45 = lean_unsigned_to_nat(1u);
x_46 = lean_nat_sub(x_37, x_45);
lean_dec(x_37);
x_47 = l_Lean_mkNatLit(x_46);
x_48 = l_Lean_Expr_app___override(x_44, x_47);
lean_inc(x_38);
x_49 = l_Lean_mkApp3(x_43, x_41, x_48, x_38);
x_50 = l_Lean_mkApp3(x_39, x_42, x_38, x_49);
lean_ctor_set_tag(x_23, 0);
lean_ctor_set(x_23, 0, x_50);
return x_22;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_51 = lean_ctor_get(x_23, 0);
x_52 = lean_ctor_get(x_22, 1);
lean_inc(x_52);
lean_dec(x_22);
x_53 = lean_ctor_get(x_51, 0);
lean_inc(x_53);
x_54 = lean_ctor_get(x_51, 1);
lean_inc(x_54);
lean_dec(x_51);
x_55 = lean_unsigned_to_nat(2u);
x_56 = lean_nat_pow(x_55, x_53);
lean_dec(x_53);
x_57 = l_Lean_mkRawNatLit(x_54);
x_58 = l_BitVec_reduceBitVecToFin___redArg___closed__4;
x_59 = l_BitVec_reduceBitVecToFin___redArg___closed__7;
lean_inc(x_56);
x_60 = l_Lean_mkNatLit(x_56);
lean_inc(x_60);
x_61 = l_Lean_Expr_app___override(x_59, x_60);
x_62 = l_BitVec_reduceBitVecToFin___redArg___closed__10;
x_63 = l_BitVec_reduceBitVecToFin___redArg___closed__14;
x_64 = lean_unsigned_to_nat(1u);
x_65 = lean_nat_sub(x_56, x_64);
lean_dec(x_56);
x_66 = l_Lean_mkNatLit(x_65);
x_67 = l_Lean_Expr_app___override(x_63, x_66);
lean_inc(x_57);
x_68 = l_Lean_mkApp3(x_62, x_60, x_67, x_57);
x_69 = l_Lean_mkApp3(x_58, x_61, x_57, x_68);
lean_ctor_set_tag(x_23, 0);
lean_ctor_set(x_23, 0, x_69);
x_70 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_70, 0, x_23);
lean_ctor_set(x_70, 1, x_52);
return x_70;
}
}
else
{
lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; lean_object* x_90; lean_object* x_91; lean_object* x_92; 
x_71 = lean_ctor_get(x_23, 0);
lean_inc(x_71);
lean_dec(x_23);
x_72 = lean_ctor_get(x_22, 1);
lean_inc(x_72);
if (lean_is_exclusive(x_22)) {
 lean_ctor_release(x_22, 0);
 lean_ctor_release(x_22, 1);
 x_73 = x_22;
} else {
 lean_dec_ref(x_22);
 x_73 = lean_box(0);
}
x_74 = lean_ctor_get(x_71, 0);
lean_inc(x_74);
x_75 = lean_ctor_get(x_71, 1);
lean_inc(x_75);
lean_dec(x_71);
x_76 = lean_unsigned_to_nat(2u);
x_77 = lean_nat_pow(x_76, x_74);
lean_dec(x_74);
x_78 = l_Lean_mkRawNatLit(x_75);
x_79 = l_BitVec_reduceBitVecToFin___redArg___closed__4;
x_80 = l_BitVec_reduceBitVecToFin___redArg___closed__7;
lean_inc(x_77);
x_81 = l_Lean_mkNatLit(x_77);
lean_inc(x_81);
x_82 = l_Lean_Expr_app___override(x_80, x_81);
x_83 = l_BitVec_reduceBitVecToFin___redArg___closed__10;
x_84 = l_BitVec_reduceBitVecToFin___redArg___closed__14;
x_85 = lean_unsigned_to_nat(1u);
x_86 = lean_nat_sub(x_77, x_85);
lean_dec(x_77);
x_87 = l_Lean_mkNatLit(x_86);
x_88 = l_Lean_Expr_app___override(x_84, x_87);
lean_inc(x_78);
x_89 = l_Lean_mkApp3(x_83, x_81, x_88, x_78);
x_90 = l_Lean_mkApp3(x_79, x_82, x_78, x_89);
x_91 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_91, 0, x_90);
if (lean_is_scalar(x_73)) {
 x_92 = lean_alloc_ctor(0, 2, 0);
} else {
 x_92 = x_73;
}
lean_ctor_set(x_92, 0, x_91);
lean_ctor_set(x_92, 1, x_72);
return x_92;
}
}
}
else
{
uint8_t x_93; 
x_93 = !lean_is_exclusive(x_22);
if (x_93 == 0)
{
return x_22;
}
else
{
lean_object* x_94; lean_object* x_95; lean_object* x_96; 
x_94 = lean_ctor_get(x_22, 0);
x_95 = lean_ctor_get(x_22, 1);
lean_inc(x_95);
lean_inc(x_94);
lean_dec(x_22);
x_96 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_96, 0, x_94);
lean_ctor_set(x_96, 1, x_95);
return x_96;
}
}
}
}
}
block_13:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_BitVec_reduceUnary___redArg___closed__0;
if (lean_is_scalar(x_10)) {
 x_12 = lean_alloc_ctor(0, 2, 0);
} else {
 x_12 = x_10;
}
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_9);
return x_12;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBitVecToFin___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBitVecToFin(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceBitVecToFin", 17, 17);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_3 = lean_alloc_ctor(6, 3, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
lean_ctor_set(x_3, 2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecToFin___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecToFin___boxed), 9, 0);
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6769_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSEvalprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceShiftShift___redArg___closed__0() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; uint8_t x_10; 
x_9 = lean_unsigned_to_nat(6u);
x_10 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_9);
if (x_10 == 0)
{
lean_object* x_11; lean_object* x_12; 
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_11 = l_BitVec_reduceBinPred___redArg___closed__0;
x_12 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_12, 0, x_11);
lean_ctor_set(x_12, 1, x_8);
return x_12;
}
else
{
lean_object* x_13; lean_object* x_14; 
x_13 = l_Lean_Expr_appArg_x21(x_3);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_14 = l_Lean_Meta_getNatValue_x3f(x_13, x_4, x_5, x_6, x_7, x_8);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___redArg___closed__0;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
uint8_t x_22; 
x_22 = !lean_is_exclusive(x_14);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; uint8_t x_25; 
x_23 = lean_ctor_get(x_14, 1);
x_24 = lean_ctor_get(x_14, 0);
lean_dec(x_24);
x_25 = !lean_is_exclusive(x_15);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; uint8_t x_29; 
x_26 = lean_ctor_get(x_15, 0);
x_27 = l_Lean_Expr_appFn_x21(x_3);
x_28 = l_Lean_Expr_appArg_x21(x_27);
lean_dec(x_27);
x_29 = l_Lean_Expr_isAppOfArity(x_28, x_1, x_9);
if (x_29 == 0)
{
lean_object* x_30; 
lean_dec(x_28);
lean_free_object(x_15);
lean_dec(x_26);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_30 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_30);
return x_14;
}
else
{
lean_object* x_31; lean_object* x_32; 
lean_free_object(x_14);
x_31 = l_Lean_Expr_appArg_x21(x_28);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_32 = l_Lean_Meta_getNatValue_x3f(x_31, x_4, x_5, x_6, x_7, x_23);
if (lean_obj_tag(x_32) == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
if (lean_obj_tag(x_33) == 0)
{
uint8_t x_34; 
lean_dec(x_31);
lean_dec(x_28);
lean_free_object(x_15);
lean_dec(x_26);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_34 = !lean_is_exclusive(x_32);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; 
x_35 = lean_ctor_get(x_32, 0);
lean_dec(x_35);
x_36 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_32, 0, x_36);
return x_32;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_37 = lean_ctor_get(x_32, 1);
lean_inc(x_37);
lean_dec(x_32);
x_38 = l_BitVec_reduceBinPred___redArg___closed__0;
x_39 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_39, 0, x_38);
lean_ctor_set(x_39, 1, x_37);
return x_39;
}
}
else
{
lean_object* x_40; uint8_t x_41; 
x_40 = lean_ctor_get(x_32, 1);
lean_inc(x_40);
lean_dec(x_32);
x_41 = !lean_is_exclusive(x_33);
if (x_41 == 0)
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_42 = lean_ctor_get(x_33, 0);
x_43 = l_Lean_Expr_appFn_x21(x_28);
lean_dec(x_28);
x_44 = l_Lean_Expr_appArg_x21(x_43);
lean_dec(x_43);
x_45 = lean_nat_add(x_26, x_42);
lean_dec(x_42);
lean_dec(x_26);
x_46 = l_Lean_mkNatLit(x_45);
x_47 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_44);
x_48 = lean_array_push(x_47, x_44);
x_49 = lean_array_push(x_48, x_46);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_50 = l_Lean_Meta_mkAppM(x_1, x_49, x_4, x_5, x_6, x_7, x_40);
if (lean_obj_tag(x_50) == 0)
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_51 = lean_ctor_get(x_50, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 1);
lean_inc(x_52);
lean_dec(x_50);
x_53 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_54 = lean_array_push(x_53, x_44);
x_55 = lean_array_push(x_54, x_31);
x_56 = lean_array_push(x_55, x_13);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_57 = l_Lean_Meta_mkAppM(x_2, x_56, x_4, x_5, x_6, x_7, x_52);
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_57, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_57, 1);
lean_inc(x_59);
lean_dec(x_57);
x_60 = l_Lean_Meta_mkEqSymm(x_58, x_4, x_5, x_6, x_7, x_59);
if (lean_obj_tag(x_60) == 0)
{
uint8_t x_61; 
x_61 = !lean_is_exclusive(x_60);
if (x_61 == 0)
{
lean_object* x_62; lean_object* x_63; 
x_62 = lean_ctor_get(x_60, 0);
lean_ctor_set(x_33, 0, x_62);
x_63 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_63, 0, x_51);
lean_ctor_set(x_63, 1, x_33);
lean_ctor_set_uint8(x_63, sizeof(void*)*2, x_29);
lean_ctor_set(x_15, 0, x_63);
lean_ctor_set(x_60, 0, x_15);
return x_60;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_64 = lean_ctor_get(x_60, 0);
x_65 = lean_ctor_get(x_60, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_60);
lean_ctor_set(x_33, 0, x_64);
x_66 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_66, 0, x_51);
lean_ctor_set(x_66, 1, x_33);
lean_ctor_set_uint8(x_66, sizeof(void*)*2, x_29);
lean_ctor_set(x_15, 0, x_66);
x_67 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_67, 0, x_15);
lean_ctor_set(x_67, 1, x_65);
return x_67;
}
}
else
{
uint8_t x_68; 
lean_dec(x_51);
lean_free_object(x_33);
lean_free_object(x_15);
x_68 = !lean_is_exclusive(x_60);
if (x_68 == 0)
{
return x_60;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_60, 0);
x_70 = lean_ctor_get(x_60, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_60);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
else
{
uint8_t x_72; 
lean_dec(x_51);
lean_free_object(x_33);
lean_free_object(x_15);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
x_72 = !lean_is_exclusive(x_57);
if (x_72 == 0)
{
return x_57;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_73 = lean_ctor_get(x_57, 0);
x_74 = lean_ctor_get(x_57, 1);
lean_inc(x_74);
lean_inc(x_73);
lean_dec(x_57);
x_75 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_75, 0, x_73);
lean_ctor_set(x_75, 1, x_74);
return x_75;
}
}
}
else
{
uint8_t x_76; 
lean_dec(x_44);
lean_free_object(x_33);
lean_dec(x_31);
lean_free_object(x_15);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_76 = !lean_is_exclusive(x_50);
if (x_76 == 0)
{
return x_50;
}
else
{
lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_77 = lean_ctor_get(x_50, 0);
x_78 = lean_ctor_get(x_50, 1);
lean_inc(x_78);
lean_inc(x_77);
lean_dec(x_50);
x_79 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_79, 0, x_77);
lean_ctor_set(x_79, 1, x_78);
return x_79;
}
}
}
else
{
lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_80 = lean_ctor_get(x_33, 0);
lean_inc(x_80);
lean_dec(x_33);
x_81 = l_Lean_Expr_appFn_x21(x_28);
lean_dec(x_28);
x_82 = l_Lean_Expr_appArg_x21(x_81);
lean_dec(x_81);
x_83 = lean_nat_add(x_26, x_80);
lean_dec(x_80);
lean_dec(x_26);
x_84 = l_Lean_mkNatLit(x_83);
x_85 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_82);
x_86 = lean_array_push(x_85, x_82);
x_87 = lean_array_push(x_86, x_84);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_88 = l_Lean_Meta_mkAppM(x_1, x_87, x_4, x_5, x_6, x_7, x_40);
if (lean_obj_tag(x_88) == 0)
{
lean_object* x_89; lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; lean_object* x_94; lean_object* x_95; 
x_89 = lean_ctor_get(x_88, 0);
lean_inc(x_89);
x_90 = lean_ctor_get(x_88, 1);
lean_inc(x_90);
lean_dec(x_88);
x_91 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_92 = lean_array_push(x_91, x_82);
x_93 = lean_array_push(x_92, x_31);
x_94 = lean_array_push(x_93, x_13);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_95 = l_Lean_Meta_mkAppM(x_2, x_94, x_4, x_5, x_6, x_7, x_90);
if (lean_obj_tag(x_95) == 0)
{
lean_object* x_96; lean_object* x_97; lean_object* x_98; 
x_96 = lean_ctor_get(x_95, 0);
lean_inc(x_96);
x_97 = lean_ctor_get(x_95, 1);
lean_inc(x_97);
lean_dec(x_95);
x_98 = l_Lean_Meta_mkEqSymm(x_96, x_4, x_5, x_6, x_7, x_97);
if (lean_obj_tag(x_98) == 0)
{
lean_object* x_99; lean_object* x_100; lean_object* x_101; lean_object* x_102; lean_object* x_103; lean_object* x_104; 
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_ctor_get(x_98, 1);
lean_inc(x_100);
if (lean_is_exclusive(x_98)) {
 lean_ctor_release(x_98, 0);
 lean_ctor_release(x_98, 1);
 x_101 = x_98;
} else {
 lean_dec_ref(x_98);
 x_101 = lean_box(0);
}
x_102 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_102, 0, x_99);
x_103 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_103, 0, x_89);
lean_ctor_set(x_103, 1, x_102);
lean_ctor_set_uint8(x_103, sizeof(void*)*2, x_29);
lean_ctor_set(x_15, 0, x_103);
if (lean_is_scalar(x_101)) {
 x_104 = lean_alloc_ctor(0, 2, 0);
} else {
 x_104 = x_101;
}
lean_ctor_set(x_104, 0, x_15);
lean_ctor_set(x_104, 1, x_100);
return x_104;
}
else
{
lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; 
lean_dec(x_89);
lean_free_object(x_15);
x_105 = lean_ctor_get(x_98, 0);
lean_inc(x_105);
x_106 = lean_ctor_get(x_98, 1);
lean_inc(x_106);
if (lean_is_exclusive(x_98)) {
 lean_ctor_release(x_98, 0);
 lean_ctor_release(x_98, 1);
 x_107 = x_98;
} else {
 lean_dec_ref(x_98);
 x_107 = lean_box(0);
}
if (lean_is_scalar(x_107)) {
 x_108 = lean_alloc_ctor(1, 2, 0);
} else {
 x_108 = x_107;
}
lean_ctor_set(x_108, 0, x_105);
lean_ctor_set(x_108, 1, x_106);
return x_108;
}
}
else
{
lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; 
lean_dec(x_89);
lean_free_object(x_15);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
x_109 = lean_ctor_get(x_95, 0);
lean_inc(x_109);
x_110 = lean_ctor_get(x_95, 1);
lean_inc(x_110);
if (lean_is_exclusive(x_95)) {
 lean_ctor_release(x_95, 0);
 lean_ctor_release(x_95, 1);
 x_111 = x_95;
} else {
 lean_dec_ref(x_95);
 x_111 = lean_box(0);
}
if (lean_is_scalar(x_111)) {
 x_112 = lean_alloc_ctor(1, 2, 0);
} else {
 x_112 = x_111;
}
lean_ctor_set(x_112, 0, x_109);
lean_ctor_set(x_112, 1, x_110);
return x_112;
}
}
else
{
lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; 
lean_dec(x_82);
lean_dec(x_31);
lean_free_object(x_15);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_113 = lean_ctor_get(x_88, 0);
lean_inc(x_113);
x_114 = lean_ctor_get(x_88, 1);
lean_inc(x_114);
if (lean_is_exclusive(x_88)) {
 lean_ctor_release(x_88, 0);
 lean_ctor_release(x_88, 1);
 x_115 = x_88;
} else {
 lean_dec_ref(x_88);
 x_115 = lean_box(0);
}
if (lean_is_scalar(x_115)) {
 x_116 = lean_alloc_ctor(1, 2, 0);
} else {
 x_116 = x_115;
}
lean_ctor_set(x_116, 0, x_113);
lean_ctor_set(x_116, 1, x_114);
return x_116;
}
}
}
}
else
{
uint8_t x_117; 
lean_dec(x_31);
lean_dec(x_28);
lean_free_object(x_15);
lean_dec(x_26);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_117 = !lean_is_exclusive(x_32);
if (x_117 == 0)
{
return x_32;
}
else
{
lean_object* x_118; lean_object* x_119; lean_object* x_120; 
x_118 = lean_ctor_get(x_32, 0);
x_119 = lean_ctor_get(x_32, 1);
lean_inc(x_119);
lean_inc(x_118);
lean_dec(x_32);
x_120 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_120, 0, x_118);
lean_ctor_set(x_120, 1, x_119);
return x_120;
}
}
}
}
else
{
lean_object* x_121; lean_object* x_122; lean_object* x_123; uint8_t x_124; 
x_121 = lean_ctor_get(x_15, 0);
lean_inc(x_121);
lean_dec(x_15);
x_122 = l_Lean_Expr_appFn_x21(x_3);
x_123 = l_Lean_Expr_appArg_x21(x_122);
lean_dec(x_122);
x_124 = l_Lean_Expr_isAppOfArity(x_123, x_1, x_9);
if (x_124 == 0)
{
lean_object* x_125; 
lean_dec(x_123);
lean_dec(x_121);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_125 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_14, 0, x_125);
return x_14;
}
else
{
lean_object* x_126; lean_object* x_127; 
lean_free_object(x_14);
x_126 = l_Lean_Expr_appArg_x21(x_123);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_127 = l_Lean_Meta_getNatValue_x3f(x_126, x_4, x_5, x_6, x_7, x_23);
if (lean_obj_tag(x_127) == 0)
{
lean_object* x_128; 
x_128 = lean_ctor_get(x_127, 0);
lean_inc(x_128);
if (lean_obj_tag(x_128) == 0)
{
lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; 
lean_dec(x_126);
lean_dec(x_123);
lean_dec(x_121);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_129 = lean_ctor_get(x_127, 1);
lean_inc(x_129);
if (lean_is_exclusive(x_127)) {
 lean_ctor_release(x_127, 0);
 lean_ctor_release(x_127, 1);
 x_130 = x_127;
} else {
 lean_dec_ref(x_127);
 x_130 = lean_box(0);
}
x_131 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_130)) {
 x_132 = lean_alloc_ctor(0, 2, 0);
} else {
 x_132 = x_130;
}
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_129);
return x_132;
}
else
{
lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; 
x_133 = lean_ctor_get(x_127, 1);
lean_inc(x_133);
lean_dec(x_127);
x_134 = lean_ctor_get(x_128, 0);
lean_inc(x_134);
if (lean_is_exclusive(x_128)) {
 lean_ctor_release(x_128, 0);
 x_135 = x_128;
} else {
 lean_dec_ref(x_128);
 x_135 = lean_box(0);
}
x_136 = l_Lean_Expr_appFn_x21(x_123);
lean_dec(x_123);
x_137 = l_Lean_Expr_appArg_x21(x_136);
lean_dec(x_136);
x_138 = lean_nat_add(x_121, x_134);
lean_dec(x_134);
lean_dec(x_121);
x_139 = l_Lean_mkNatLit(x_138);
x_140 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_137);
x_141 = lean_array_push(x_140, x_137);
x_142 = lean_array_push(x_141, x_139);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_143 = l_Lean_Meta_mkAppM(x_1, x_142, x_4, x_5, x_6, x_7, x_133);
if (lean_obj_tag(x_143) == 0)
{
lean_object* x_144; lean_object* x_145; lean_object* x_146; lean_object* x_147; lean_object* x_148; lean_object* x_149; lean_object* x_150; 
x_144 = lean_ctor_get(x_143, 0);
lean_inc(x_144);
x_145 = lean_ctor_get(x_143, 1);
lean_inc(x_145);
lean_dec(x_143);
x_146 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_147 = lean_array_push(x_146, x_137);
x_148 = lean_array_push(x_147, x_126);
x_149 = lean_array_push(x_148, x_13);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_150 = l_Lean_Meta_mkAppM(x_2, x_149, x_4, x_5, x_6, x_7, x_145);
if (lean_obj_tag(x_150) == 0)
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_150, 0);
lean_inc(x_151);
x_152 = lean_ctor_get(x_150, 1);
lean_inc(x_152);
lean_dec(x_150);
x_153 = l_Lean_Meta_mkEqSymm(x_151, x_4, x_5, x_6, x_7, x_152);
if (lean_obj_tag(x_153) == 0)
{
lean_object* x_154; lean_object* x_155; lean_object* x_156; lean_object* x_157; lean_object* x_158; lean_object* x_159; lean_object* x_160; 
x_154 = lean_ctor_get(x_153, 0);
lean_inc(x_154);
x_155 = lean_ctor_get(x_153, 1);
lean_inc(x_155);
if (lean_is_exclusive(x_153)) {
 lean_ctor_release(x_153, 0);
 lean_ctor_release(x_153, 1);
 x_156 = x_153;
} else {
 lean_dec_ref(x_153);
 x_156 = lean_box(0);
}
if (lean_is_scalar(x_135)) {
 x_157 = lean_alloc_ctor(1, 1, 0);
} else {
 x_157 = x_135;
}
lean_ctor_set(x_157, 0, x_154);
x_158 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_158, 0, x_144);
lean_ctor_set(x_158, 1, x_157);
lean_ctor_set_uint8(x_158, sizeof(void*)*2, x_124);
x_159 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_159, 0, x_158);
if (lean_is_scalar(x_156)) {
 x_160 = lean_alloc_ctor(0, 2, 0);
} else {
 x_160 = x_156;
}
lean_ctor_set(x_160, 0, x_159);
lean_ctor_set(x_160, 1, x_155);
return x_160;
}
else
{
lean_object* x_161; lean_object* x_162; lean_object* x_163; lean_object* x_164; 
lean_dec(x_144);
lean_dec(x_135);
x_161 = lean_ctor_get(x_153, 0);
lean_inc(x_161);
x_162 = lean_ctor_get(x_153, 1);
lean_inc(x_162);
if (lean_is_exclusive(x_153)) {
 lean_ctor_release(x_153, 0);
 lean_ctor_release(x_153, 1);
 x_163 = x_153;
} else {
 lean_dec_ref(x_153);
 x_163 = lean_box(0);
}
if (lean_is_scalar(x_163)) {
 x_164 = lean_alloc_ctor(1, 2, 0);
} else {
 x_164 = x_163;
}
lean_ctor_set(x_164, 0, x_161);
lean_ctor_set(x_164, 1, x_162);
return x_164;
}
}
else
{
lean_object* x_165; lean_object* x_166; lean_object* x_167; lean_object* x_168; 
lean_dec(x_144);
lean_dec(x_135);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
x_165 = lean_ctor_get(x_150, 0);
lean_inc(x_165);
x_166 = lean_ctor_get(x_150, 1);
lean_inc(x_166);
if (lean_is_exclusive(x_150)) {
 lean_ctor_release(x_150, 0);
 lean_ctor_release(x_150, 1);
 x_167 = x_150;
} else {
 lean_dec_ref(x_150);
 x_167 = lean_box(0);
}
if (lean_is_scalar(x_167)) {
 x_168 = lean_alloc_ctor(1, 2, 0);
} else {
 x_168 = x_167;
}
lean_ctor_set(x_168, 0, x_165);
lean_ctor_set(x_168, 1, x_166);
return x_168;
}
}
else
{
lean_object* x_169; lean_object* x_170; lean_object* x_171; lean_object* x_172; 
lean_dec(x_137);
lean_dec(x_135);
lean_dec(x_126);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_169 = lean_ctor_get(x_143, 0);
lean_inc(x_169);
x_170 = lean_ctor_get(x_143, 1);
lean_inc(x_170);
if (lean_is_exclusive(x_143)) {
 lean_ctor_release(x_143, 0);
 lean_ctor_release(x_143, 1);
 x_171 = x_143;
} else {
 lean_dec_ref(x_143);
 x_171 = lean_box(0);
}
if (lean_is_scalar(x_171)) {
 x_172 = lean_alloc_ctor(1, 2, 0);
} else {
 x_172 = x_171;
}
lean_ctor_set(x_172, 0, x_169);
lean_ctor_set(x_172, 1, x_170);
return x_172;
}
}
}
else
{
lean_object* x_173; lean_object* x_174; lean_object* x_175; lean_object* x_176; 
lean_dec(x_126);
lean_dec(x_123);
lean_dec(x_121);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_173 = lean_ctor_get(x_127, 0);
lean_inc(x_173);
x_174 = lean_ctor_get(x_127, 1);
lean_inc(x_174);
if (lean_is_exclusive(x_127)) {
 lean_ctor_release(x_127, 0);
 lean_ctor_release(x_127, 1);
 x_175 = x_127;
} else {
 lean_dec_ref(x_127);
 x_175 = lean_box(0);
}
if (lean_is_scalar(x_175)) {
 x_176 = lean_alloc_ctor(1, 2, 0);
} else {
 x_176 = x_175;
}
lean_ctor_set(x_176, 0, x_173);
lean_ctor_set(x_176, 1, x_174);
return x_176;
}
}
}
}
else
{
lean_object* x_177; lean_object* x_178; lean_object* x_179; lean_object* x_180; lean_object* x_181; uint8_t x_182; 
x_177 = lean_ctor_get(x_14, 1);
lean_inc(x_177);
lean_dec(x_14);
x_178 = lean_ctor_get(x_15, 0);
lean_inc(x_178);
if (lean_is_exclusive(x_15)) {
 lean_ctor_release(x_15, 0);
 x_179 = x_15;
} else {
 lean_dec_ref(x_15);
 x_179 = lean_box(0);
}
x_180 = l_Lean_Expr_appFn_x21(x_3);
x_181 = l_Lean_Expr_appArg_x21(x_180);
lean_dec(x_180);
x_182 = l_Lean_Expr_isAppOfArity(x_181, x_1, x_9);
if (x_182 == 0)
{
lean_object* x_183; lean_object* x_184; 
lean_dec(x_181);
lean_dec(x_179);
lean_dec(x_178);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_183 = l_BitVec_reduceBinPred___redArg___closed__0;
x_184 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_184, 0, x_183);
lean_ctor_set(x_184, 1, x_177);
return x_184;
}
else
{
lean_object* x_185; lean_object* x_186; 
x_185 = l_Lean_Expr_appArg_x21(x_181);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_186 = l_Lean_Meta_getNatValue_x3f(x_185, x_4, x_5, x_6, x_7, x_177);
if (lean_obj_tag(x_186) == 0)
{
lean_object* x_187; 
x_187 = lean_ctor_get(x_186, 0);
lean_inc(x_187);
if (lean_obj_tag(x_187) == 0)
{
lean_object* x_188; lean_object* x_189; lean_object* x_190; lean_object* x_191; 
lean_dec(x_185);
lean_dec(x_181);
lean_dec(x_179);
lean_dec(x_178);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_188 = lean_ctor_get(x_186, 1);
lean_inc(x_188);
if (lean_is_exclusive(x_186)) {
 lean_ctor_release(x_186, 0);
 lean_ctor_release(x_186, 1);
 x_189 = x_186;
} else {
 lean_dec_ref(x_186);
 x_189 = lean_box(0);
}
x_190 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_189)) {
 x_191 = lean_alloc_ctor(0, 2, 0);
} else {
 x_191 = x_189;
}
lean_ctor_set(x_191, 0, x_190);
lean_ctor_set(x_191, 1, x_188);
return x_191;
}
else
{
lean_object* x_192; lean_object* x_193; lean_object* x_194; lean_object* x_195; lean_object* x_196; lean_object* x_197; lean_object* x_198; lean_object* x_199; lean_object* x_200; lean_object* x_201; lean_object* x_202; 
x_192 = lean_ctor_get(x_186, 1);
lean_inc(x_192);
lean_dec(x_186);
x_193 = lean_ctor_get(x_187, 0);
lean_inc(x_193);
if (lean_is_exclusive(x_187)) {
 lean_ctor_release(x_187, 0);
 x_194 = x_187;
} else {
 lean_dec_ref(x_187);
 x_194 = lean_box(0);
}
x_195 = l_Lean_Expr_appFn_x21(x_181);
lean_dec(x_181);
x_196 = l_Lean_Expr_appArg_x21(x_195);
lean_dec(x_195);
x_197 = lean_nat_add(x_178, x_193);
lean_dec(x_193);
lean_dec(x_178);
x_198 = l_Lean_mkNatLit(x_197);
x_199 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_196);
x_200 = lean_array_push(x_199, x_196);
x_201 = lean_array_push(x_200, x_198);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_202 = l_Lean_Meta_mkAppM(x_1, x_201, x_4, x_5, x_6, x_7, x_192);
if (lean_obj_tag(x_202) == 0)
{
lean_object* x_203; lean_object* x_204; lean_object* x_205; lean_object* x_206; lean_object* x_207; lean_object* x_208; lean_object* x_209; 
x_203 = lean_ctor_get(x_202, 0);
lean_inc(x_203);
x_204 = lean_ctor_get(x_202, 1);
lean_inc(x_204);
lean_dec(x_202);
x_205 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_206 = lean_array_push(x_205, x_196);
x_207 = lean_array_push(x_206, x_185);
x_208 = lean_array_push(x_207, x_13);
lean_inc(x_7);
lean_inc(x_6);
lean_inc(x_5);
lean_inc(x_4);
x_209 = l_Lean_Meta_mkAppM(x_2, x_208, x_4, x_5, x_6, x_7, x_204);
if (lean_obj_tag(x_209) == 0)
{
lean_object* x_210; lean_object* x_211; lean_object* x_212; 
x_210 = lean_ctor_get(x_209, 0);
lean_inc(x_210);
x_211 = lean_ctor_get(x_209, 1);
lean_inc(x_211);
lean_dec(x_209);
x_212 = l_Lean_Meta_mkEqSymm(x_210, x_4, x_5, x_6, x_7, x_211);
if (lean_obj_tag(x_212) == 0)
{
lean_object* x_213; lean_object* x_214; lean_object* x_215; lean_object* x_216; lean_object* x_217; lean_object* x_218; lean_object* x_219; 
x_213 = lean_ctor_get(x_212, 0);
lean_inc(x_213);
x_214 = lean_ctor_get(x_212, 1);
lean_inc(x_214);
if (lean_is_exclusive(x_212)) {
 lean_ctor_release(x_212, 0);
 lean_ctor_release(x_212, 1);
 x_215 = x_212;
} else {
 lean_dec_ref(x_212);
 x_215 = lean_box(0);
}
if (lean_is_scalar(x_194)) {
 x_216 = lean_alloc_ctor(1, 1, 0);
} else {
 x_216 = x_194;
}
lean_ctor_set(x_216, 0, x_213);
x_217 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_217, 0, x_203);
lean_ctor_set(x_217, 1, x_216);
lean_ctor_set_uint8(x_217, sizeof(void*)*2, x_182);
if (lean_is_scalar(x_179)) {
 x_218 = lean_alloc_ctor(1, 1, 0);
} else {
 x_218 = x_179;
}
lean_ctor_set(x_218, 0, x_217);
if (lean_is_scalar(x_215)) {
 x_219 = lean_alloc_ctor(0, 2, 0);
} else {
 x_219 = x_215;
}
lean_ctor_set(x_219, 0, x_218);
lean_ctor_set(x_219, 1, x_214);
return x_219;
}
else
{
lean_object* x_220; lean_object* x_221; lean_object* x_222; lean_object* x_223; 
lean_dec(x_203);
lean_dec(x_194);
lean_dec(x_179);
x_220 = lean_ctor_get(x_212, 0);
lean_inc(x_220);
x_221 = lean_ctor_get(x_212, 1);
lean_inc(x_221);
if (lean_is_exclusive(x_212)) {
 lean_ctor_release(x_212, 0);
 lean_ctor_release(x_212, 1);
 x_222 = x_212;
} else {
 lean_dec_ref(x_212);
 x_222 = lean_box(0);
}
if (lean_is_scalar(x_222)) {
 x_223 = lean_alloc_ctor(1, 2, 0);
} else {
 x_223 = x_222;
}
lean_ctor_set(x_223, 0, x_220);
lean_ctor_set(x_223, 1, x_221);
return x_223;
}
}
else
{
lean_object* x_224; lean_object* x_225; lean_object* x_226; lean_object* x_227; 
lean_dec(x_203);
lean_dec(x_194);
lean_dec(x_179);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
x_224 = lean_ctor_get(x_209, 0);
lean_inc(x_224);
x_225 = lean_ctor_get(x_209, 1);
lean_inc(x_225);
if (lean_is_exclusive(x_209)) {
 lean_ctor_release(x_209, 0);
 lean_ctor_release(x_209, 1);
 x_226 = x_209;
} else {
 lean_dec_ref(x_209);
 x_226 = lean_box(0);
}
if (lean_is_scalar(x_226)) {
 x_227 = lean_alloc_ctor(1, 2, 0);
} else {
 x_227 = x_226;
}
lean_ctor_set(x_227, 0, x_224);
lean_ctor_set(x_227, 1, x_225);
return x_227;
}
}
else
{
lean_object* x_228; lean_object* x_229; lean_object* x_230; lean_object* x_231; 
lean_dec(x_196);
lean_dec(x_194);
lean_dec(x_185);
lean_dec(x_179);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_228 = lean_ctor_get(x_202, 0);
lean_inc(x_228);
x_229 = lean_ctor_get(x_202, 1);
lean_inc(x_229);
if (lean_is_exclusive(x_202)) {
 lean_ctor_release(x_202, 0);
 lean_ctor_release(x_202, 1);
 x_230 = x_202;
} else {
 lean_dec_ref(x_202);
 x_230 = lean_box(0);
}
if (lean_is_scalar(x_230)) {
 x_231 = lean_alloc_ctor(1, 2, 0);
} else {
 x_231 = x_230;
}
lean_ctor_set(x_231, 0, x_228);
lean_ctor_set(x_231, 1, x_229);
return x_231;
}
}
}
else
{
lean_object* x_232; lean_object* x_233; lean_object* x_234; lean_object* x_235; 
lean_dec(x_185);
lean_dec(x_181);
lean_dec(x_179);
lean_dec(x_178);
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_232 = lean_ctor_get(x_186, 0);
lean_inc(x_232);
x_233 = lean_ctor_get(x_186, 1);
lean_inc(x_233);
if (lean_is_exclusive(x_186)) {
 lean_ctor_release(x_186, 0);
 lean_ctor_release(x_186, 1);
 x_234 = x_186;
} else {
 lean_dec_ref(x_186);
 x_234 = lean_box(0);
}
if (lean_is_scalar(x_234)) {
 x_235 = lean_alloc_ctor(1, 2, 0);
} else {
 x_235 = x_234;
}
lean_ctor_set(x_235, 0, x_232);
lean_ctor_set(x_235, 1, x_233);
return x_235;
}
}
}
}
}
else
{
uint8_t x_236; 
lean_dec(x_13);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_236 = !lean_is_exclusive(x_14);
if (x_236 == 0)
{
return x_14;
}
else
{
lean_object* x_237; lean_object* x_238; lean_object* x_239; 
x_237 = lean_ctor_get(x_14, 0);
x_238 = lean_ctor_get(x_14, 1);
lean_inc(x_238);
lean_inc(x_237);
lean_dec(x_14);
x_239 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_239, 0, x_237);
lean_ctor_set(x_239, 1, x_238);
return x_239;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(6u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_14 = l_BitVec_reduceBinPred___redArg___closed__0;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = l_Lean_Expr_appArg_x21(x_3);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_17 = l_Lean_Meta_getNatValue_x3f(x_16, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_17) == 0)
{
lean_object* x_18; 
x_18 = lean_ctor_get(x_17, 0);
lean_inc(x_18);
if (lean_obj_tag(x_18) == 0)
{
uint8_t x_19; 
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_19 = !lean_is_exclusive(x_17);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; 
x_20 = lean_ctor_get(x_17, 0);
lean_dec(x_20);
x_21 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_17, 0, x_21);
return x_17;
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_22 = lean_ctor_get(x_17, 1);
lean_inc(x_22);
lean_dec(x_17);
x_23 = l_BitVec_reduceBinPred___redArg___closed__0;
x_24 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_24, 0, x_23);
lean_ctor_set(x_24, 1, x_22);
return x_24;
}
}
else
{
uint8_t x_25; 
x_25 = !lean_is_exclusive(x_17);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; uint8_t x_28; 
x_26 = lean_ctor_get(x_17, 1);
x_27 = lean_ctor_get(x_17, 0);
lean_dec(x_27);
x_28 = !lean_is_exclusive(x_18);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; uint8_t x_32; 
x_29 = lean_ctor_get(x_18, 0);
x_30 = l_Lean_Expr_appFn_x21(x_3);
x_31 = l_Lean_Expr_appArg_x21(x_30);
lean_dec(x_30);
x_32 = l_Lean_Expr_isAppOfArity(x_31, x_1, x_12);
if (x_32 == 0)
{
lean_object* x_33; 
lean_dec(x_31);
lean_free_object(x_18);
lean_dec(x_29);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_33 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_17, 0, x_33);
return x_17;
}
else
{
lean_object* x_34; lean_object* x_35; 
lean_free_object(x_17);
x_34 = l_Lean_Expr_appArg_x21(x_31);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_35 = l_Lean_Meta_getNatValue_x3f(x_34, x_7, x_8, x_9, x_10, x_26);
if (lean_obj_tag(x_35) == 0)
{
lean_object* x_36; 
x_36 = lean_ctor_get(x_35, 0);
lean_inc(x_36);
if (lean_obj_tag(x_36) == 0)
{
uint8_t x_37; 
lean_dec(x_34);
lean_dec(x_31);
lean_free_object(x_18);
lean_dec(x_29);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_37 = !lean_is_exclusive(x_35);
if (x_37 == 0)
{
lean_object* x_38; lean_object* x_39; 
x_38 = lean_ctor_get(x_35, 0);
lean_dec(x_38);
x_39 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_35, 0, x_39);
return x_35;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_35, 1);
lean_inc(x_40);
lean_dec(x_35);
x_41 = l_BitVec_reduceBinPred___redArg___closed__0;
x_42 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_42, 1, x_40);
return x_42;
}
}
else
{
lean_object* x_43; uint8_t x_44; 
x_43 = lean_ctor_get(x_35, 1);
lean_inc(x_43);
lean_dec(x_35);
x_44 = !lean_is_exclusive(x_36);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_45 = lean_ctor_get(x_36, 0);
x_46 = l_Lean_Expr_appFn_x21(x_31);
lean_dec(x_31);
x_47 = l_Lean_Expr_appArg_x21(x_46);
lean_dec(x_46);
x_48 = lean_nat_add(x_29, x_45);
lean_dec(x_45);
lean_dec(x_29);
x_49 = l_Lean_mkNatLit(x_48);
x_50 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_47);
x_51 = lean_array_push(x_50, x_47);
x_52 = lean_array_push(x_51, x_49);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_53 = l_Lean_Meta_mkAppM(x_1, x_52, x_7, x_8, x_9, x_10, x_43);
if (lean_obj_tag(x_53) == 0)
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_54 = lean_ctor_get(x_53, 0);
lean_inc(x_54);
x_55 = lean_ctor_get(x_53, 1);
lean_inc(x_55);
lean_dec(x_53);
x_56 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_57 = lean_array_push(x_56, x_47);
x_58 = lean_array_push(x_57, x_34);
x_59 = lean_array_push(x_58, x_16);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_60 = l_Lean_Meta_mkAppM(x_2, x_59, x_7, x_8, x_9, x_10, x_55);
if (lean_obj_tag(x_60) == 0)
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_60, 0);
lean_inc(x_61);
x_62 = lean_ctor_get(x_60, 1);
lean_inc(x_62);
lean_dec(x_60);
x_63 = l_Lean_Meta_mkEqSymm(x_61, x_7, x_8, x_9, x_10, x_62);
if (lean_obj_tag(x_63) == 0)
{
uint8_t x_64; 
x_64 = !lean_is_exclusive(x_63);
if (x_64 == 0)
{
lean_object* x_65; lean_object* x_66; 
x_65 = lean_ctor_get(x_63, 0);
lean_ctor_set(x_36, 0, x_65);
x_66 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_66, 0, x_54);
lean_ctor_set(x_66, 1, x_36);
lean_ctor_set_uint8(x_66, sizeof(void*)*2, x_32);
lean_ctor_set(x_18, 0, x_66);
lean_ctor_set(x_63, 0, x_18);
return x_63;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_67 = lean_ctor_get(x_63, 0);
x_68 = lean_ctor_get(x_63, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_63);
lean_ctor_set(x_36, 0, x_67);
x_69 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_69, 0, x_54);
lean_ctor_set(x_69, 1, x_36);
lean_ctor_set_uint8(x_69, sizeof(void*)*2, x_32);
lean_ctor_set(x_18, 0, x_69);
x_70 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_70, 0, x_18);
lean_ctor_set(x_70, 1, x_68);
return x_70;
}
}
else
{
uint8_t x_71; 
lean_dec(x_54);
lean_free_object(x_36);
lean_free_object(x_18);
x_71 = !lean_is_exclusive(x_63);
if (x_71 == 0)
{
return x_63;
}
else
{
lean_object* x_72; lean_object* x_73; lean_object* x_74; 
x_72 = lean_ctor_get(x_63, 0);
x_73 = lean_ctor_get(x_63, 1);
lean_inc(x_73);
lean_inc(x_72);
lean_dec(x_63);
x_74 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_74, 0, x_72);
lean_ctor_set(x_74, 1, x_73);
return x_74;
}
}
}
else
{
uint8_t x_75; 
lean_dec(x_54);
lean_free_object(x_36);
lean_free_object(x_18);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
x_75 = !lean_is_exclusive(x_60);
if (x_75 == 0)
{
return x_60;
}
else
{
lean_object* x_76; lean_object* x_77; lean_object* x_78; 
x_76 = lean_ctor_get(x_60, 0);
x_77 = lean_ctor_get(x_60, 1);
lean_inc(x_77);
lean_inc(x_76);
lean_dec(x_60);
x_78 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_78, 0, x_76);
lean_ctor_set(x_78, 1, x_77);
return x_78;
}
}
}
else
{
uint8_t x_79; 
lean_dec(x_47);
lean_free_object(x_36);
lean_dec(x_34);
lean_free_object(x_18);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_79 = !lean_is_exclusive(x_53);
if (x_79 == 0)
{
return x_53;
}
else
{
lean_object* x_80; lean_object* x_81; lean_object* x_82; 
x_80 = lean_ctor_get(x_53, 0);
x_81 = lean_ctor_get(x_53, 1);
lean_inc(x_81);
lean_inc(x_80);
lean_dec(x_53);
x_82 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_82, 0, x_80);
lean_ctor_set(x_82, 1, x_81);
return x_82;
}
}
}
else
{
lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; lean_object* x_90; lean_object* x_91; 
x_83 = lean_ctor_get(x_36, 0);
lean_inc(x_83);
lean_dec(x_36);
x_84 = l_Lean_Expr_appFn_x21(x_31);
lean_dec(x_31);
x_85 = l_Lean_Expr_appArg_x21(x_84);
lean_dec(x_84);
x_86 = lean_nat_add(x_29, x_83);
lean_dec(x_83);
lean_dec(x_29);
x_87 = l_Lean_mkNatLit(x_86);
x_88 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_85);
x_89 = lean_array_push(x_88, x_85);
x_90 = lean_array_push(x_89, x_87);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_91 = l_Lean_Meta_mkAppM(x_1, x_90, x_7, x_8, x_9, x_10, x_43);
if (lean_obj_tag(x_91) == 0)
{
lean_object* x_92; lean_object* x_93; lean_object* x_94; lean_object* x_95; lean_object* x_96; lean_object* x_97; lean_object* x_98; 
x_92 = lean_ctor_get(x_91, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 1);
lean_inc(x_93);
lean_dec(x_91);
x_94 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_95 = lean_array_push(x_94, x_85);
x_96 = lean_array_push(x_95, x_34);
x_97 = lean_array_push(x_96, x_16);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_98 = l_Lean_Meta_mkAppM(x_2, x_97, x_7, x_8, x_9, x_10, x_93);
if (lean_obj_tag(x_98) == 0)
{
lean_object* x_99; lean_object* x_100; lean_object* x_101; 
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_ctor_get(x_98, 1);
lean_inc(x_100);
lean_dec(x_98);
x_101 = l_Lean_Meta_mkEqSymm(x_99, x_7, x_8, x_9, x_10, x_100);
if (lean_obj_tag(x_101) == 0)
{
lean_object* x_102; lean_object* x_103; lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; 
x_102 = lean_ctor_get(x_101, 0);
lean_inc(x_102);
x_103 = lean_ctor_get(x_101, 1);
lean_inc(x_103);
if (lean_is_exclusive(x_101)) {
 lean_ctor_release(x_101, 0);
 lean_ctor_release(x_101, 1);
 x_104 = x_101;
} else {
 lean_dec_ref(x_101);
 x_104 = lean_box(0);
}
x_105 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_105, 0, x_102);
x_106 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_106, 0, x_92);
lean_ctor_set(x_106, 1, x_105);
lean_ctor_set_uint8(x_106, sizeof(void*)*2, x_32);
lean_ctor_set(x_18, 0, x_106);
if (lean_is_scalar(x_104)) {
 x_107 = lean_alloc_ctor(0, 2, 0);
} else {
 x_107 = x_104;
}
lean_ctor_set(x_107, 0, x_18);
lean_ctor_set(x_107, 1, x_103);
return x_107;
}
else
{
lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; 
lean_dec(x_92);
lean_free_object(x_18);
x_108 = lean_ctor_get(x_101, 0);
lean_inc(x_108);
x_109 = lean_ctor_get(x_101, 1);
lean_inc(x_109);
if (lean_is_exclusive(x_101)) {
 lean_ctor_release(x_101, 0);
 lean_ctor_release(x_101, 1);
 x_110 = x_101;
} else {
 lean_dec_ref(x_101);
 x_110 = lean_box(0);
}
if (lean_is_scalar(x_110)) {
 x_111 = lean_alloc_ctor(1, 2, 0);
} else {
 x_111 = x_110;
}
lean_ctor_set(x_111, 0, x_108);
lean_ctor_set(x_111, 1, x_109);
return x_111;
}
}
else
{
lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; 
lean_dec(x_92);
lean_free_object(x_18);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
x_112 = lean_ctor_get(x_98, 0);
lean_inc(x_112);
x_113 = lean_ctor_get(x_98, 1);
lean_inc(x_113);
if (lean_is_exclusive(x_98)) {
 lean_ctor_release(x_98, 0);
 lean_ctor_release(x_98, 1);
 x_114 = x_98;
} else {
 lean_dec_ref(x_98);
 x_114 = lean_box(0);
}
if (lean_is_scalar(x_114)) {
 x_115 = lean_alloc_ctor(1, 2, 0);
} else {
 x_115 = x_114;
}
lean_ctor_set(x_115, 0, x_112);
lean_ctor_set(x_115, 1, x_113);
return x_115;
}
}
else
{
lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; 
lean_dec(x_85);
lean_dec(x_34);
lean_free_object(x_18);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_116 = lean_ctor_get(x_91, 0);
lean_inc(x_116);
x_117 = lean_ctor_get(x_91, 1);
lean_inc(x_117);
if (lean_is_exclusive(x_91)) {
 lean_ctor_release(x_91, 0);
 lean_ctor_release(x_91, 1);
 x_118 = x_91;
} else {
 lean_dec_ref(x_91);
 x_118 = lean_box(0);
}
if (lean_is_scalar(x_118)) {
 x_119 = lean_alloc_ctor(1, 2, 0);
} else {
 x_119 = x_118;
}
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_117);
return x_119;
}
}
}
}
else
{
uint8_t x_120; 
lean_dec(x_34);
lean_dec(x_31);
lean_free_object(x_18);
lean_dec(x_29);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_120 = !lean_is_exclusive(x_35);
if (x_120 == 0)
{
return x_35;
}
else
{
lean_object* x_121; lean_object* x_122; lean_object* x_123; 
x_121 = lean_ctor_get(x_35, 0);
x_122 = lean_ctor_get(x_35, 1);
lean_inc(x_122);
lean_inc(x_121);
lean_dec(x_35);
x_123 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_123, 0, x_121);
lean_ctor_set(x_123, 1, x_122);
return x_123;
}
}
}
}
else
{
lean_object* x_124; lean_object* x_125; lean_object* x_126; uint8_t x_127; 
x_124 = lean_ctor_get(x_18, 0);
lean_inc(x_124);
lean_dec(x_18);
x_125 = l_Lean_Expr_appFn_x21(x_3);
x_126 = l_Lean_Expr_appArg_x21(x_125);
lean_dec(x_125);
x_127 = l_Lean_Expr_isAppOfArity(x_126, x_1, x_12);
if (x_127 == 0)
{
lean_object* x_128; 
lean_dec(x_126);
lean_dec(x_124);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_128 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_17, 0, x_128);
return x_17;
}
else
{
lean_object* x_129; lean_object* x_130; 
lean_free_object(x_17);
x_129 = l_Lean_Expr_appArg_x21(x_126);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_130 = l_Lean_Meta_getNatValue_x3f(x_129, x_7, x_8, x_9, x_10, x_26);
if (lean_obj_tag(x_130) == 0)
{
lean_object* x_131; 
x_131 = lean_ctor_get(x_130, 0);
lean_inc(x_131);
if (lean_obj_tag(x_131) == 0)
{
lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; 
lean_dec(x_129);
lean_dec(x_126);
lean_dec(x_124);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_132 = lean_ctor_get(x_130, 1);
lean_inc(x_132);
if (lean_is_exclusive(x_130)) {
 lean_ctor_release(x_130, 0);
 lean_ctor_release(x_130, 1);
 x_133 = x_130;
} else {
 lean_dec_ref(x_130);
 x_133 = lean_box(0);
}
x_134 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_133)) {
 x_135 = lean_alloc_ctor(0, 2, 0);
} else {
 x_135 = x_133;
}
lean_ctor_set(x_135, 0, x_134);
lean_ctor_set(x_135, 1, x_132);
return x_135;
}
else
{
lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; lean_object* x_146; 
x_136 = lean_ctor_get(x_130, 1);
lean_inc(x_136);
lean_dec(x_130);
x_137 = lean_ctor_get(x_131, 0);
lean_inc(x_137);
if (lean_is_exclusive(x_131)) {
 lean_ctor_release(x_131, 0);
 x_138 = x_131;
} else {
 lean_dec_ref(x_131);
 x_138 = lean_box(0);
}
x_139 = l_Lean_Expr_appFn_x21(x_126);
lean_dec(x_126);
x_140 = l_Lean_Expr_appArg_x21(x_139);
lean_dec(x_139);
x_141 = lean_nat_add(x_124, x_137);
lean_dec(x_137);
lean_dec(x_124);
x_142 = l_Lean_mkNatLit(x_141);
x_143 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_140);
x_144 = lean_array_push(x_143, x_140);
x_145 = lean_array_push(x_144, x_142);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_146 = l_Lean_Meta_mkAppM(x_1, x_145, x_7, x_8, x_9, x_10, x_136);
if (lean_obj_tag(x_146) == 0)
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; lean_object* x_150; lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_147 = lean_ctor_get(x_146, 0);
lean_inc(x_147);
x_148 = lean_ctor_get(x_146, 1);
lean_inc(x_148);
lean_dec(x_146);
x_149 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_150 = lean_array_push(x_149, x_140);
x_151 = lean_array_push(x_150, x_129);
x_152 = lean_array_push(x_151, x_16);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_153 = l_Lean_Meta_mkAppM(x_2, x_152, x_7, x_8, x_9, x_10, x_148);
if (lean_obj_tag(x_153) == 0)
{
lean_object* x_154; lean_object* x_155; lean_object* x_156; 
x_154 = lean_ctor_get(x_153, 0);
lean_inc(x_154);
x_155 = lean_ctor_get(x_153, 1);
lean_inc(x_155);
lean_dec(x_153);
x_156 = l_Lean_Meta_mkEqSymm(x_154, x_7, x_8, x_9, x_10, x_155);
if (lean_obj_tag(x_156) == 0)
{
lean_object* x_157; lean_object* x_158; lean_object* x_159; lean_object* x_160; lean_object* x_161; lean_object* x_162; lean_object* x_163; 
x_157 = lean_ctor_get(x_156, 0);
lean_inc(x_157);
x_158 = lean_ctor_get(x_156, 1);
lean_inc(x_158);
if (lean_is_exclusive(x_156)) {
 lean_ctor_release(x_156, 0);
 lean_ctor_release(x_156, 1);
 x_159 = x_156;
} else {
 lean_dec_ref(x_156);
 x_159 = lean_box(0);
}
if (lean_is_scalar(x_138)) {
 x_160 = lean_alloc_ctor(1, 1, 0);
} else {
 x_160 = x_138;
}
lean_ctor_set(x_160, 0, x_157);
x_161 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_161, 0, x_147);
lean_ctor_set(x_161, 1, x_160);
lean_ctor_set_uint8(x_161, sizeof(void*)*2, x_127);
x_162 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_162, 0, x_161);
if (lean_is_scalar(x_159)) {
 x_163 = lean_alloc_ctor(0, 2, 0);
} else {
 x_163 = x_159;
}
lean_ctor_set(x_163, 0, x_162);
lean_ctor_set(x_163, 1, x_158);
return x_163;
}
else
{
lean_object* x_164; lean_object* x_165; lean_object* x_166; lean_object* x_167; 
lean_dec(x_147);
lean_dec(x_138);
x_164 = lean_ctor_get(x_156, 0);
lean_inc(x_164);
x_165 = lean_ctor_get(x_156, 1);
lean_inc(x_165);
if (lean_is_exclusive(x_156)) {
 lean_ctor_release(x_156, 0);
 lean_ctor_release(x_156, 1);
 x_166 = x_156;
} else {
 lean_dec_ref(x_156);
 x_166 = lean_box(0);
}
if (lean_is_scalar(x_166)) {
 x_167 = lean_alloc_ctor(1, 2, 0);
} else {
 x_167 = x_166;
}
lean_ctor_set(x_167, 0, x_164);
lean_ctor_set(x_167, 1, x_165);
return x_167;
}
}
else
{
lean_object* x_168; lean_object* x_169; lean_object* x_170; lean_object* x_171; 
lean_dec(x_147);
lean_dec(x_138);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
x_168 = lean_ctor_get(x_153, 0);
lean_inc(x_168);
x_169 = lean_ctor_get(x_153, 1);
lean_inc(x_169);
if (lean_is_exclusive(x_153)) {
 lean_ctor_release(x_153, 0);
 lean_ctor_release(x_153, 1);
 x_170 = x_153;
} else {
 lean_dec_ref(x_153);
 x_170 = lean_box(0);
}
if (lean_is_scalar(x_170)) {
 x_171 = lean_alloc_ctor(1, 2, 0);
} else {
 x_171 = x_170;
}
lean_ctor_set(x_171, 0, x_168);
lean_ctor_set(x_171, 1, x_169);
return x_171;
}
}
else
{
lean_object* x_172; lean_object* x_173; lean_object* x_174; lean_object* x_175; 
lean_dec(x_140);
lean_dec(x_138);
lean_dec(x_129);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_172 = lean_ctor_get(x_146, 0);
lean_inc(x_172);
x_173 = lean_ctor_get(x_146, 1);
lean_inc(x_173);
if (lean_is_exclusive(x_146)) {
 lean_ctor_release(x_146, 0);
 lean_ctor_release(x_146, 1);
 x_174 = x_146;
} else {
 lean_dec_ref(x_146);
 x_174 = lean_box(0);
}
if (lean_is_scalar(x_174)) {
 x_175 = lean_alloc_ctor(1, 2, 0);
} else {
 x_175 = x_174;
}
lean_ctor_set(x_175, 0, x_172);
lean_ctor_set(x_175, 1, x_173);
return x_175;
}
}
}
else
{
lean_object* x_176; lean_object* x_177; lean_object* x_178; lean_object* x_179; 
lean_dec(x_129);
lean_dec(x_126);
lean_dec(x_124);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_176 = lean_ctor_get(x_130, 0);
lean_inc(x_176);
x_177 = lean_ctor_get(x_130, 1);
lean_inc(x_177);
if (lean_is_exclusive(x_130)) {
 lean_ctor_release(x_130, 0);
 lean_ctor_release(x_130, 1);
 x_178 = x_130;
} else {
 lean_dec_ref(x_130);
 x_178 = lean_box(0);
}
if (lean_is_scalar(x_178)) {
 x_179 = lean_alloc_ctor(1, 2, 0);
} else {
 x_179 = x_178;
}
lean_ctor_set(x_179, 0, x_176);
lean_ctor_set(x_179, 1, x_177);
return x_179;
}
}
}
}
else
{
lean_object* x_180; lean_object* x_181; lean_object* x_182; lean_object* x_183; lean_object* x_184; uint8_t x_185; 
x_180 = lean_ctor_get(x_17, 1);
lean_inc(x_180);
lean_dec(x_17);
x_181 = lean_ctor_get(x_18, 0);
lean_inc(x_181);
if (lean_is_exclusive(x_18)) {
 lean_ctor_release(x_18, 0);
 x_182 = x_18;
} else {
 lean_dec_ref(x_18);
 x_182 = lean_box(0);
}
x_183 = l_Lean_Expr_appFn_x21(x_3);
x_184 = l_Lean_Expr_appArg_x21(x_183);
lean_dec(x_183);
x_185 = l_Lean_Expr_isAppOfArity(x_184, x_1, x_12);
if (x_185 == 0)
{
lean_object* x_186; lean_object* x_187; 
lean_dec(x_184);
lean_dec(x_182);
lean_dec(x_181);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_186 = l_BitVec_reduceBinPred___redArg___closed__0;
x_187 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_187, 0, x_186);
lean_ctor_set(x_187, 1, x_180);
return x_187;
}
else
{
lean_object* x_188; lean_object* x_189; 
x_188 = l_Lean_Expr_appArg_x21(x_184);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_189 = l_Lean_Meta_getNatValue_x3f(x_188, x_7, x_8, x_9, x_10, x_180);
if (lean_obj_tag(x_189) == 0)
{
lean_object* x_190; 
x_190 = lean_ctor_get(x_189, 0);
lean_inc(x_190);
if (lean_obj_tag(x_190) == 0)
{
lean_object* x_191; lean_object* x_192; lean_object* x_193; lean_object* x_194; 
lean_dec(x_188);
lean_dec(x_184);
lean_dec(x_182);
lean_dec(x_181);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_191 = lean_ctor_get(x_189, 1);
lean_inc(x_191);
if (lean_is_exclusive(x_189)) {
 lean_ctor_release(x_189, 0);
 lean_ctor_release(x_189, 1);
 x_192 = x_189;
} else {
 lean_dec_ref(x_189);
 x_192 = lean_box(0);
}
x_193 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_192)) {
 x_194 = lean_alloc_ctor(0, 2, 0);
} else {
 x_194 = x_192;
}
lean_ctor_set(x_194, 0, x_193);
lean_ctor_set(x_194, 1, x_191);
return x_194;
}
else
{
lean_object* x_195; lean_object* x_196; lean_object* x_197; lean_object* x_198; lean_object* x_199; lean_object* x_200; lean_object* x_201; lean_object* x_202; lean_object* x_203; lean_object* x_204; lean_object* x_205; 
x_195 = lean_ctor_get(x_189, 1);
lean_inc(x_195);
lean_dec(x_189);
x_196 = lean_ctor_get(x_190, 0);
lean_inc(x_196);
if (lean_is_exclusive(x_190)) {
 lean_ctor_release(x_190, 0);
 x_197 = x_190;
} else {
 lean_dec_ref(x_190);
 x_197 = lean_box(0);
}
x_198 = l_Lean_Expr_appFn_x21(x_184);
lean_dec(x_184);
x_199 = l_Lean_Expr_appArg_x21(x_198);
lean_dec(x_198);
x_200 = lean_nat_add(x_181, x_196);
lean_dec(x_196);
lean_dec(x_181);
x_201 = l_Lean_mkNatLit(x_200);
x_202 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_199);
x_203 = lean_array_push(x_202, x_199);
x_204 = lean_array_push(x_203, x_201);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_205 = l_Lean_Meta_mkAppM(x_1, x_204, x_7, x_8, x_9, x_10, x_195);
if (lean_obj_tag(x_205) == 0)
{
lean_object* x_206; lean_object* x_207; lean_object* x_208; lean_object* x_209; lean_object* x_210; lean_object* x_211; lean_object* x_212; 
x_206 = lean_ctor_get(x_205, 0);
lean_inc(x_206);
x_207 = lean_ctor_get(x_205, 1);
lean_inc(x_207);
lean_dec(x_205);
x_208 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_209 = lean_array_push(x_208, x_199);
x_210 = lean_array_push(x_209, x_188);
x_211 = lean_array_push(x_210, x_16);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_212 = l_Lean_Meta_mkAppM(x_2, x_211, x_7, x_8, x_9, x_10, x_207);
if (lean_obj_tag(x_212) == 0)
{
lean_object* x_213; lean_object* x_214; lean_object* x_215; 
x_213 = lean_ctor_get(x_212, 0);
lean_inc(x_213);
x_214 = lean_ctor_get(x_212, 1);
lean_inc(x_214);
lean_dec(x_212);
x_215 = l_Lean_Meta_mkEqSymm(x_213, x_7, x_8, x_9, x_10, x_214);
if (lean_obj_tag(x_215) == 0)
{
lean_object* x_216; lean_object* x_217; lean_object* x_218; lean_object* x_219; lean_object* x_220; lean_object* x_221; lean_object* x_222; 
x_216 = lean_ctor_get(x_215, 0);
lean_inc(x_216);
x_217 = lean_ctor_get(x_215, 1);
lean_inc(x_217);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_218 = x_215;
} else {
 lean_dec_ref(x_215);
 x_218 = lean_box(0);
}
if (lean_is_scalar(x_197)) {
 x_219 = lean_alloc_ctor(1, 1, 0);
} else {
 x_219 = x_197;
}
lean_ctor_set(x_219, 0, x_216);
x_220 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_220, 0, x_206);
lean_ctor_set(x_220, 1, x_219);
lean_ctor_set_uint8(x_220, sizeof(void*)*2, x_185);
if (lean_is_scalar(x_182)) {
 x_221 = lean_alloc_ctor(1, 1, 0);
} else {
 x_221 = x_182;
}
lean_ctor_set(x_221, 0, x_220);
if (lean_is_scalar(x_218)) {
 x_222 = lean_alloc_ctor(0, 2, 0);
} else {
 x_222 = x_218;
}
lean_ctor_set(x_222, 0, x_221);
lean_ctor_set(x_222, 1, x_217);
return x_222;
}
else
{
lean_object* x_223; lean_object* x_224; lean_object* x_225; lean_object* x_226; 
lean_dec(x_206);
lean_dec(x_197);
lean_dec(x_182);
x_223 = lean_ctor_get(x_215, 0);
lean_inc(x_223);
x_224 = lean_ctor_get(x_215, 1);
lean_inc(x_224);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_225 = x_215;
} else {
 lean_dec_ref(x_215);
 x_225 = lean_box(0);
}
if (lean_is_scalar(x_225)) {
 x_226 = lean_alloc_ctor(1, 2, 0);
} else {
 x_226 = x_225;
}
lean_ctor_set(x_226, 0, x_223);
lean_ctor_set(x_226, 1, x_224);
return x_226;
}
}
else
{
lean_object* x_227; lean_object* x_228; lean_object* x_229; lean_object* x_230; 
lean_dec(x_206);
lean_dec(x_197);
lean_dec(x_182);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
x_227 = lean_ctor_get(x_212, 0);
lean_inc(x_227);
x_228 = lean_ctor_get(x_212, 1);
lean_inc(x_228);
if (lean_is_exclusive(x_212)) {
 lean_ctor_release(x_212, 0);
 lean_ctor_release(x_212, 1);
 x_229 = x_212;
} else {
 lean_dec_ref(x_212);
 x_229 = lean_box(0);
}
if (lean_is_scalar(x_229)) {
 x_230 = lean_alloc_ctor(1, 2, 0);
} else {
 x_230 = x_229;
}
lean_ctor_set(x_230, 0, x_227);
lean_ctor_set(x_230, 1, x_228);
return x_230;
}
}
else
{
lean_object* x_231; lean_object* x_232; lean_object* x_233; lean_object* x_234; 
lean_dec(x_199);
lean_dec(x_197);
lean_dec(x_188);
lean_dec(x_182);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_231 = lean_ctor_get(x_205, 0);
lean_inc(x_231);
x_232 = lean_ctor_get(x_205, 1);
lean_inc(x_232);
if (lean_is_exclusive(x_205)) {
 lean_ctor_release(x_205, 0);
 lean_ctor_release(x_205, 1);
 x_233 = x_205;
} else {
 lean_dec_ref(x_205);
 x_233 = lean_box(0);
}
if (lean_is_scalar(x_233)) {
 x_234 = lean_alloc_ctor(1, 2, 0);
} else {
 x_234 = x_233;
}
lean_ctor_set(x_234, 0, x_231);
lean_ctor_set(x_234, 1, x_232);
return x_234;
}
}
}
else
{
lean_object* x_235; lean_object* x_236; lean_object* x_237; lean_object* x_238; 
lean_dec(x_188);
lean_dec(x_184);
lean_dec(x_182);
lean_dec(x_181);
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_235 = lean_ctor_get(x_189, 0);
lean_inc(x_235);
x_236 = lean_ctor_get(x_189, 1);
lean_inc(x_236);
if (lean_is_exclusive(x_189)) {
 lean_ctor_release(x_189, 0);
 lean_ctor_release(x_189, 1);
 x_237 = x_189;
} else {
 lean_dec_ref(x_189);
 x_237 = lean_box(0);
}
if (lean_is_scalar(x_237)) {
 x_238 = lean_alloc_ctor(1, 2, 0);
} else {
 x_238 = x_237;
}
lean_ctor_set(x_238, 0, x_235);
lean_ctor_set(x_238, 1, x_236);
return x_238;
}
}
}
}
}
else
{
uint8_t x_239; 
lean_dec(x_16);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_239 = !lean_is_exclusive(x_17);
if (x_239 == 0)
{
return x_17;
}
else
{
lean_object* x_240; lean_object* x_241; lean_object* x_242; 
x_240 = lean_ctor_get(x_17, 0);
x_241 = lean_ctor_get(x_17, 1);
lean_inc(x_241);
lean_inc(x_240);
lean_dec(x_17);
x_242 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_242, 0, x_240);
lean_ctor_set(x_242, 1, x_241);
return x_242;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8) {
_start:
{
lean_object* x_9; 
x_9 = l_BitVec_reduceShiftShift___redArg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8);
lean_dec(x_3);
return x_9;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftShift___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceShiftShift(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("shiftLeft_add", 13, 13);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftLeft___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_Lean_Meta_getNatValue_x3f(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_13);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; uint8_t x_24; 
x_22 = lean_ctor_get(x_13, 1);
x_23 = lean_ctor_get(x_13, 0);
lean_dec(x_23);
x_24 = !lean_is_exclusive(x_14);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; uint8_t x_28; 
x_25 = lean_ctor_get(x_14, 0);
x_26 = l_Lean_Expr_appFn_x21(x_1);
x_27 = l_Lean_Expr_appArg_x21(x_26);
lean_dec(x_26);
x_28 = l_Lean_Expr_isAppOfArity(x_27, x_7, x_8);
if (x_28 == 0)
{
lean_object* x_29; 
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_29);
return x_13;
}
else
{
lean_object* x_30; lean_object* x_31; 
lean_free_object(x_13);
x_30 = l_Lean_Expr_appArg_x21(x_27);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_31 = l_Lean_Meta_getNatValue_x3f(x_30, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_31) == 0)
{
lean_object* x_32; 
x_32 = lean_ctor_get(x_31, 0);
lean_inc(x_32);
if (lean_obj_tag(x_32) == 0)
{
uint8_t x_33; 
lean_dec(x_30);
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_33 = !lean_is_exclusive(x_31);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; 
x_34 = lean_ctor_get(x_31, 0);
lean_dec(x_34);
x_35 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_31, 0, x_35);
return x_31;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_36 = lean_ctor_get(x_31, 1);
lean_inc(x_36);
lean_dec(x_31);
x_37 = l_BitVec_reduceBinPred___redArg___closed__0;
x_38 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_36);
return x_38;
}
}
else
{
lean_object* x_39; uint8_t x_40; 
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_dec(x_31);
x_40 = !lean_is_exclusive(x_32);
if (x_40 == 0)
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_41 = lean_ctor_get(x_32, 0);
x_42 = l_Lean_Expr_appFn_x21(x_27);
lean_dec(x_27);
x_43 = l_Lean_Expr_appArg_x21(x_42);
lean_dec(x_42);
x_44 = lean_nat_add(x_25, x_41);
lean_dec(x_41);
lean_dec(x_25);
x_45 = l_Lean_mkNatLit(x_44);
x_46 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_43);
x_47 = lean_array_push(x_46, x_43);
x_48 = lean_array_push(x_47, x_45);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_49 = l_Lean_Meta_mkAppM(x_7, x_48, x_2, x_3, x_4, x_5, x_39);
if (lean_obj_tag(x_49) == 0)
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_50 = lean_ctor_get(x_49, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_49, 1);
lean_inc(x_51);
lean_dec(x_49);
x_52 = l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1;
x_53 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_54 = lean_array_push(x_53, x_43);
x_55 = lean_array_push(x_54, x_30);
x_56 = lean_array_push(x_55, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_57 = l_Lean_Meta_mkAppM(x_52, x_56, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_57, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_57, 1);
lean_inc(x_59);
lean_dec(x_57);
x_60 = l_Lean_Meta_mkEqSymm(x_58, x_2, x_3, x_4, x_5, x_59);
if (lean_obj_tag(x_60) == 0)
{
uint8_t x_61; 
x_61 = !lean_is_exclusive(x_60);
if (x_61 == 0)
{
lean_object* x_62; lean_object* x_63; 
x_62 = lean_ctor_get(x_60, 0);
lean_ctor_set(x_32, 0, x_62);
x_63 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_63, 0, x_50);
lean_ctor_set(x_63, 1, x_32);
lean_ctor_set_uint8(x_63, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_63);
lean_ctor_set(x_60, 0, x_14);
return x_60;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_64 = lean_ctor_get(x_60, 0);
x_65 = lean_ctor_get(x_60, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_60);
lean_ctor_set(x_32, 0, x_64);
x_66 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_66, 0, x_50);
lean_ctor_set(x_66, 1, x_32);
lean_ctor_set_uint8(x_66, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_66);
x_67 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_67, 0, x_14);
lean_ctor_set(x_67, 1, x_65);
return x_67;
}
}
else
{
uint8_t x_68; 
lean_dec(x_50);
lean_free_object(x_32);
lean_free_object(x_14);
x_68 = !lean_is_exclusive(x_60);
if (x_68 == 0)
{
return x_60;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_60, 0);
x_70 = lean_ctor_get(x_60, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_60);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
else
{
uint8_t x_72; 
lean_dec(x_50);
lean_free_object(x_32);
lean_free_object(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_72 = !lean_is_exclusive(x_57);
if (x_72 == 0)
{
return x_57;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_73 = lean_ctor_get(x_57, 0);
x_74 = lean_ctor_get(x_57, 1);
lean_inc(x_74);
lean_inc(x_73);
lean_dec(x_57);
x_75 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_75, 0, x_73);
lean_ctor_set(x_75, 1, x_74);
return x_75;
}
}
}
else
{
uint8_t x_76; 
lean_dec(x_43);
lean_free_object(x_32);
lean_dec(x_30);
lean_free_object(x_14);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_76 = !lean_is_exclusive(x_49);
if (x_76 == 0)
{
return x_49;
}
else
{
lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_77 = lean_ctor_get(x_49, 0);
x_78 = lean_ctor_get(x_49, 1);
lean_inc(x_78);
lean_inc(x_77);
lean_dec(x_49);
x_79 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_79, 0, x_77);
lean_ctor_set(x_79, 1, x_78);
return x_79;
}
}
}
else
{
lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_80 = lean_ctor_get(x_32, 0);
lean_inc(x_80);
lean_dec(x_32);
x_81 = l_Lean_Expr_appFn_x21(x_27);
lean_dec(x_27);
x_82 = l_Lean_Expr_appArg_x21(x_81);
lean_dec(x_81);
x_83 = lean_nat_add(x_25, x_80);
lean_dec(x_80);
lean_dec(x_25);
x_84 = l_Lean_mkNatLit(x_83);
x_85 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_82);
x_86 = lean_array_push(x_85, x_82);
x_87 = lean_array_push(x_86, x_84);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_88 = l_Lean_Meta_mkAppM(x_7, x_87, x_2, x_3, x_4, x_5, x_39);
if (lean_obj_tag(x_88) == 0)
{
lean_object* x_89; lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; lean_object* x_94; lean_object* x_95; lean_object* x_96; 
x_89 = lean_ctor_get(x_88, 0);
lean_inc(x_89);
x_90 = lean_ctor_get(x_88, 1);
lean_inc(x_90);
lean_dec(x_88);
x_91 = l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1;
x_92 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_93 = lean_array_push(x_92, x_82);
x_94 = lean_array_push(x_93, x_30);
x_95 = lean_array_push(x_94, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_96 = l_Lean_Meta_mkAppM(x_91, x_95, x_2, x_3, x_4, x_5, x_90);
if (lean_obj_tag(x_96) == 0)
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; 
x_97 = lean_ctor_get(x_96, 0);
lean_inc(x_97);
x_98 = lean_ctor_get(x_96, 1);
lean_inc(x_98);
lean_dec(x_96);
x_99 = l_Lean_Meta_mkEqSymm(x_97, x_2, x_3, x_4, x_5, x_98);
if (lean_obj_tag(x_99) == 0)
{
lean_object* x_100; lean_object* x_101; lean_object* x_102; lean_object* x_103; lean_object* x_104; lean_object* x_105; 
x_100 = lean_ctor_get(x_99, 0);
lean_inc(x_100);
x_101 = lean_ctor_get(x_99, 1);
lean_inc(x_101);
if (lean_is_exclusive(x_99)) {
 lean_ctor_release(x_99, 0);
 lean_ctor_release(x_99, 1);
 x_102 = x_99;
} else {
 lean_dec_ref(x_99);
 x_102 = lean_box(0);
}
x_103 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_103, 0, x_100);
x_104 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_104, 0, x_89);
lean_ctor_set(x_104, 1, x_103);
lean_ctor_set_uint8(x_104, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_104);
if (lean_is_scalar(x_102)) {
 x_105 = lean_alloc_ctor(0, 2, 0);
} else {
 x_105 = x_102;
}
lean_ctor_set(x_105, 0, x_14);
lean_ctor_set(x_105, 1, x_101);
return x_105;
}
else
{
lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; 
lean_dec(x_89);
lean_free_object(x_14);
x_106 = lean_ctor_get(x_99, 0);
lean_inc(x_106);
x_107 = lean_ctor_get(x_99, 1);
lean_inc(x_107);
if (lean_is_exclusive(x_99)) {
 lean_ctor_release(x_99, 0);
 lean_ctor_release(x_99, 1);
 x_108 = x_99;
} else {
 lean_dec_ref(x_99);
 x_108 = lean_box(0);
}
if (lean_is_scalar(x_108)) {
 x_109 = lean_alloc_ctor(1, 2, 0);
} else {
 x_109 = x_108;
}
lean_ctor_set(x_109, 0, x_106);
lean_ctor_set(x_109, 1, x_107);
return x_109;
}
}
else
{
lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; 
lean_dec(x_89);
lean_free_object(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_110 = lean_ctor_get(x_96, 0);
lean_inc(x_110);
x_111 = lean_ctor_get(x_96, 1);
lean_inc(x_111);
if (lean_is_exclusive(x_96)) {
 lean_ctor_release(x_96, 0);
 lean_ctor_release(x_96, 1);
 x_112 = x_96;
} else {
 lean_dec_ref(x_96);
 x_112 = lean_box(0);
}
if (lean_is_scalar(x_112)) {
 x_113 = lean_alloc_ctor(1, 2, 0);
} else {
 x_113 = x_112;
}
lean_ctor_set(x_113, 0, x_110);
lean_ctor_set(x_113, 1, x_111);
return x_113;
}
}
else
{
lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; 
lean_dec(x_82);
lean_dec(x_30);
lean_free_object(x_14);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_114 = lean_ctor_get(x_88, 0);
lean_inc(x_114);
x_115 = lean_ctor_get(x_88, 1);
lean_inc(x_115);
if (lean_is_exclusive(x_88)) {
 lean_ctor_release(x_88, 0);
 lean_ctor_release(x_88, 1);
 x_116 = x_88;
} else {
 lean_dec_ref(x_88);
 x_116 = lean_box(0);
}
if (lean_is_scalar(x_116)) {
 x_117 = lean_alloc_ctor(1, 2, 0);
} else {
 x_117 = x_116;
}
lean_ctor_set(x_117, 0, x_114);
lean_ctor_set(x_117, 1, x_115);
return x_117;
}
}
}
}
else
{
uint8_t x_118; 
lean_dec(x_30);
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_118 = !lean_is_exclusive(x_31);
if (x_118 == 0)
{
return x_31;
}
else
{
lean_object* x_119; lean_object* x_120; lean_object* x_121; 
x_119 = lean_ctor_get(x_31, 0);
x_120 = lean_ctor_get(x_31, 1);
lean_inc(x_120);
lean_inc(x_119);
lean_dec(x_31);
x_121 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_121, 0, x_119);
lean_ctor_set(x_121, 1, x_120);
return x_121;
}
}
}
}
else
{
lean_object* x_122; lean_object* x_123; lean_object* x_124; uint8_t x_125; 
x_122 = lean_ctor_get(x_14, 0);
lean_inc(x_122);
lean_dec(x_14);
x_123 = l_Lean_Expr_appFn_x21(x_1);
x_124 = l_Lean_Expr_appArg_x21(x_123);
lean_dec(x_123);
x_125 = l_Lean_Expr_isAppOfArity(x_124, x_7, x_8);
if (x_125 == 0)
{
lean_object* x_126; 
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_126 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_126);
return x_13;
}
else
{
lean_object* x_127; lean_object* x_128; 
lean_free_object(x_13);
x_127 = l_Lean_Expr_appArg_x21(x_124);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_128 = l_Lean_Meta_getNatValue_x3f(x_127, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_128) == 0)
{
lean_object* x_129; 
x_129 = lean_ctor_get(x_128, 0);
lean_inc(x_129);
if (lean_obj_tag(x_129) == 0)
{
lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; 
lean_dec(x_127);
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_130 = lean_ctor_get(x_128, 1);
lean_inc(x_130);
if (lean_is_exclusive(x_128)) {
 lean_ctor_release(x_128, 0);
 lean_ctor_release(x_128, 1);
 x_131 = x_128;
} else {
 lean_dec_ref(x_128);
 x_131 = lean_box(0);
}
x_132 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_131)) {
 x_133 = lean_alloc_ctor(0, 2, 0);
} else {
 x_133 = x_131;
}
lean_ctor_set(x_133, 0, x_132);
lean_ctor_set(x_133, 1, x_130);
return x_133;
}
else
{
lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; 
x_134 = lean_ctor_get(x_128, 1);
lean_inc(x_134);
lean_dec(x_128);
x_135 = lean_ctor_get(x_129, 0);
lean_inc(x_135);
if (lean_is_exclusive(x_129)) {
 lean_ctor_release(x_129, 0);
 x_136 = x_129;
} else {
 lean_dec_ref(x_129);
 x_136 = lean_box(0);
}
x_137 = l_Lean_Expr_appFn_x21(x_124);
lean_dec(x_124);
x_138 = l_Lean_Expr_appArg_x21(x_137);
lean_dec(x_137);
x_139 = lean_nat_add(x_122, x_135);
lean_dec(x_135);
lean_dec(x_122);
x_140 = l_Lean_mkNatLit(x_139);
x_141 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_138);
x_142 = lean_array_push(x_141, x_138);
x_143 = lean_array_push(x_142, x_140);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_144 = l_Lean_Meta_mkAppM(x_7, x_143, x_2, x_3, x_4, x_5, x_134);
if (lean_obj_tag(x_144) == 0)
{
lean_object* x_145; lean_object* x_146; lean_object* x_147; lean_object* x_148; lean_object* x_149; lean_object* x_150; lean_object* x_151; lean_object* x_152; 
x_145 = lean_ctor_get(x_144, 0);
lean_inc(x_145);
x_146 = lean_ctor_get(x_144, 1);
lean_inc(x_146);
lean_dec(x_144);
x_147 = l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1;
x_148 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_149 = lean_array_push(x_148, x_138);
x_150 = lean_array_push(x_149, x_127);
x_151 = lean_array_push(x_150, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_152 = l_Lean_Meta_mkAppM(x_147, x_151, x_2, x_3, x_4, x_5, x_146);
if (lean_obj_tag(x_152) == 0)
{
lean_object* x_153; lean_object* x_154; lean_object* x_155; 
x_153 = lean_ctor_get(x_152, 0);
lean_inc(x_153);
x_154 = lean_ctor_get(x_152, 1);
lean_inc(x_154);
lean_dec(x_152);
x_155 = l_Lean_Meta_mkEqSymm(x_153, x_2, x_3, x_4, x_5, x_154);
if (lean_obj_tag(x_155) == 0)
{
lean_object* x_156; lean_object* x_157; lean_object* x_158; lean_object* x_159; lean_object* x_160; lean_object* x_161; lean_object* x_162; 
x_156 = lean_ctor_get(x_155, 0);
lean_inc(x_156);
x_157 = lean_ctor_get(x_155, 1);
lean_inc(x_157);
if (lean_is_exclusive(x_155)) {
 lean_ctor_release(x_155, 0);
 lean_ctor_release(x_155, 1);
 x_158 = x_155;
} else {
 lean_dec_ref(x_155);
 x_158 = lean_box(0);
}
if (lean_is_scalar(x_136)) {
 x_159 = lean_alloc_ctor(1, 1, 0);
} else {
 x_159 = x_136;
}
lean_ctor_set(x_159, 0, x_156);
x_160 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_160, 0, x_145);
lean_ctor_set(x_160, 1, x_159);
lean_ctor_set_uint8(x_160, sizeof(void*)*2, x_125);
x_161 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_161, 0, x_160);
if (lean_is_scalar(x_158)) {
 x_162 = lean_alloc_ctor(0, 2, 0);
} else {
 x_162 = x_158;
}
lean_ctor_set(x_162, 0, x_161);
lean_ctor_set(x_162, 1, x_157);
return x_162;
}
else
{
lean_object* x_163; lean_object* x_164; lean_object* x_165; lean_object* x_166; 
lean_dec(x_145);
lean_dec(x_136);
x_163 = lean_ctor_get(x_155, 0);
lean_inc(x_163);
x_164 = lean_ctor_get(x_155, 1);
lean_inc(x_164);
if (lean_is_exclusive(x_155)) {
 lean_ctor_release(x_155, 0);
 lean_ctor_release(x_155, 1);
 x_165 = x_155;
} else {
 lean_dec_ref(x_155);
 x_165 = lean_box(0);
}
if (lean_is_scalar(x_165)) {
 x_166 = lean_alloc_ctor(1, 2, 0);
} else {
 x_166 = x_165;
}
lean_ctor_set(x_166, 0, x_163);
lean_ctor_set(x_166, 1, x_164);
return x_166;
}
}
else
{
lean_object* x_167; lean_object* x_168; lean_object* x_169; lean_object* x_170; 
lean_dec(x_145);
lean_dec(x_136);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_167 = lean_ctor_get(x_152, 0);
lean_inc(x_167);
x_168 = lean_ctor_get(x_152, 1);
lean_inc(x_168);
if (lean_is_exclusive(x_152)) {
 lean_ctor_release(x_152, 0);
 lean_ctor_release(x_152, 1);
 x_169 = x_152;
} else {
 lean_dec_ref(x_152);
 x_169 = lean_box(0);
}
if (lean_is_scalar(x_169)) {
 x_170 = lean_alloc_ctor(1, 2, 0);
} else {
 x_170 = x_169;
}
lean_ctor_set(x_170, 0, x_167);
lean_ctor_set(x_170, 1, x_168);
return x_170;
}
}
else
{
lean_object* x_171; lean_object* x_172; lean_object* x_173; lean_object* x_174; 
lean_dec(x_138);
lean_dec(x_136);
lean_dec(x_127);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_171 = lean_ctor_get(x_144, 0);
lean_inc(x_171);
x_172 = lean_ctor_get(x_144, 1);
lean_inc(x_172);
if (lean_is_exclusive(x_144)) {
 lean_ctor_release(x_144, 0);
 lean_ctor_release(x_144, 1);
 x_173 = x_144;
} else {
 lean_dec_ref(x_144);
 x_173 = lean_box(0);
}
if (lean_is_scalar(x_173)) {
 x_174 = lean_alloc_ctor(1, 2, 0);
} else {
 x_174 = x_173;
}
lean_ctor_set(x_174, 0, x_171);
lean_ctor_set(x_174, 1, x_172);
return x_174;
}
}
}
else
{
lean_object* x_175; lean_object* x_176; lean_object* x_177; lean_object* x_178; 
lean_dec(x_127);
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_175 = lean_ctor_get(x_128, 0);
lean_inc(x_175);
x_176 = lean_ctor_get(x_128, 1);
lean_inc(x_176);
if (lean_is_exclusive(x_128)) {
 lean_ctor_release(x_128, 0);
 lean_ctor_release(x_128, 1);
 x_177 = x_128;
} else {
 lean_dec_ref(x_128);
 x_177 = lean_box(0);
}
if (lean_is_scalar(x_177)) {
 x_178 = lean_alloc_ctor(1, 2, 0);
} else {
 x_178 = x_177;
}
lean_ctor_set(x_178, 0, x_175);
lean_ctor_set(x_178, 1, x_176);
return x_178;
}
}
}
}
else
{
lean_object* x_179; lean_object* x_180; lean_object* x_181; lean_object* x_182; lean_object* x_183; uint8_t x_184; 
x_179 = lean_ctor_get(x_13, 1);
lean_inc(x_179);
lean_dec(x_13);
x_180 = lean_ctor_get(x_14, 0);
lean_inc(x_180);
if (lean_is_exclusive(x_14)) {
 lean_ctor_release(x_14, 0);
 x_181 = x_14;
} else {
 lean_dec_ref(x_14);
 x_181 = lean_box(0);
}
x_182 = l_Lean_Expr_appFn_x21(x_1);
x_183 = l_Lean_Expr_appArg_x21(x_182);
lean_dec(x_182);
x_184 = l_Lean_Expr_isAppOfArity(x_183, x_7, x_8);
if (x_184 == 0)
{
lean_object* x_185; lean_object* x_186; 
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_185 = l_BitVec_reduceBinPred___redArg___closed__0;
x_186 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_186, 0, x_185);
lean_ctor_set(x_186, 1, x_179);
return x_186;
}
else
{
lean_object* x_187; lean_object* x_188; 
x_187 = l_Lean_Expr_appArg_x21(x_183);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_188 = l_Lean_Meta_getNatValue_x3f(x_187, x_2, x_3, x_4, x_5, x_179);
if (lean_obj_tag(x_188) == 0)
{
lean_object* x_189; 
x_189 = lean_ctor_get(x_188, 0);
lean_inc(x_189);
if (lean_obj_tag(x_189) == 0)
{
lean_object* x_190; lean_object* x_191; lean_object* x_192; lean_object* x_193; 
lean_dec(x_187);
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_190 = lean_ctor_get(x_188, 1);
lean_inc(x_190);
if (lean_is_exclusive(x_188)) {
 lean_ctor_release(x_188, 0);
 lean_ctor_release(x_188, 1);
 x_191 = x_188;
} else {
 lean_dec_ref(x_188);
 x_191 = lean_box(0);
}
x_192 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_191)) {
 x_193 = lean_alloc_ctor(0, 2, 0);
} else {
 x_193 = x_191;
}
lean_ctor_set(x_193, 0, x_192);
lean_ctor_set(x_193, 1, x_190);
return x_193;
}
else
{
lean_object* x_194; lean_object* x_195; lean_object* x_196; lean_object* x_197; lean_object* x_198; lean_object* x_199; lean_object* x_200; lean_object* x_201; lean_object* x_202; lean_object* x_203; lean_object* x_204; 
x_194 = lean_ctor_get(x_188, 1);
lean_inc(x_194);
lean_dec(x_188);
x_195 = lean_ctor_get(x_189, 0);
lean_inc(x_195);
if (lean_is_exclusive(x_189)) {
 lean_ctor_release(x_189, 0);
 x_196 = x_189;
} else {
 lean_dec_ref(x_189);
 x_196 = lean_box(0);
}
x_197 = l_Lean_Expr_appFn_x21(x_183);
lean_dec(x_183);
x_198 = l_Lean_Expr_appArg_x21(x_197);
lean_dec(x_197);
x_199 = lean_nat_add(x_180, x_195);
lean_dec(x_195);
lean_dec(x_180);
x_200 = l_Lean_mkNatLit(x_199);
x_201 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_198);
x_202 = lean_array_push(x_201, x_198);
x_203 = lean_array_push(x_202, x_200);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_204 = l_Lean_Meta_mkAppM(x_7, x_203, x_2, x_3, x_4, x_5, x_194);
if (lean_obj_tag(x_204) == 0)
{
lean_object* x_205; lean_object* x_206; lean_object* x_207; lean_object* x_208; lean_object* x_209; lean_object* x_210; lean_object* x_211; lean_object* x_212; 
x_205 = lean_ctor_get(x_204, 0);
lean_inc(x_205);
x_206 = lean_ctor_get(x_204, 1);
lean_inc(x_206);
lean_dec(x_204);
x_207 = l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1;
x_208 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_209 = lean_array_push(x_208, x_198);
x_210 = lean_array_push(x_209, x_187);
x_211 = lean_array_push(x_210, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_212 = l_Lean_Meta_mkAppM(x_207, x_211, x_2, x_3, x_4, x_5, x_206);
if (lean_obj_tag(x_212) == 0)
{
lean_object* x_213; lean_object* x_214; lean_object* x_215; 
x_213 = lean_ctor_get(x_212, 0);
lean_inc(x_213);
x_214 = lean_ctor_get(x_212, 1);
lean_inc(x_214);
lean_dec(x_212);
x_215 = l_Lean_Meta_mkEqSymm(x_213, x_2, x_3, x_4, x_5, x_214);
if (lean_obj_tag(x_215) == 0)
{
lean_object* x_216; lean_object* x_217; lean_object* x_218; lean_object* x_219; lean_object* x_220; lean_object* x_221; lean_object* x_222; 
x_216 = lean_ctor_get(x_215, 0);
lean_inc(x_216);
x_217 = lean_ctor_get(x_215, 1);
lean_inc(x_217);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_218 = x_215;
} else {
 lean_dec_ref(x_215);
 x_218 = lean_box(0);
}
if (lean_is_scalar(x_196)) {
 x_219 = lean_alloc_ctor(1, 1, 0);
} else {
 x_219 = x_196;
}
lean_ctor_set(x_219, 0, x_216);
x_220 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_220, 0, x_205);
lean_ctor_set(x_220, 1, x_219);
lean_ctor_set_uint8(x_220, sizeof(void*)*2, x_184);
if (lean_is_scalar(x_181)) {
 x_221 = lean_alloc_ctor(1, 1, 0);
} else {
 x_221 = x_181;
}
lean_ctor_set(x_221, 0, x_220);
if (lean_is_scalar(x_218)) {
 x_222 = lean_alloc_ctor(0, 2, 0);
} else {
 x_222 = x_218;
}
lean_ctor_set(x_222, 0, x_221);
lean_ctor_set(x_222, 1, x_217);
return x_222;
}
else
{
lean_object* x_223; lean_object* x_224; lean_object* x_225; lean_object* x_226; 
lean_dec(x_205);
lean_dec(x_196);
lean_dec(x_181);
x_223 = lean_ctor_get(x_215, 0);
lean_inc(x_223);
x_224 = lean_ctor_get(x_215, 1);
lean_inc(x_224);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_225 = x_215;
} else {
 lean_dec_ref(x_215);
 x_225 = lean_box(0);
}
if (lean_is_scalar(x_225)) {
 x_226 = lean_alloc_ctor(1, 2, 0);
} else {
 x_226 = x_225;
}
lean_ctor_set(x_226, 0, x_223);
lean_ctor_set(x_226, 1, x_224);
return x_226;
}
}
else
{
lean_object* x_227; lean_object* x_228; lean_object* x_229; lean_object* x_230; 
lean_dec(x_205);
lean_dec(x_196);
lean_dec(x_181);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_227 = lean_ctor_get(x_212, 0);
lean_inc(x_227);
x_228 = lean_ctor_get(x_212, 1);
lean_inc(x_228);
if (lean_is_exclusive(x_212)) {
 lean_ctor_release(x_212, 0);
 lean_ctor_release(x_212, 1);
 x_229 = x_212;
} else {
 lean_dec_ref(x_212);
 x_229 = lean_box(0);
}
if (lean_is_scalar(x_229)) {
 x_230 = lean_alloc_ctor(1, 2, 0);
} else {
 x_230 = x_229;
}
lean_ctor_set(x_230, 0, x_227);
lean_ctor_set(x_230, 1, x_228);
return x_230;
}
}
else
{
lean_object* x_231; lean_object* x_232; lean_object* x_233; lean_object* x_234; 
lean_dec(x_198);
lean_dec(x_196);
lean_dec(x_187);
lean_dec(x_181);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_231 = lean_ctor_get(x_204, 0);
lean_inc(x_231);
x_232 = lean_ctor_get(x_204, 1);
lean_inc(x_232);
if (lean_is_exclusive(x_204)) {
 lean_ctor_release(x_204, 0);
 lean_ctor_release(x_204, 1);
 x_233 = x_204;
} else {
 lean_dec_ref(x_204);
 x_233 = lean_box(0);
}
if (lean_is_scalar(x_233)) {
 x_234 = lean_alloc_ctor(1, 2, 0);
} else {
 x_234 = x_233;
}
lean_ctor_set(x_234, 0, x_231);
lean_ctor_set(x_234, 1, x_232);
return x_234;
}
}
}
else
{
lean_object* x_235; lean_object* x_236; lean_object* x_237; lean_object* x_238; 
lean_dec(x_187);
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_235 = lean_ctor_get(x_188, 0);
lean_inc(x_235);
x_236 = lean_ctor_get(x_188, 1);
lean_inc(x_236);
if (lean_is_exclusive(x_188)) {
 lean_ctor_release(x_188, 0);
 lean_ctor_release(x_188, 1);
 x_237 = x_188;
} else {
 lean_dec_ref(x_188);
 x_237 = lean_box(0);
}
if (lean_is_scalar(x_237)) {
 x_238 = lean_alloc_ctor(1, 2, 0);
} else {
 x_238 = x_237;
}
lean_ctor_set(x_238, 0, x_235);
lean_ctor_set(x_238, 1, x_236);
return x_238;
}
}
}
}
}
else
{
uint8_t x_239; 
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_239 = !lean_is_exclusive(x_13);
if (x_239 == 0)
{
return x_13;
}
else
{
lean_object* x_240; lean_object* x_241; lean_object* x_242; 
x_240 = lean_ctor_get(x_13, 0);
x_241 = lean_ctor_get(x_13, 1);
lean_inc(x_241);
lean_inc(x_240);
lean_dec(x_13);
x_242 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_242, 0, x_240);
lean_ctor_set(x_242, 1, x_241);
return x_242;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeftShiftLeft___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceShiftLeftShiftLeft___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftLeftShiftLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceShiftLeftShiftLeft", 24, 24);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(16u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftShiftLeft___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftShiftLeft___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceShiftRightShiftRight___redArg___closed__0() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("shiftRight_add", 14, 14);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftRightShiftRight___redArg___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftRightShiftRight___redArg___closed__0;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___redArg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; lean_object* x_8; uint8_t x_9; 
x_7 = l_BitVec_reduceHShiftRight___redArg___closed__2;
x_8 = lean_unsigned_to_nat(6u);
x_9 = l_Lean_Expr_isAppOfArity(x_1, x_7, x_8);
if (x_9 == 0)
{
lean_object* x_10; lean_object* x_11; 
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_10 = l_BitVec_reduceBinPred___redArg___closed__0;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_6);
return x_11;
}
else
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_13 = l_Lean_Meta_getNatValue_x3f(x_12, x_2, x_3, x_4, x_5, x_6);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___redArg___closed__0;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_13);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; uint8_t x_24; 
x_22 = lean_ctor_get(x_13, 1);
x_23 = lean_ctor_get(x_13, 0);
lean_dec(x_23);
x_24 = !lean_is_exclusive(x_14);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; uint8_t x_28; 
x_25 = lean_ctor_get(x_14, 0);
x_26 = l_Lean_Expr_appFn_x21(x_1);
x_27 = l_Lean_Expr_appArg_x21(x_26);
lean_dec(x_26);
x_28 = l_Lean_Expr_isAppOfArity(x_27, x_7, x_8);
if (x_28 == 0)
{
lean_object* x_29; 
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_29 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_29);
return x_13;
}
else
{
lean_object* x_30; lean_object* x_31; 
lean_free_object(x_13);
x_30 = l_Lean_Expr_appArg_x21(x_27);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_31 = l_Lean_Meta_getNatValue_x3f(x_30, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_31) == 0)
{
lean_object* x_32; 
x_32 = lean_ctor_get(x_31, 0);
lean_inc(x_32);
if (lean_obj_tag(x_32) == 0)
{
uint8_t x_33; 
lean_dec(x_30);
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_33 = !lean_is_exclusive(x_31);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; 
x_34 = lean_ctor_get(x_31, 0);
lean_dec(x_34);
x_35 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_31, 0, x_35);
return x_31;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_36 = lean_ctor_get(x_31, 1);
lean_inc(x_36);
lean_dec(x_31);
x_37 = l_BitVec_reduceBinPred___redArg___closed__0;
x_38 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_36);
return x_38;
}
}
else
{
lean_object* x_39; uint8_t x_40; 
x_39 = lean_ctor_get(x_31, 1);
lean_inc(x_39);
lean_dec(x_31);
x_40 = !lean_is_exclusive(x_32);
if (x_40 == 0)
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_41 = lean_ctor_get(x_32, 0);
x_42 = l_Lean_Expr_appFn_x21(x_27);
lean_dec(x_27);
x_43 = l_Lean_Expr_appArg_x21(x_42);
lean_dec(x_42);
x_44 = lean_nat_add(x_25, x_41);
lean_dec(x_41);
lean_dec(x_25);
x_45 = l_Lean_mkNatLit(x_44);
x_46 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_43);
x_47 = lean_array_push(x_46, x_43);
x_48 = lean_array_push(x_47, x_45);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_49 = l_Lean_Meta_mkAppM(x_7, x_48, x_2, x_3, x_4, x_5, x_39);
if (lean_obj_tag(x_49) == 0)
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_50 = lean_ctor_get(x_49, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_49, 1);
lean_inc(x_51);
lean_dec(x_49);
x_52 = l_BitVec_reduceShiftRightShiftRight___redArg___closed__1;
x_53 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_54 = lean_array_push(x_53, x_43);
x_55 = lean_array_push(x_54, x_30);
x_56 = lean_array_push(x_55, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_57 = l_Lean_Meta_mkAppM(x_52, x_56, x_2, x_3, x_4, x_5, x_51);
if (lean_obj_tag(x_57) == 0)
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_57, 0);
lean_inc(x_58);
x_59 = lean_ctor_get(x_57, 1);
lean_inc(x_59);
lean_dec(x_57);
x_60 = l_Lean_Meta_mkEqSymm(x_58, x_2, x_3, x_4, x_5, x_59);
if (lean_obj_tag(x_60) == 0)
{
uint8_t x_61; 
x_61 = !lean_is_exclusive(x_60);
if (x_61 == 0)
{
lean_object* x_62; lean_object* x_63; 
x_62 = lean_ctor_get(x_60, 0);
lean_ctor_set(x_32, 0, x_62);
x_63 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_63, 0, x_50);
lean_ctor_set(x_63, 1, x_32);
lean_ctor_set_uint8(x_63, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_63);
lean_ctor_set(x_60, 0, x_14);
return x_60;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_64 = lean_ctor_get(x_60, 0);
x_65 = lean_ctor_get(x_60, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_60);
lean_ctor_set(x_32, 0, x_64);
x_66 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_66, 0, x_50);
lean_ctor_set(x_66, 1, x_32);
lean_ctor_set_uint8(x_66, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_66);
x_67 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_67, 0, x_14);
lean_ctor_set(x_67, 1, x_65);
return x_67;
}
}
else
{
uint8_t x_68; 
lean_dec(x_50);
lean_free_object(x_32);
lean_free_object(x_14);
x_68 = !lean_is_exclusive(x_60);
if (x_68 == 0)
{
return x_60;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_60, 0);
x_70 = lean_ctor_get(x_60, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_60);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
else
{
uint8_t x_72; 
lean_dec(x_50);
lean_free_object(x_32);
lean_free_object(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_72 = !lean_is_exclusive(x_57);
if (x_72 == 0)
{
return x_57;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_73 = lean_ctor_get(x_57, 0);
x_74 = lean_ctor_get(x_57, 1);
lean_inc(x_74);
lean_inc(x_73);
lean_dec(x_57);
x_75 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_75, 0, x_73);
lean_ctor_set(x_75, 1, x_74);
return x_75;
}
}
}
else
{
uint8_t x_76; 
lean_dec(x_43);
lean_free_object(x_32);
lean_dec(x_30);
lean_free_object(x_14);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_76 = !lean_is_exclusive(x_49);
if (x_76 == 0)
{
return x_49;
}
else
{
lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_77 = lean_ctor_get(x_49, 0);
x_78 = lean_ctor_get(x_49, 1);
lean_inc(x_78);
lean_inc(x_77);
lean_dec(x_49);
x_79 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_79, 0, x_77);
lean_ctor_set(x_79, 1, x_78);
return x_79;
}
}
}
else
{
lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; 
x_80 = lean_ctor_get(x_32, 0);
lean_inc(x_80);
lean_dec(x_32);
x_81 = l_Lean_Expr_appFn_x21(x_27);
lean_dec(x_27);
x_82 = l_Lean_Expr_appArg_x21(x_81);
lean_dec(x_81);
x_83 = lean_nat_add(x_25, x_80);
lean_dec(x_80);
lean_dec(x_25);
x_84 = l_Lean_mkNatLit(x_83);
x_85 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_82);
x_86 = lean_array_push(x_85, x_82);
x_87 = lean_array_push(x_86, x_84);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_88 = l_Lean_Meta_mkAppM(x_7, x_87, x_2, x_3, x_4, x_5, x_39);
if (lean_obj_tag(x_88) == 0)
{
lean_object* x_89; lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; lean_object* x_94; lean_object* x_95; lean_object* x_96; 
x_89 = lean_ctor_get(x_88, 0);
lean_inc(x_89);
x_90 = lean_ctor_get(x_88, 1);
lean_inc(x_90);
lean_dec(x_88);
x_91 = l_BitVec_reduceShiftRightShiftRight___redArg___closed__1;
x_92 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_93 = lean_array_push(x_92, x_82);
x_94 = lean_array_push(x_93, x_30);
x_95 = lean_array_push(x_94, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_96 = l_Lean_Meta_mkAppM(x_91, x_95, x_2, x_3, x_4, x_5, x_90);
if (lean_obj_tag(x_96) == 0)
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; 
x_97 = lean_ctor_get(x_96, 0);
lean_inc(x_97);
x_98 = lean_ctor_get(x_96, 1);
lean_inc(x_98);
lean_dec(x_96);
x_99 = l_Lean_Meta_mkEqSymm(x_97, x_2, x_3, x_4, x_5, x_98);
if (lean_obj_tag(x_99) == 0)
{
lean_object* x_100; lean_object* x_101; lean_object* x_102; lean_object* x_103; lean_object* x_104; lean_object* x_105; 
x_100 = lean_ctor_get(x_99, 0);
lean_inc(x_100);
x_101 = lean_ctor_get(x_99, 1);
lean_inc(x_101);
if (lean_is_exclusive(x_99)) {
 lean_ctor_release(x_99, 0);
 lean_ctor_release(x_99, 1);
 x_102 = x_99;
} else {
 lean_dec_ref(x_99);
 x_102 = lean_box(0);
}
x_103 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_103, 0, x_100);
x_104 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_104, 0, x_89);
lean_ctor_set(x_104, 1, x_103);
lean_ctor_set_uint8(x_104, sizeof(void*)*2, x_28);
lean_ctor_set(x_14, 0, x_104);
if (lean_is_scalar(x_102)) {
 x_105 = lean_alloc_ctor(0, 2, 0);
} else {
 x_105 = x_102;
}
lean_ctor_set(x_105, 0, x_14);
lean_ctor_set(x_105, 1, x_101);
return x_105;
}
else
{
lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; 
lean_dec(x_89);
lean_free_object(x_14);
x_106 = lean_ctor_get(x_99, 0);
lean_inc(x_106);
x_107 = lean_ctor_get(x_99, 1);
lean_inc(x_107);
if (lean_is_exclusive(x_99)) {
 lean_ctor_release(x_99, 0);
 lean_ctor_release(x_99, 1);
 x_108 = x_99;
} else {
 lean_dec_ref(x_99);
 x_108 = lean_box(0);
}
if (lean_is_scalar(x_108)) {
 x_109 = lean_alloc_ctor(1, 2, 0);
} else {
 x_109 = x_108;
}
lean_ctor_set(x_109, 0, x_106);
lean_ctor_set(x_109, 1, x_107);
return x_109;
}
}
else
{
lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; 
lean_dec(x_89);
lean_free_object(x_14);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_110 = lean_ctor_get(x_96, 0);
lean_inc(x_110);
x_111 = lean_ctor_get(x_96, 1);
lean_inc(x_111);
if (lean_is_exclusive(x_96)) {
 lean_ctor_release(x_96, 0);
 lean_ctor_release(x_96, 1);
 x_112 = x_96;
} else {
 lean_dec_ref(x_96);
 x_112 = lean_box(0);
}
if (lean_is_scalar(x_112)) {
 x_113 = lean_alloc_ctor(1, 2, 0);
} else {
 x_113 = x_112;
}
lean_ctor_set(x_113, 0, x_110);
lean_ctor_set(x_113, 1, x_111);
return x_113;
}
}
else
{
lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; 
lean_dec(x_82);
lean_dec(x_30);
lean_free_object(x_14);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_114 = lean_ctor_get(x_88, 0);
lean_inc(x_114);
x_115 = lean_ctor_get(x_88, 1);
lean_inc(x_115);
if (lean_is_exclusive(x_88)) {
 lean_ctor_release(x_88, 0);
 lean_ctor_release(x_88, 1);
 x_116 = x_88;
} else {
 lean_dec_ref(x_88);
 x_116 = lean_box(0);
}
if (lean_is_scalar(x_116)) {
 x_117 = lean_alloc_ctor(1, 2, 0);
} else {
 x_117 = x_116;
}
lean_ctor_set(x_117, 0, x_114);
lean_ctor_set(x_117, 1, x_115);
return x_117;
}
}
}
}
else
{
uint8_t x_118; 
lean_dec(x_30);
lean_dec(x_27);
lean_free_object(x_14);
lean_dec(x_25);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_118 = !lean_is_exclusive(x_31);
if (x_118 == 0)
{
return x_31;
}
else
{
lean_object* x_119; lean_object* x_120; lean_object* x_121; 
x_119 = lean_ctor_get(x_31, 0);
x_120 = lean_ctor_get(x_31, 1);
lean_inc(x_120);
lean_inc(x_119);
lean_dec(x_31);
x_121 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_121, 0, x_119);
lean_ctor_set(x_121, 1, x_120);
return x_121;
}
}
}
}
else
{
lean_object* x_122; lean_object* x_123; lean_object* x_124; uint8_t x_125; 
x_122 = lean_ctor_get(x_14, 0);
lean_inc(x_122);
lean_dec(x_14);
x_123 = l_Lean_Expr_appFn_x21(x_1);
x_124 = l_Lean_Expr_appArg_x21(x_123);
lean_dec(x_123);
x_125 = l_Lean_Expr_isAppOfArity(x_124, x_7, x_8);
if (x_125 == 0)
{
lean_object* x_126; 
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_126 = l_BitVec_reduceBinPred___redArg___closed__0;
lean_ctor_set(x_13, 0, x_126);
return x_13;
}
else
{
lean_object* x_127; lean_object* x_128; 
lean_free_object(x_13);
x_127 = l_Lean_Expr_appArg_x21(x_124);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_128 = l_Lean_Meta_getNatValue_x3f(x_127, x_2, x_3, x_4, x_5, x_22);
if (lean_obj_tag(x_128) == 0)
{
lean_object* x_129; 
x_129 = lean_ctor_get(x_128, 0);
lean_inc(x_129);
if (lean_obj_tag(x_129) == 0)
{
lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; 
lean_dec(x_127);
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_130 = lean_ctor_get(x_128, 1);
lean_inc(x_130);
if (lean_is_exclusive(x_128)) {
 lean_ctor_release(x_128, 0);
 lean_ctor_release(x_128, 1);
 x_131 = x_128;
} else {
 lean_dec_ref(x_128);
 x_131 = lean_box(0);
}
x_132 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_131)) {
 x_133 = lean_alloc_ctor(0, 2, 0);
} else {
 x_133 = x_131;
}
lean_ctor_set(x_133, 0, x_132);
lean_ctor_set(x_133, 1, x_130);
return x_133;
}
else
{
lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; 
x_134 = lean_ctor_get(x_128, 1);
lean_inc(x_134);
lean_dec(x_128);
x_135 = lean_ctor_get(x_129, 0);
lean_inc(x_135);
if (lean_is_exclusive(x_129)) {
 lean_ctor_release(x_129, 0);
 x_136 = x_129;
} else {
 lean_dec_ref(x_129);
 x_136 = lean_box(0);
}
x_137 = l_Lean_Expr_appFn_x21(x_124);
lean_dec(x_124);
x_138 = l_Lean_Expr_appArg_x21(x_137);
lean_dec(x_137);
x_139 = lean_nat_add(x_122, x_135);
lean_dec(x_135);
lean_dec(x_122);
x_140 = l_Lean_mkNatLit(x_139);
x_141 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_138);
x_142 = lean_array_push(x_141, x_138);
x_143 = lean_array_push(x_142, x_140);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_144 = l_Lean_Meta_mkAppM(x_7, x_143, x_2, x_3, x_4, x_5, x_134);
if (lean_obj_tag(x_144) == 0)
{
lean_object* x_145; lean_object* x_146; lean_object* x_147; lean_object* x_148; lean_object* x_149; lean_object* x_150; lean_object* x_151; lean_object* x_152; 
x_145 = lean_ctor_get(x_144, 0);
lean_inc(x_145);
x_146 = lean_ctor_get(x_144, 1);
lean_inc(x_146);
lean_dec(x_144);
x_147 = l_BitVec_reduceShiftRightShiftRight___redArg___closed__1;
x_148 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_149 = lean_array_push(x_148, x_138);
x_150 = lean_array_push(x_149, x_127);
x_151 = lean_array_push(x_150, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_152 = l_Lean_Meta_mkAppM(x_147, x_151, x_2, x_3, x_4, x_5, x_146);
if (lean_obj_tag(x_152) == 0)
{
lean_object* x_153; lean_object* x_154; lean_object* x_155; 
x_153 = lean_ctor_get(x_152, 0);
lean_inc(x_153);
x_154 = lean_ctor_get(x_152, 1);
lean_inc(x_154);
lean_dec(x_152);
x_155 = l_Lean_Meta_mkEqSymm(x_153, x_2, x_3, x_4, x_5, x_154);
if (lean_obj_tag(x_155) == 0)
{
lean_object* x_156; lean_object* x_157; lean_object* x_158; lean_object* x_159; lean_object* x_160; lean_object* x_161; lean_object* x_162; 
x_156 = lean_ctor_get(x_155, 0);
lean_inc(x_156);
x_157 = lean_ctor_get(x_155, 1);
lean_inc(x_157);
if (lean_is_exclusive(x_155)) {
 lean_ctor_release(x_155, 0);
 lean_ctor_release(x_155, 1);
 x_158 = x_155;
} else {
 lean_dec_ref(x_155);
 x_158 = lean_box(0);
}
if (lean_is_scalar(x_136)) {
 x_159 = lean_alloc_ctor(1, 1, 0);
} else {
 x_159 = x_136;
}
lean_ctor_set(x_159, 0, x_156);
x_160 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_160, 0, x_145);
lean_ctor_set(x_160, 1, x_159);
lean_ctor_set_uint8(x_160, sizeof(void*)*2, x_125);
x_161 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_161, 0, x_160);
if (lean_is_scalar(x_158)) {
 x_162 = lean_alloc_ctor(0, 2, 0);
} else {
 x_162 = x_158;
}
lean_ctor_set(x_162, 0, x_161);
lean_ctor_set(x_162, 1, x_157);
return x_162;
}
else
{
lean_object* x_163; lean_object* x_164; lean_object* x_165; lean_object* x_166; 
lean_dec(x_145);
lean_dec(x_136);
x_163 = lean_ctor_get(x_155, 0);
lean_inc(x_163);
x_164 = lean_ctor_get(x_155, 1);
lean_inc(x_164);
if (lean_is_exclusive(x_155)) {
 lean_ctor_release(x_155, 0);
 lean_ctor_release(x_155, 1);
 x_165 = x_155;
} else {
 lean_dec_ref(x_155);
 x_165 = lean_box(0);
}
if (lean_is_scalar(x_165)) {
 x_166 = lean_alloc_ctor(1, 2, 0);
} else {
 x_166 = x_165;
}
lean_ctor_set(x_166, 0, x_163);
lean_ctor_set(x_166, 1, x_164);
return x_166;
}
}
else
{
lean_object* x_167; lean_object* x_168; lean_object* x_169; lean_object* x_170; 
lean_dec(x_145);
lean_dec(x_136);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_167 = lean_ctor_get(x_152, 0);
lean_inc(x_167);
x_168 = lean_ctor_get(x_152, 1);
lean_inc(x_168);
if (lean_is_exclusive(x_152)) {
 lean_ctor_release(x_152, 0);
 lean_ctor_release(x_152, 1);
 x_169 = x_152;
} else {
 lean_dec_ref(x_152);
 x_169 = lean_box(0);
}
if (lean_is_scalar(x_169)) {
 x_170 = lean_alloc_ctor(1, 2, 0);
} else {
 x_170 = x_169;
}
lean_ctor_set(x_170, 0, x_167);
lean_ctor_set(x_170, 1, x_168);
return x_170;
}
}
else
{
lean_object* x_171; lean_object* x_172; lean_object* x_173; lean_object* x_174; 
lean_dec(x_138);
lean_dec(x_136);
lean_dec(x_127);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_171 = lean_ctor_get(x_144, 0);
lean_inc(x_171);
x_172 = lean_ctor_get(x_144, 1);
lean_inc(x_172);
if (lean_is_exclusive(x_144)) {
 lean_ctor_release(x_144, 0);
 lean_ctor_release(x_144, 1);
 x_173 = x_144;
} else {
 lean_dec_ref(x_144);
 x_173 = lean_box(0);
}
if (lean_is_scalar(x_173)) {
 x_174 = lean_alloc_ctor(1, 2, 0);
} else {
 x_174 = x_173;
}
lean_ctor_set(x_174, 0, x_171);
lean_ctor_set(x_174, 1, x_172);
return x_174;
}
}
}
else
{
lean_object* x_175; lean_object* x_176; lean_object* x_177; lean_object* x_178; 
lean_dec(x_127);
lean_dec(x_124);
lean_dec(x_122);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_175 = lean_ctor_get(x_128, 0);
lean_inc(x_175);
x_176 = lean_ctor_get(x_128, 1);
lean_inc(x_176);
if (lean_is_exclusive(x_128)) {
 lean_ctor_release(x_128, 0);
 lean_ctor_release(x_128, 1);
 x_177 = x_128;
} else {
 lean_dec_ref(x_128);
 x_177 = lean_box(0);
}
if (lean_is_scalar(x_177)) {
 x_178 = lean_alloc_ctor(1, 2, 0);
} else {
 x_178 = x_177;
}
lean_ctor_set(x_178, 0, x_175);
lean_ctor_set(x_178, 1, x_176);
return x_178;
}
}
}
}
else
{
lean_object* x_179; lean_object* x_180; lean_object* x_181; lean_object* x_182; lean_object* x_183; uint8_t x_184; 
x_179 = lean_ctor_get(x_13, 1);
lean_inc(x_179);
lean_dec(x_13);
x_180 = lean_ctor_get(x_14, 0);
lean_inc(x_180);
if (lean_is_exclusive(x_14)) {
 lean_ctor_release(x_14, 0);
 x_181 = x_14;
} else {
 lean_dec_ref(x_14);
 x_181 = lean_box(0);
}
x_182 = l_Lean_Expr_appFn_x21(x_1);
x_183 = l_Lean_Expr_appArg_x21(x_182);
lean_dec(x_182);
x_184 = l_Lean_Expr_isAppOfArity(x_183, x_7, x_8);
if (x_184 == 0)
{
lean_object* x_185; lean_object* x_186; 
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_185 = l_BitVec_reduceBinPred___redArg___closed__0;
x_186 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_186, 0, x_185);
lean_ctor_set(x_186, 1, x_179);
return x_186;
}
else
{
lean_object* x_187; lean_object* x_188; 
x_187 = l_Lean_Expr_appArg_x21(x_183);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_188 = l_Lean_Meta_getNatValue_x3f(x_187, x_2, x_3, x_4, x_5, x_179);
if (lean_obj_tag(x_188) == 0)
{
lean_object* x_189; 
x_189 = lean_ctor_get(x_188, 0);
lean_inc(x_189);
if (lean_obj_tag(x_189) == 0)
{
lean_object* x_190; lean_object* x_191; lean_object* x_192; lean_object* x_193; 
lean_dec(x_187);
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_190 = lean_ctor_get(x_188, 1);
lean_inc(x_190);
if (lean_is_exclusive(x_188)) {
 lean_ctor_release(x_188, 0);
 lean_ctor_release(x_188, 1);
 x_191 = x_188;
} else {
 lean_dec_ref(x_188);
 x_191 = lean_box(0);
}
x_192 = l_BitVec_reduceBinPred___redArg___closed__0;
if (lean_is_scalar(x_191)) {
 x_193 = lean_alloc_ctor(0, 2, 0);
} else {
 x_193 = x_191;
}
lean_ctor_set(x_193, 0, x_192);
lean_ctor_set(x_193, 1, x_190);
return x_193;
}
else
{
lean_object* x_194; lean_object* x_195; lean_object* x_196; lean_object* x_197; lean_object* x_198; lean_object* x_199; lean_object* x_200; lean_object* x_201; lean_object* x_202; lean_object* x_203; lean_object* x_204; 
x_194 = lean_ctor_get(x_188, 1);
lean_inc(x_194);
lean_dec(x_188);
x_195 = lean_ctor_get(x_189, 0);
lean_inc(x_195);
if (lean_is_exclusive(x_189)) {
 lean_ctor_release(x_189, 0);
 x_196 = x_189;
} else {
 lean_dec_ref(x_189);
 x_196 = lean_box(0);
}
x_197 = l_Lean_Expr_appFn_x21(x_183);
lean_dec(x_183);
x_198 = l_Lean_Expr_appArg_x21(x_197);
lean_dec(x_197);
x_199 = lean_nat_add(x_180, x_195);
lean_dec(x_195);
lean_dec(x_180);
x_200 = l_Lean_mkNatLit(x_199);
x_201 = l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0;
lean_inc(x_198);
x_202 = lean_array_push(x_201, x_198);
x_203 = lean_array_push(x_202, x_200);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_204 = l_Lean_Meta_mkAppM(x_7, x_203, x_2, x_3, x_4, x_5, x_194);
if (lean_obj_tag(x_204) == 0)
{
lean_object* x_205; lean_object* x_206; lean_object* x_207; lean_object* x_208; lean_object* x_209; lean_object* x_210; lean_object* x_211; lean_object* x_212; 
x_205 = lean_ctor_get(x_204, 0);
lean_inc(x_205);
x_206 = lean_ctor_get(x_204, 1);
lean_inc(x_206);
lean_dec(x_204);
x_207 = l_BitVec_reduceShiftRightShiftRight___redArg___closed__1;
x_208 = l_BitVec_reduceShiftShift___redArg___closed__0;
x_209 = lean_array_push(x_208, x_198);
x_210 = lean_array_push(x_209, x_187);
x_211 = lean_array_push(x_210, x_12);
lean_inc(x_5);
lean_inc(x_4);
lean_inc(x_3);
lean_inc(x_2);
x_212 = l_Lean_Meta_mkAppM(x_207, x_211, x_2, x_3, x_4, x_5, x_206);
if (lean_obj_tag(x_212) == 0)
{
lean_object* x_213; lean_object* x_214; lean_object* x_215; 
x_213 = lean_ctor_get(x_212, 0);
lean_inc(x_213);
x_214 = lean_ctor_get(x_212, 1);
lean_inc(x_214);
lean_dec(x_212);
x_215 = l_Lean_Meta_mkEqSymm(x_213, x_2, x_3, x_4, x_5, x_214);
if (lean_obj_tag(x_215) == 0)
{
lean_object* x_216; lean_object* x_217; lean_object* x_218; lean_object* x_219; lean_object* x_220; lean_object* x_221; lean_object* x_222; 
x_216 = lean_ctor_get(x_215, 0);
lean_inc(x_216);
x_217 = lean_ctor_get(x_215, 1);
lean_inc(x_217);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_218 = x_215;
} else {
 lean_dec_ref(x_215);
 x_218 = lean_box(0);
}
if (lean_is_scalar(x_196)) {
 x_219 = lean_alloc_ctor(1, 1, 0);
} else {
 x_219 = x_196;
}
lean_ctor_set(x_219, 0, x_216);
x_220 = lean_alloc_ctor(0, 2, 1);
lean_ctor_set(x_220, 0, x_205);
lean_ctor_set(x_220, 1, x_219);
lean_ctor_set_uint8(x_220, sizeof(void*)*2, x_184);
if (lean_is_scalar(x_181)) {
 x_221 = lean_alloc_ctor(1, 1, 0);
} else {
 x_221 = x_181;
}
lean_ctor_set(x_221, 0, x_220);
if (lean_is_scalar(x_218)) {
 x_222 = lean_alloc_ctor(0, 2, 0);
} else {
 x_222 = x_218;
}
lean_ctor_set(x_222, 0, x_221);
lean_ctor_set(x_222, 1, x_217);
return x_222;
}
else
{
lean_object* x_223; lean_object* x_224; lean_object* x_225; lean_object* x_226; 
lean_dec(x_205);
lean_dec(x_196);
lean_dec(x_181);
x_223 = lean_ctor_get(x_215, 0);
lean_inc(x_223);
x_224 = lean_ctor_get(x_215, 1);
lean_inc(x_224);
if (lean_is_exclusive(x_215)) {
 lean_ctor_release(x_215, 0);
 lean_ctor_release(x_215, 1);
 x_225 = x_215;
} else {
 lean_dec_ref(x_215);
 x_225 = lean_box(0);
}
if (lean_is_scalar(x_225)) {
 x_226 = lean_alloc_ctor(1, 2, 0);
} else {
 x_226 = x_225;
}
lean_ctor_set(x_226, 0, x_223);
lean_ctor_set(x_226, 1, x_224);
return x_226;
}
}
else
{
lean_object* x_227; lean_object* x_228; lean_object* x_229; lean_object* x_230; 
lean_dec(x_205);
lean_dec(x_196);
lean_dec(x_181);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_227 = lean_ctor_get(x_212, 0);
lean_inc(x_227);
x_228 = lean_ctor_get(x_212, 1);
lean_inc(x_228);
if (lean_is_exclusive(x_212)) {
 lean_ctor_release(x_212, 0);
 lean_ctor_release(x_212, 1);
 x_229 = x_212;
} else {
 lean_dec_ref(x_212);
 x_229 = lean_box(0);
}
if (lean_is_scalar(x_229)) {
 x_230 = lean_alloc_ctor(1, 2, 0);
} else {
 x_230 = x_229;
}
lean_ctor_set(x_230, 0, x_227);
lean_ctor_set(x_230, 1, x_228);
return x_230;
}
}
else
{
lean_object* x_231; lean_object* x_232; lean_object* x_233; lean_object* x_234; 
lean_dec(x_198);
lean_dec(x_196);
lean_dec(x_187);
lean_dec(x_181);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_231 = lean_ctor_get(x_204, 0);
lean_inc(x_231);
x_232 = lean_ctor_get(x_204, 1);
lean_inc(x_232);
if (lean_is_exclusive(x_204)) {
 lean_ctor_release(x_204, 0);
 lean_ctor_release(x_204, 1);
 x_233 = x_204;
} else {
 lean_dec_ref(x_204);
 x_233 = lean_box(0);
}
if (lean_is_scalar(x_233)) {
 x_234 = lean_alloc_ctor(1, 2, 0);
} else {
 x_234 = x_233;
}
lean_ctor_set(x_234, 0, x_231);
lean_ctor_set(x_234, 1, x_232);
return x_234;
}
}
}
else
{
lean_object* x_235; lean_object* x_236; lean_object* x_237; lean_object* x_238; 
lean_dec(x_187);
lean_dec(x_183);
lean_dec(x_181);
lean_dec(x_180);
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_235 = lean_ctor_get(x_188, 0);
lean_inc(x_235);
x_236 = lean_ctor_get(x_188, 1);
lean_inc(x_236);
if (lean_is_exclusive(x_188)) {
 lean_ctor_release(x_188, 0);
 lean_ctor_release(x_188, 1);
 x_237 = x_188;
} else {
 lean_dec_ref(x_188);
 x_237 = lean_box(0);
}
if (lean_is_scalar(x_237)) {
 x_238 = lean_alloc_ctor(1, 2, 0);
} else {
 x_238 = x_237;
}
lean_ctor_set(x_238, 0, x_235);
lean_ctor_set(x_238, 1, x_236);
return x_238;
}
}
}
}
}
else
{
uint8_t x_239; 
lean_dec(x_12);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_239 = !lean_is_exclusive(x_13);
if (x_239 == 0)
{
return x_13;
}
else
{
lean_object* x_240; lean_object* x_241; lean_object* x_242; 
x_240 = lean_ctor_get(x_13, 0);
x_241 = lean_ctor_get(x_13, 1);
lean_inc(x_241);
lean_inc(x_240);
lean_dec(x_13);
x_242 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_242, 0, x_240);
lean_ctor_set(x_242, 1, x_241);
return x_242;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftRightShiftRight___redArg(x_1, x_5, x_6, x_7, x_8, x_9);
return x_10;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___redArg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6) {
_start:
{
lean_object* x_7; 
x_7 = l_BitVec_reduceShiftRightShiftRight___redArg(x_1, x_2, x_3, x_4, x_5, x_6);
lean_dec(x_1);
return x_7;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceShiftRightShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_unchecked("reduceShiftRightShiftRight", 26, 26);
return x_1;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_2 = l_BitVec_reduceUnary___redArg___closed__1;
x_3 = l_Lean_Name_mkStr2(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_;
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(3);
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_array_push(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_4 = lean_alloc_closure((void*)(l_BitVec_reduceShiftRightShiftRight___boxed), 9, 0);
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftRightShiftRight___boxed), 9, 0);
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; uint8_t x_5; lean_object* x_6; 
x_2 = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_;
x_3 = lean_box(1);
x_4 = l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_;
x_5 = lean_unbox(x_3);
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttr(x_2, x_5, x_4, x_1);
return x_6;
}
}
lean_object* initialize_Lean_Meta_LitValues(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(uint8_t builtin, lean_object*);
lean_object* initialize_Init_Data_BitVec_Basic(uint8_t builtin, lean_object*);
static bool _G_initialized = false;
LEAN_EXPORT lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec(uint8_t builtin, lean_object* w) {
lean_object * res;
if (_G_initialized) return lean_io_result_mk_ok(lean_box(0));
_G_initialized = true;
res = initialize_Lean_Meta_LitValues(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Init_Data_BitVec_Basic(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_ = _init_l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_();
lean_mark_persistent(l_BitVec_reprLiteral___redArg___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_177_);
l_BitVec_instReprLiteral___closed__0 = _init_l_BitVec_instReprLiteral___closed__0();
lean_mark_persistent(l_BitVec_instReprLiteral___closed__0);
l_BitVec_instReprLiteral = _init_l_BitVec_instReprLiteral();
lean_mark_persistent(l_BitVec_instReprLiteral);
l_BitVec_reduceUnary___redArg___closed__0 = _init_l_BitVec_reduceUnary___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceUnary___redArg___closed__0);
l_BitVec_reduceUnary___redArg___closed__1 = _init_l_BitVec_reduceUnary___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceUnary___redArg___closed__1);
l_BitVec_reduceUnary___redArg___closed__2 = _init_l_BitVec_reduceUnary___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceUnary___redArg___closed__2);
l_BitVec_reduceUnary___redArg___closed__3 = _init_l_BitVec_reduceUnary___redArg___closed__3();
lean_mark_persistent(l_BitVec_reduceUnary___redArg___closed__3);
l_BitVec_reduceUnary___redArg___closed__4 = _init_l_BitVec_reduceUnary___redArg___closed__4();
lean_mark_persistent(l_BitVec_reduceUnary___redArg___closed__4);
l_BitVec_reduceGetBit___redArg___closed__0 = _init_l_BitVec_reduceGetBit___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__0);
l_BitVec_reduceGetBit___redArg___closed__1 = _init_l_BitVec_reduceGetBit___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__1);
l_BitVec_reduceGetBit___redArg___closed__2 = _init_l_BitVec_reduceGetBit___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__2);
l_BitVec_reduceGetBit___redArg___closed__3 = _init_l_BitVec_reduceGetBit___redArg___closed__3();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__3);
l_BitVec_reduceGetBit___redArg___closed__4 = _init_l_BitVec_reduceGetBit___redArg___closed__4();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__4);
l_BitVec_reduceGetBit___redArg___closed__5 = _init_l_BitVec_reduceGetBit___redArg___closed__5();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__5);
l_BitVec_reduceGetBit___redArg___closed__6 = _init_l_BitVec_reduceGetBit___redArg___closed__6();
lean_mark_persistent(l_BitVec_reduceGetBit___redArg___closed__6);
l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0 = _init_l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftWithBitVecLit___redArg___closed__0);
l_BitVec_reduceBinPred___redArg___closed__0 = _init_l_BitVec_reduceBinPred___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceBinPred___redArg___closed__0);
l_BitVec_reduceNeg___redArg___closed__0 = _init_l_BitVec_reduceNeg___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceNeg___redArg___closed__0);
l_BitVec_reduceNeg___redArg___closed__1 = _init_l_BitVec_reduceNeg___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceNeg___redArg___closed__1);
l_BitVec_reduceNeg___redArg___closed__2 = _init_l_BitVec_reduceNeg___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceNeg___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNeg_declare__44____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1537_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_ = _init_l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_();
lean_mark_persistent(l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_);
if (builtin) {res = l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1539_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceNeg___regBuiltin_BitVec_reduceNeg_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1541_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNot___redArg___closed__0 = _init_l_BitVec_reduceNot___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceNot___redArg___closed__0);
l_BitVec_reduceNot___redArg___closed__1 = _init_l_BitVec_reduceNot___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceNot___redArg___closed__1);
l_BitVec_reduceNot___redArg___closed__2 = _init_l_BitVec_reduceNot___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceNot___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNot_declare__49____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1574_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_ = _init_l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_();
lean_mark_persistent(l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_);
if (builtin) {res = l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1576_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceNot___regBuiltin_BitVec_reduceNot_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1578_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAbs___redArg___closed__0 = _init_l_BitVec_reduceAbs___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceAbs___redArg___closed__0);
l_BitVec_reduceAbs___redArg___closed__1 = _init_l_BitVec_reduceAbs___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceAbs___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAbs_declare__54____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_ = _init_l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_();
lean_mark_persistent(l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_);
if (builtin) {res = l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceAbs___regBuiltin_BitVec_reduceAbs_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1600_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAnd___redArg___closed__0 = _init_l_BitVec_reduceAnd___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceAnd___redArg___closed__0);
l_BitVec_reduceAnd___redArg___closed__1 = _init_l_BitVec_reduceAnd___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceAnd___redArg___closed__1);
l_BitVec_reduceAnd___redArg___closed__2 = _init_l_BitVec_reduceAnd___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceAnd___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAnd_declare__59____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1636_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_ = _init_l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_();
lean_mark_persistent(l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_);
if (builtin) {res = l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1638_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceAnd___regBuiltin_BitVec_reduceAnd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOr___redArg___closed__0 = _init_l_BitVec_reduceOr___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceOr___redArg___closed__0);
l_BitVec_reduceOr___redArg___closed__1 = _init_l_BitVec_reduceOr___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceOr___redArg___closed__1);
l_BitVec_reduceOr___redArg___closed__2 = _init_l_BitVec_reduceOr___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceOr___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOr_declare__64____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_ = _init_l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_();
lean_mark_persistent(l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_);
if (builtin) {res = l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1678_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceOr___regBuiltin_BitVec_reduceOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1680_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceXOr___redArg___closed__0 = _init_l_BitVec_reduceXOr___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceXOr___redArg___closed__0);
l_BitVec_reduceXOr___redArg___closed__1 = _init_l_BitVec_reduceXOr___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceXOr___redArg___closed__1);
l_BitVec_reduceXOr___redArg___closed__2 = _init_l_BitVec_reduceXOr___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceXOr___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceXOr_declare__69____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1716_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_ = _init_l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_();
lean_mark_persistent(l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_);
if (builtin) {res = l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceXOr___regBuiltin_BitVec_reduceXOr_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAdd___redArg___closed__0 = _init_l_BitVec_reduceAdd___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceAdd___redArg___closed__0);
l_BitVec_reduceAdd___redArg___closed__1 = _init_l_BitVec_reduceAdd___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceAdd___redArg___closed__1);
l_BitVec_reduceAdd___redArg___closed__2 = _init_l_BitVec_reduceAdd___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceAdd___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAdd_declare__74____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1756_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_ = _init_l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_();
lean_mark_persistent(l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_);
if (builtin) {res = l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1758_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceAdd___regBuiltin_BitVec_reduceAdd_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1760_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMul___redArg___closed__0 = _init_l_BitVec_reduceMul___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceMul___redArg___closed__0);
l_BitVec_reduceMul___redArg___closed__1 = _init_l_BitVec_reduceMul___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceMul___redArg___closed__1);
l_BitVec_reduceMul___redArg___closed__2 = _init_l_BitVec_reduceMul___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceMul___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMul_declare__79____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1796_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_ = _init_l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_();
lean_mark_persistent(l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_);
if (builtin) {res = l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1798_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceMul___regBuiltin_BitVec_reduceMul_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1800_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSub___redArg___closed__0 = _init_l_BitVec_reduceSub___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSub___redArg___closed__0);
l_BitVec_reduceSub___redArg___closed__1 = _init_l_BitVec_reduceSub___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSub___redArg___closed__1);
l_BitVec_reduceSub___redArg___closed__2 = _init_l_BitVec_reduceSub___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceSub___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSub_declare__84____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_ = _init_l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_();
lean_mark_persistent(l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_);
if (builtin) {res = l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSub___regBuiltin_BitVec_reduceSub_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1840_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceDiv___redArg___closed__0 = _init_l_BitVec_reduceDiv___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceDiv___redArg___closed__0);
l_BitVec_reduceDiv___redArg___closed__1 = _init_l_BitVec_reduceDiv___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceDiv___redArg___closed__1);
l_BitVec_reduceDiv___redArg___closed__2 = _init_l_BitVec_reduceDiv___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceDiv___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceDiv_declare__89____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_ = _init_l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_();
lean_mark_persistent(l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_);
if (builtin) {res = l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceDiv___regBuiltin_BitVec_reduceDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMod___redArg___closed__0 = _init_l_BitVec_reduceMod___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceMod___redArg___closed__0);
l_BitVec_reduceMod___redArg___closed__1 = _init_l_BitVec_reduceMod___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceMod___redArg___closed__1);
l_BitVec_reduceMod___redArg___closed__2 = _init_l_BitVec_reduceMod___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceMod___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceMod_declare__94____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_ = _init_l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_();
lean_mark_persistent(l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_);
if (builtin) {res = l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceMod___regBuiltin_BitVec_reduceMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUMod___redArg___closed__0 = _init_l_BitVec_reduceUMod___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceUMod___redArg___closed__0);
l_BitVec_reduceUMod___redArg___closed__1 = _init_l_BitVec_reduceUMod___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceUMod___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUMod_declare__99____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1943_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_ = _init_l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_();
lean_mark_persistent(l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_);
if (builtin) {res = l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1945_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceUMod___regBuiltin_BitVec_reduceUMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1947_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUDiv___redArg___closed__0 = _init_l_BitVec_reduceUDiv___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceUDiv___redArg___closed__0);
l_BitVec_reduceUDiv___redArg___closed__1 = _init_l_BitVec_reduceUDiv___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceUDiv___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUDiv_declare__104____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1970_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_ = _init_l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_();
lean_mark_persistent(l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_);
if (builtin) {res = l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1972_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceUDiv___regBuiltin_BitVec_reduceUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1974_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTUDiv___redArg___closed__0 = _init_l_BitVec_reduceSMTUDiv___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___redArg___closed__0);
l_BitVec_reduceSMTUDiv___redArg___closed__1 = _init_l_BitVec_reduceSMTUDiv___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTUDiv_declare__109____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1997_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_ = _init_l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_);
if (builtin) {res = l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1999_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSMTUDiv___regBuiltin_BitVec_reduceSMTUDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2001_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMod___redArg___closed__0 = _init_l_BitVec_reduceSMod___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSMod___redArg___closed__0);
l_BitVec_reduceSMod___redArg___closed__1 = _init_l_BitVec_reduceSMod___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSMod___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMod_declare__114____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2024_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_ = _init_l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_();
lean_mark_persistent(l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_);
if (builtin) {res = l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2026_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSMod___regBuiltin_BitVec_reduceSMod_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2028_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSRem___redArg___closed__0 = _init_l_BitVec_reduceSRem___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSRem___redArg___closed__0);
l_BitVec_reduceSRem___redArg___closed__1 = _init_l_BitVec_reduceSRem___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSRem___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSRem_declare__119____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2051_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_ = _init_l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_();
lean_mark_persistent(l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_);
if (builtin) {res = l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2053_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSRem___regBuiltin_BitVec_reduceSRem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2055_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSDiv___redArg___closed__0 = _init_l_BitVec_reduceSDiv___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSDiv___redArg___closed__0);
l_BitVec_reduceSDiv___redArg___closed__1 = _init_l_BitVec_reduceSDiv___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSDiv___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSDiv_declare__124____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2078_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_ = _init_l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_();
lean_mark_persistent(l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_);
if (builtin) {res = l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2080_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSDiv___regBuiltin_BitVec_reduceSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2082_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTSDiv___redArg___closed__0 = _init_l_BitVec_reduceSMTSDiv___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___redArg___closed__0);
l_BitVec_reduceSMTSDiv___redArg___closed__1 = _init_l_BitVec_reduceSMTSDiv___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSMTSDiv_declare__129____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2105_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_ = _init_l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_);
if (builtin) {res = l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2107_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSMTSDiv___regBuiltin_BitVec_reduceSMTSDiv_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2109_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetLsb___redArg___closed__0 = _init_l_BitVec_reduceGetLsb___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGetLsb___redArg___closed__0);
l_BitVec_reduceGetLsb___redArg___closed__1 = _init_l_BitVec_reduceGetLsb___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGetLsb___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetLsb_declare__134____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2127_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_ = _init_l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_();
lean_mark_persistent(l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_);
if (builtin) {res = l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2129_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceGetLsb___regBuiltin_BitVec_reduceGetLsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2131_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetMsb___redArg___closed__0 = _init_l_BitVec_reduceGetMsb___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGetMsb___redArg___closed__0);
l_BitVec_reduceGetMsb___redArg___closed__1 = _init_l_BitVec_reduceGetMsb___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGetMsb___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetMsb_declare__139____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2149_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_ = _init_l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_();
lean_mark_persistent(l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_);
if (builtin) {res = l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2151_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceGetMsb___regBuiltin_BitVec_reduceGetMsb_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2153_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceClz___redArg___closed__0 = _init_l_BitVec_reduceClz___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceClz___redArg___closed__0);
l_BitVec_reduceClz___redArg___closed__1 = _init_l_BitVec_reduceClz___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceClz___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceClz_declare__144____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2171_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_ = _init_l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_();
lean_mark_persistent(l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_);
if (builtin) {res = l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2173_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceClz___regBuiltin_BitVec_reduceClz_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2175_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetElem___redArg___closed__0 = _init_l_BitVec_reduceGetElem___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGetElem___redArg___closed__0);
l_BitVec_reduceGetElem___redArg___closed__1 = _init_l_BitVec_reduceGetElem___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGetElem___redArg___closed__1);
l_BitVec_reduceGetElem___redArg___closed__2 = _init_l_BitVec_reduceGetElem___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceGetElem___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGetElem_declare__149____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2638_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_ = _init_l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_();
lean_mark_persistent(l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_);
if (builtin) {res = l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2640_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceGetElem___regBuiltin_BitVec_reduceGetElem_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2642_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeft___redArg___closed__0 = _init_l_BitVec_reduceShiftLeft___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftLeft___redArg___closed__0);
l_BitVec_reduceShiftLeft___redArg___closed__1 = _init_l_BitVec_reduceShiftLeft___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeft___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeft_declare__154____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2661_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_ = _init_l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_();
lean_mark_persistent(l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_);
if (builtin) {res = l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2663_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceShiftLeft___regBuiltin_BitVec_reduceShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2665_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUShiftRight___redArg___closed__0 = _init_l_BitVec_reduceUShiftRight___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceUShiftRight___redArg___closed__0);
l_BitVec_reduceUShiftRight___redArg___closed__1 = _init_l_BitVec_reduceUShiftRight___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceUShiftRight___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceUShiftRight_declare__159____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2684_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_ = _init_l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_();
lean_mark_persistent(l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_);
if (builtin) {res = l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2686_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceUShiftRight___regBuiltin_BitVec_reduceUShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2688_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSShiftRight___redArg___closed__0 = _init_l_BitVec_reduceSShiftRight___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSShiftRight___redArg___closed__0);
l_BitVec_reduceSShiftRight___redArg___closed__1 = _init_l_BitVec_reduceSShiftRight___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSShiftRight___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSShiftRight_declare__164____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2707_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_ = _init_l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_();
lean_mark_persistent(l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_);
if (builtin) {res = l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2709_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSShiftRight___regBuiltin_BitVec_reduceSShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2711_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftLeft___redArg___closed__0 = _init_l_BitVec_reduceHShiftLeft___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___redArg___closed__0);
l_BitVec_reduceHShiftLeft___redArg___closed__1 = _init_l_BitVec_reduceHShiftLeft___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___redArg___closed__1);
l_BitVec_reduceHShiftLeft___redArg___closed__2 = _init_l_BitVec_reduceHShiftLeft___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_declare__169____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2747_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_ = _init_l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_);
if (builtin) {res = l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2749_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceHShiftLeft___regBuiltin_BitVec_reduceHShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2751_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftLeft_x27_declare__174____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2777_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_ = _init_l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_();
lean_mark_persistent(l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_);
if (builtin) {res = l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2779_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceHShiftLeft_x27___regBuiltin_BitVec_reduceHShiftLeft_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2781_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftRight___redArg___closed__0 = _init_l_BitVec_reduceHShiftRight___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceHShiftRight___redArg___closed__0);
l_BitVec_reduceHShiftRight___redArg___closed__1 = _init_l_BitVec_reduceHShiftRight___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftRight___redArg___closed__1);
l_BitVec_reduceHShiftRight___redArg___closed__2 = _init_l_BitVec_reduceHShiftRight___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftRight___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_declare__179____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2817_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_ = _init_l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_();
lean_mark_persistent(l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_);
if (builtin) {res = l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2819_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceHShiftRight___regBuiltin_BitVec_reduceHShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2821_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceHShiftRight_x27_declare__184____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2847_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_ = _init_l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_();
lean_mark_persistent(l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_);
if (builtin) {res = l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2849_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceHShiftRight_x27___regBuiltin_BitVec_reduceHShiftRight_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2851_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateLeft___redArg___closed__0 = _init_l_BitVec_reduceRotateLeft___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceRotateLeft___redArg___closed__0);
l_BitVec_reduceRotateLeft___redArg___closed__1 = _init_l_BitVec_reduceRotateLeft___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateLeft___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateLeft_declare__189____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2870_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_ = _init_l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_();
lean_mark_persistent(l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_);
if (builtin) {res = l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceRotateLeft___regBuiltin_BitVec_reduceRotateLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateRight___redArg___closed__0 = _init_l_BitVec_reduceRotateRight___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceRotateRight___redArg___closed__0);
l_BitVec_reduceRotateRight___redArg___closed__1 = _init_l_BitVec_reduceRotateRight___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateRight___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceRotateRight_declare__194____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2893_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_ = _init_l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_();
lean_mark_persistent(l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_);
if (builtin) {res = l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2895_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceRotateRight___regBuiltin_BitVec_reduceRotateRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2897_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAppend___redArg___closed__0 = _init_l_BitVec_reduceAppend___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceAppend___redArg___closed__0);
l_BitVec_reduceAppend___redArg___closed__1 = _init_l_BitVec_reduceAppend___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceAppend___redArg___closed__1);
l_BitVec_reduceAppend___redArg___closed__2 = _init_l_BitVec_reduceAppend___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceAppend___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAppend_declare__199____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3260_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_ = _init_l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_();
lean_mark_persistent(l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_);
if (builtin) {res = l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3262_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceAppend___regBuiltin_BitVec_reduceAppend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3264_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceCast___redArg___closed__0 = _init_l_BitVec_reduceCast___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceCast___redArg___closed__0);
l_BitVec_reduceCast___redArg___closed__1 = _init_l_BitVec_reduceCast___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceCast___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceCast_declare__204____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3559_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_ = _init_l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_();
lean_mark_persistent(l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_);
if (builtin) {res = l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3561_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceCast___regBuiltin_BitVec_reduceCast_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3563_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToNat___redArg___closed__0 = _init_l_BitVec_reduceToNat___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceToNat___redArg___closed__0);
l_BitVec_reduceToNat___redArg___closed__1 = _init_l_BitVec_reduceToNat___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceToNat___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToNat_declare__209____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_ = _init_l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_();
lean_mark_persistent(l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_);
if (builtin) {res = l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceToNat___regBuiltin_BitVec_reduceToNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToInt___redArg___closed__0 = _init_l_BitVec_reduceToInt___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__0);
l_BitVec_reduceToInt___redArg___closed__1 = _init_l_BitVec_reduceToInt___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__1);
l_BitVec_reduceToInt___redArg___closed__2 = _init_l_BitVec_reduceToInt___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__2);
l_BitVec_reduceToInt___redArg___closed__3 = _init_l_BitVec_reduceToInt___redArg___closed__3();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__3);
l_BitVec_reduceToInt___redArg___closed__4 = _init_l_BitVec_reduceToInt___redArg___closed__4();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__4);
l_BitVec_reduceToInt___redArg___closed__5 = _init_l_BitVec_reduceToInt___redArg___closed__5();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__5);
l_BitVec_reduceToInt___redArg___closed__6 = _init_l_BitVec_reduceToInt___redArg___closed__6();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__6);
l_BitVec_reduceToInt___redArg___closed__7 = _init_l_BitVec_reduceToInt___redArg___closed__7();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__7);
l_BitVec_reduceToInt___redArg___closed__8 = _init_l_BitVec_reduceToInt___redArg___closed__8();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__8);
l_BitVec_reduceToInt___redArg___closed__9 = _init_l_BitVec_reduceToInt___redArg___closed__9();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__9);
l_BitVec_reduceToInt___redArg___closed__10 = _init_l_BitVec_reduceToInt___redArg___closed__10();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__10);
l_BitVec_reduceToInt___redArg___closed__11 = _init_l_BitVec_reduceToInt___redArg___closed__11();
lean_mark_persistent(l_BitVec_reduceToInt___redArg___closed__11);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceToInt_declare__214____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3933_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_ = _init_l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_();
lean_mark_persistent(l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_);
if (builtin) {res = l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3935_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceToInt___regBuiltin_BitVec_reduceToInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3937_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfInt___redArg___closed__0 = _init_l_BitVec_reduceOfInt___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceOfInt___redArg___closed__0);
l_BitVec_reduceOfInt___redArg___closed__1 = _init_l_BitVec_reduceOfInt___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceOfInt___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfInt_declare__219____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4172_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_ = _init_l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_();
lean_mark_persistent(l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_);
if (builtin) {res = l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4174_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceOfInt___regBuiltin_BitVec_reduceOfInt_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4176_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceOfNat_declare__224____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4463_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_ = _init_l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_();
lean_mark_persistent(l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_);
if (builtin) {res = l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4465_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceOfNat___regBuiltin_BitVec_reduceOfNat_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4467_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceEq___redArg___closed__0 = _init_l_BitVec_reduceEq___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceEq___redArg___closed__0);
l_BitVec_reduceEq___redArg___closed__1 = _init_l_BitVec_reduceEq___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceEq___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceEq_declare__229____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4504_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_ = _init_l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_();
lean_mark_persistent(l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_);
if (builtin) {res = l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4506_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceEq___regBuiltin_BitVec_reduceEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4508_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNe___redArg___closed__0 = _init_l_BitVec_reduceNe___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceNe___redArg___closed__0);
l_BitVec_reduceNe___redArg___closed__1 = _init_l_BitVec_reduceNe___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceNe___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceNe_declare__234____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4544_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_ = _init_l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_();
lean_mark_persistent(l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_);
if (builtin) {res = l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4546_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceNe___regBuiltin_BitVec_reduceNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4548_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBEq___redArg___closed__0 = _init_l_BitVec_reduceBEq___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceBEq___redArg___closed__0);
l_BitVec_reduceBEq___redArg___closed__1 = _init_l_BitVec_reduceBEq___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceBEq___redArg___closed__1);
l_BitVec_reduceBEq___redArg___closed__2 = _init_l_BitVec_reduceBEq___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceBEq___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBEq_declare__239____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4585_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_ = _init_l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_();
lean_mark_persistent(l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_);
if (builtin) {res = l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4587_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceBEq___regBuiltin_BitVec_reduceBEq_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4589_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBNe___redArg___closed__0 = _init_l_BitVec_reduceBNe___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceBNe___redArg___closed__0);
l_BitVec_reduceBNe___redArg___closed__1 = _init_l_BitVec_reduceBNe___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceBNe___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBNe_declare__244____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4625_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_ = _init_l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_();
lean_mark_persistent(l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_);
if (builtin) {res = l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4627_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceBNe___regBuiltin_BitVec_reduceBNe_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4629_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLT___redArg___closed__0 = _init_l_BitVec_reduceLT___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceLT___redArg___closed__0);
l_BitVec_reduceLT___redArg___closed__1 = _init_l_BitVec_reduceLT___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceLT___redArg___closed__1);
l_BitVec_reduceLT___redArg___closed__2 = _init_l_BitVec_reduceLT___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceLT___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLT_declare__249____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4666_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_ = _init_l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_();
lean_mark_persistent(l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_);
if (builtin) {res = l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4668_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceLT___regBuiltin_BitVec_reduceLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4670_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLE___redArg___closed__0 = _init_l_BitVec_reduceLE___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceLE___redArg___closed__0);
l_BitVec_reduceLE___redArg___closed__1 = _init_l_BitVec_reduceLE___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceLE___redArg___closed__1);
l_BitVec_reduceLE___redArg___closed__2 = _init_l_BitVec_reduceLE___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceLE___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceLE_declare__254____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4707_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_ = _init_l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_();
lean_mark_persistent(l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_);
if (builtin) {res = l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4709_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceLE___regBuiltin_BitVec_reduceLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4711_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGT___redArg___closed__0 = _init_l_BitVec_reduceGT___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGT___redArg___closed__0);
l_BitVec_reduceGT___redArg___closed__1 = _init_l_BitVec_reduceGT___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGT___redArg___closed__1);
l_BitVec_reduceGT___redArg___closed__2 = _init_l_BitVec_reduceGT___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceGT___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGT_declare__259____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4748_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_ = _init_l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_();
lean_mark_persistent(l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_);
if (builtin) {res = l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4750_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceGT___regBuiltin_BitVec_reduceGT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4752_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGE___redArg___closed__0 = _init_l_BitVec_reduceGE___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceGE___redArg___closed__0);
l_BitVec_reduceGE___redArg___closed__1 = _init_l_BitVec_reduceGE___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceGE___redArg___closed__1);
l_BitVec_reduceGE___redArg___closed__2 = _init_l_BitVec_reduceGE___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceGE___redArg___closed__2);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceGE_declare__264____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4789_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_ = _init_l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_();
lean_mark_persistent(l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_);
if (builtin) {res = l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4791_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceGE___regBuiltin_BitVec_reduceGE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4793_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULT___redArg___closed__0 = _init_l_BitVec_reduceULT___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceULT___redArg___closed__0);
l_BitVec_reduceULT___redArg___closed__1 = _init_l_BitVec_reduceULT___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceULT___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULT_declare__269____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4812_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_ = _init_l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_();
lean_mark_persistent(l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_);
if (builtin) {res = l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4814_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceULT___regBuiltin_BitVec_reduceULT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4816_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULE___redArg___closed__0 = _init_l_BitVec_reduceULE___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceULE___redArg___closed__0);
l_BitVec_reduceULE___redArg___closed__1 = _init_l_BitVec_reduceULE___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceULE___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceULE_declare__274____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4835_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_ = _init_l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_();
lean_mark_persistent(l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_);
if (builtin) {res = l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4837_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceULE___regBuiltin_BitVec_reduceULE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4839_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLT___redArg___closed__0 = _init_l_BitVec_reduceSLT___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSLT___redArg___closed__0);
l_BitVec_reduceSLT___redArg___closed__1 = _init_l_BitVec_reduceSLT___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSLT___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLT_declare__279____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4858_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_ = _init_l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_();
lean_mark_persistent(l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_);
if (builtin) {res = l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4860_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSLT___regBuiltin_BitVec_reduceSLT_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4862_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLE___redArg___closed__0 = _init_l_BitVec_reduceSLE___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSLE___redArg___closed__0);
l_BitVec_reduceSLE___redArg___closed__1 = _init_l_BitVec_reduceSLE___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSLE___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSLE_declare__284____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4881_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_ = _init_l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_();
lean_mark_persistent(l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_);
if (builtin) {res = l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4883_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSLE___regBuiltin_BitVec_reduceSLE_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4885_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSetWidth_x27___redArg___closed__0 = _init_l_BitVec_reduceSetWidth_x27___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSetWidth_x27___redArg___closed__0);
l_BitVec_reduceSetWidth_x27___redArg___closed__1 = _init_l_BitVec_reduceSetWidth_x27___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSetWidth_x27___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_x27_declare__289____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5207_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_ = _init_l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_();
lean_mark_persistent(l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_);
if (builtin) {res = l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5209_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSetWidth_x27___regBuiltin_BitVec_reduceSetWidth_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5211_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0 = _init_l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__0);
l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1 = _init_l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__294____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5475_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_ = _init_l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_);
if (builtin) {res = l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5477_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceShiftLeftZeroExtend___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5479_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceExtracLsb_x27___redArg___closed__0 = _init_l_BitVec_reduceExtracLsb_x27___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___redArg___closed__0);
l_BitVec_reduceExtracLsb_x27___redArg___closed__1 = _init_l_BitVec_reduceExtracLsb_x27___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceExtracLsb_x27_declare__299____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5823_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_ = _init_l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_);
if (builtin) {res = l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5825_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceExtracLsb_x27___regBuiltin_BitVec_reduceExtracLsb_x27_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5827_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceReplicate___redArg___closed__0 = _init_l_BitVec_reduceReplicate___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceReplicate___redArg___closed__0);
l_BitVec_reduceReplicate___redArg___closed__1 = _init_l_BitVec_reduceReplicate___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceReplicate___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceReplicate_declare__304____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6091_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_ = _init_l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_();
lean_mark_persistent(l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_);
if (builtin) {res = l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6093_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceReplicate___regBuiltin_BitVec_reduceReplicate_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6095_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSetWidth___redArg___closed__0 = _init_l_BitVec_reduceSetWidth___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSetWidth___redArg___closed__0);
l_BitVec_reduceSetWidth___redArg___closed__1 = _init_l_BitVec_reduceSetWidth___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSetWidth___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSetWidth_declare__309____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6113_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_ = _init_l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_();
lean_mark_persistent(l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_);
if (builtin) {res = l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6115_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSetWidth___regBuiltin_BitVec_reduceSetWidth_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6117_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend___redArg___closed__0 = _init_l_BitVec_reduceZeroExtend___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceZeroExtend___redArg___closed__0);
l_BitVec_reduceZeroExtend___redArg___closed__1 = _init_l_BitVec_reduceZeroExtend___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceZeroExtend___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceZeroExtend_declare__314____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6135_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_ = _init_l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_();
lean_mark_persistent(l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_);
if (builtin) {res = l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6137_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceZeroExtend___regBuiltin_BitVec_reduceZeroExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6139_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSignExtend___redArg___closed__0 = _init_l_BitVec_reduceSignExtend___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceSignExtend___redArg___closed__0);
l_BitVec_reduceSignExtend___redArg___closed__1 = _init_l_BitVec_reduceSignExtend___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceSignExtend___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceSignExtend_declare__319____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6157_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_ = _init_l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_();
lean_mark_persistent(l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_);
if (builtin) {res = l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6159_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceSignExtend___regBuiltin_BitVec_reduceSignExtend_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6161_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAllOnes___redArg___closed__0 = _init_l_BitVec_reduceAllOnes___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceAllOnes___redArg___closed__0);
l_BitVec_reduceAllOnes___redArg___closed__1 = _init_l_BitVec_reduceAllOnes___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceAllOnes___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceAllOnes_declare__324____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6317_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_ = _init_l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_();
lean_mark_persistent(l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_);
if (builtin) {res = l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6319_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceAllOnes___regBuiltin_BitVec_reduceAllOnes_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6321_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecOfFin___redArg___closed__0 = _init_l_BitVec_reduceBitVecOfFin___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___redArg___closed__0);
l_BitVec_reduceBitVecOfFin___redArg___closed__1 = _init_l_BitVec_reduceBitVecOfFin___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecOfFin_declare__329____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6567_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_ = _init_l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_);
if (builtin) {res = l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6569_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceBitVecOfFin___regBuiltin_BitVec_reduceBitVecOfFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6571_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecToFin___redArg___closed__0 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__0);
l_BitVec_reduceBitVecToFin___redArg___closed__1 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__1);
l_BitVec_reduceBitVecToFin___redArg___closed__2 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__2();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__2);
l_BitVec_reduceBitVecToFin___redArg___closed__3 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__3();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__3);
l_BitVec_reduceBitVecToFin___redArg___closed__4 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__4();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__4);
l_BitVec_reduceBitVecToFin___redArg___closed__5 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__5();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__5);
l_BitVec_reduceBitVecToFin___redArg___closed__6 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__6();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__6);
l_BitVec_reduceBitVecToFin___redArg___closed__7 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__7();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__7);
l_BitVec_reduceBitVecToFin___redArg___closed__8 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__8();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__8);
l_BitVec_reduceBitVecToFin___redArg___closed__9 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__9();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__9);
l_BitVec_reduceBitVecToFin___redArg___closed__10 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__10();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__10);
l_BitVec_reduceBitVecToFin___redArg___closed__11 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__11();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__11);
l_BitVec_reduceBitVecToFin___redArg___closed__12 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__12();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__12);
l_BitVec_reduceBitVecToFin___redArg___closed__13 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__13();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__13);
l_BitVec_reduceBitVecToFin___redArg___closed__14 = _init_l_BitVec_reduceBitVecToFin___redArg___closed__14();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___redArg___closed__14);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceBitVecToFin_declare__334____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6765_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_ = _init_l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_);
if (builtin) {res = l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6767_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l_BitVec_reduceBitVecToFin___regBuiltin_BitVec_reduceBitVecToFin_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_6769_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftShift___redArg___closed__0 = _init_l_BitVec_reduceShiftShift___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftShift___redArg___closed__0);
l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0 = _init_l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__0);
l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1 = _init_l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeftShiftLeft___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342___closed__18____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__342____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7064_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_ = _init_l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_();
lean_mark_persistent(l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_);
if (builtin) {res = l_BitVec_reduceShiftLeftShiftLeft___regBuiltin_BitVec_reduceShiftLeftShiftLeft_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7066_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftRightShiftRight___redArg___closed__0 = _init_l_BitVec_reduceShiftRightShiftRight___redArg___closed__0();
lean_mark_persistent(l_BitVec_reduceShiftRightShiftRight___redArg___closed__0);
l_BitVec_reduceShiftRightShiftRight___redArg___closed__1 = _init_l_BitVec_reduceShiftRightShiftRight___redArg___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftRightShiftRight___redArg___closed__1);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__2____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__3____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__4____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__5____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__6____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__7____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__8____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__9____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__10____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__11____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__12____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__13____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__14____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__15____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__16____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_ = _init_l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_();
lean_mark_persistent(l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347___closed__17____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_);
if (builtin) {res = l___private_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec_0____regBuiltin_BitVec_reduceShiftRightShiftRight_declare__347____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7097_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_ = _init_l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_();
lean_mark_persistent(l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1___closed__0____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_);
if (builtin) {res = l_BitVec_reduceShiftRightShiftRight___regBuiltin_BitVec_reduceShiftRightShiftRight_declare__1____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_7099_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}return lean_io_result_mk_ok(lean_box(0));
}
#ifdef __cplusplus
}
#endif
